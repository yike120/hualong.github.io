<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小廖子的博客</title>
  
  <subtitle>好记性不如记笔记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://xiaoliaozi.com/"/>
  <updated>2020-06-01T10:52:27.280Z</updated>
  <id>https://xiaoliaozi.com/</id>
  
  <author>
    <name>小廖子</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>C++30天学习打卡（三）</title>
    <link href="https://xiaoliaozi.com/2020/05/31/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>https://xiaoliaozi.com/2020/05/31/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%89%EF%BC%89/</id>
    <published>2020-05-31T08:02:57.000Z</published>
    <updated>2020-06-01T10:52:27.280Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-30天学习打卡（三）"><a href="#C-30天学习打卡（三）" class="headerlink" title="C++30天学习打卡（三）"></a>C++30天学习打卡（三）</h3><h3 id="程序流程结构"><a href="#程序流程结构" class="headerlink" title="程序流程结构"></a>程序流程结构</h3><p>C/C++支持最基本的三种程序运行结构：==顺序结构、选择结构、循环结构==</p><ul><li>顺序结构：程序按顺序执行，不发生跳转</li><li>选择结构：依据条件是否满足，有选择的执行相应功能</li><li>循环结构：依据条件是否满足，循环多次执行某段代码</li></ul><a id="more"></a><h4 id="选择结构"><a href="#选择结构" class="headerlink" title="选择结构"></a>选择结构</h4><ul><li><h5 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h5><ul><li><p><strong>作用：</strong>执行满足条件的语句</p></li><li><p>if语句的三种形式：单行格式if语句；多行格式if语句；多条件的if语句</p></li><li><p>注意：==在if判断语句后面，不要加分号==</p></li><li><p>代码示例：三只小猪称体重</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 三只小猪称体重</span></span><br><span class="line"><span class="keyword">int</span> A = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> B = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> C = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪A的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; A;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪B的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; B;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪C的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; C;</span><br><span class="line"><span class="keyword">if</span> (A &gt;= C) &#123;</span><br><span class="line"><span class="keyword">if</span> (B &gt;= A) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪B的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪A的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (B &gt;= C) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪B的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪C的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="三目运算符"><a href="#三目运算符" class="headerlink" title="三目运算符"></a>三目运算符</h5><ul><li><p>作用：通过三目运算符实现简单的判断，和if语句比较，三目运算符优点是短小整洁，缺点是如果用嵌套，结构不清晰</p></li><li><p>语法：<code>表达式1 ? 表达式2 ：表达式3</code></p></li><li><p>解释：==如果表达式1的值为真，执行表达式2，并返回表达式2的结果；如果表达式1的值为假，执行表达式3，并返回表达式3的结果。==</p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">c = a &gt; b ? a : b;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"c = "</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// C++中的三目运算符返回的是变量，可以继续赋值</span></span><br><span class="line">(a &gt; b ? a : b) = <span class="number">100</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"b = "</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"c = "</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="switch语句"><a href="#switch语句" class="headerlink" title="switch语句"></a>switch语句</h5><ul><li><p>作用：执行多条件分支语句</p></li><li><p>语法：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(表达式)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> 结果<span class="number">1</span>：执行语句;<span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> 结果<span class="number">2</span>：执行语句;<span class="keyword">break</span>;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">default</span>:执行语句;<span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 给电影评分</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">9-10-非常好</span></span><br><span class="line"><span class="comment">7-8-还行</span></span><br><span class="line"><span class="comment">5-6-一般</span></span><br><span class="line"><span class="comment">5以下-烂片</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请给该电影评分："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; score;</span><br><span class="line"><span class="keyword">switch</span> (score)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="number">10</span>:</span><br><span class="line"><span class="keyword">case</span> <span class="number">9</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影非常好看"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">8</span>:</span><br><span class="line"><span class="keyword">case</span> <span class="number">7</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影还行"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">6</span>:</span><br><span class="line"><span class="keyword">case</span> <span class="number">5</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影一般"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影是烂片，别看"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>注意：</p><blockquote><p>1.switch语句中表达式类型只能是整型或者字符型；</p><p>2.case里如果没有break，那么程序会一直向下执行；</p><p>3.与if语句比，对于多条件判断时，switch的结构清晰，执行效率高，缺点是switch不可以判断区间。</p></blockquote></li></ul></li></ul><h4 id="循环结构"><a href="#循环结构" class="headerlink" title="循环结构"></a>循环结构</h4><ul><li><h5 id="while循环语句"><a href="#while循环语句" class="headerlink" title="while循环语句"></a>while循环语句</h5><ul><li><p>作用：满足循环条件，执行循环语句。</p></li><li><p>语法：==while(循环条件){循环语句}==</p></li><li><p>示例：==猜数字==，注意：在执行循环语句时候，程序必须提供跳出循环的出口，否则出现死循环。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 猜数字游戏</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">bool</span> flag = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (flag)</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// 随机生成数字</span></span><br><span class="line"><span class="keyword">int</span> a = rand() % <span class="number">101</span>;</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"产生的随机数为："</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 测试用</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请玩家输入猜测的数字："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; b;</span><br><span class="line"><span class="keyword">if</span> (b &gt; a) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"数字猜大了哦"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (b &lt; a) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"猜的数字有点小了哈"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"恭喜玩家猜对了呢"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"退出游戏输入0，继续游戏输入1"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; flag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"退出游戏了哦"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="do…while循环语句"><a href="#do…while循环语句" class="headerlink" title="do…while循环语句"></a>do…while循环语句</h5><ul><li><p>作用：满足循环条件，执行循环语句；</p></li><li><p>语法：<code>do{ 循环语句 } while(循环条件);</code></p></li><li><p>注意：与while的区别在于==do…while会先执行一次循环语句==，再判断循环条件；</p></li><li><p>示例：水仙花数，水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 水仙花数</span></span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> c = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> start = <span class="number">100</span>;</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line"><span class="keyword">int</span> a = start / <span class="number">100</span>; <span class="comment">// 百位</span></span><br><span class="line">b = (start / <span class="number">10</span>)%<span class="number">10</span>; <span class="comment">// 十位</span></span><br><span class="line">c = start % <span class="number">10</span>; <span class="comment">// 个位</span></span><br><span class="line"><span class="keyword">if</span> ((a*a*a + b*b*b + c*c*c) == start) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; start &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">start++;</span><br><span class="line">&#125; <span class="keyword">while</span> (start &lt; <span class="number">1000</span>);</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="for循环语句"><a href="#for循环语句" class="headerlink" title="for循环语句"></a>for循环语句</h5><ul><li><p>作用： 满足循环条件，执行循环语句</p></li><li><p>语法：<code>for(起始表达式;条件表达式;末尾循环体) { 循环语句; }</code></p></li><li><p>注意：</p><blockquote><p>1.for循环中的表达式，要用分号进行分隔</p><p>2.while , do…while, for都是开发中常用的循环语句，for循环结构比较清晰，比较常用</p></blockquote></li><li><p>示例：敲桌子：从1开始数到数字100， 如果数字个位含有7，或者数字十位含有7，或者该数字是7的倍数，我们打印敲桌子，其余数字直接打印输出。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 敲桌子</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">100</span>; i++) &#123;</span><br><span class="line"><span class="keyword">if</span> (i / <span class="number">10</span> == <span class="number">7</span> || i % <span class="number">10</span> == <span class="number">7</span> || i % <span class="number">7</span> == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"敲桌子\t"</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; i &lt;&lt;<span class="string">"\t"</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="嵌套循环"><a href="#嵌套循环" class="headerlink" title="嵌套循环"></a>嵌套循环</h5><ul><li><p>作用：在循环体中再嵌套一层循环，解决一些实际问题；</p></li><li><p>示例：九九乘法表</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 九九乘法表</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; <span class="number">10</span>; j++) &#123;</span><br><span class="line"><span class="keyword">if</span> (j &lt;= i)&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; j &lt;&lt; <span class="string">" * "</span> &lt;&lt; i &lt;&lt; <span class="string">" = "</span> &lt;&lt; i * j &lt;&lt; <span class="string">"\t"</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="跳转语句"><a href="#跳转语句" class="headerlink" title="跳转语句"></a>跳转语句</h4><ul><li><h5 id="break语句"><a href="#break语句" class="headerlink" title="break语句"></a>break语句</h5><ul><li>作用： 用于跳出==选择结构==或者==循环结构==</li><li>使用的时机：<ol><li>出现在switch条件语句中，作用是终止case并跳出switch;</li><li>出现在循环语句中，作用是跳出当前的循环语句;</li><li>出现在嵌套循环中，跳出==最近==的内层循环语句</li></ol></li></ul></li><li><h5 id="continue语句"><a href="#continue语句" class="headerlink" title="continue语句"></a>continue语句</h5><ul><li>作用：在==循环语句==中，跳过本次循环中余下尚未执行的语句，继续执行下一次循环</li><li>注意：==continue并没有使整个循环终止，而break会跳出循环。==</li></ul></li><li><h5 id="goto语句"><a href="#goto语句" class="headerlink" title="goto语句"></a>goto语句</h5><ul><li><p>作用：可以无条件跳转语句</p></li><li><p>语法： <code>goto 标记;</code>如果标记的名称存在，执行到goto语句时，会跳转到标记的位置。</p></li><li><p>示例：==在程序中不建议使用goto语句，以免造成程序流程混乱。==</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"1"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">goto</span> FLAG;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"2"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"3"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"4"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">FLAG:</span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"5"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-30天学习打卡（三）&quot;&gt;&lt;a href=&quot;#C-30天学习打卡（三）&quot; class=&quot;headerlink&quot; title=&quot;C++30天学习打卡（三）&quot;&gt;&lt;/a&gt;C++30天学习打卡（三）&lt;/h3&gt;&lt;h3 id=&quot;程序流程结构&quot;&gt;&lt;a href=&quot;#程序流程结构&quot; class=&quot;headerlink&quot; title=&quot;程序流程结构&quot;&gt;&lt;/a&gt;程序流程结构&lt;/h3&gt;&lt;p&gt;C/C++支持最基本的三种程序运行结构：==顺序结构、选择结构、循环结构==&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顺序结构：程序按顺序执行，不发生跳转&lt;/li&gt;
&lt;li&gt;选择结构：依据条件是否满足，有选择的执行相应功能&lt;/li&gt;
&lt;li&gt;循环结构：依据条件是否满足，循环多次执行某段代码&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="C++30天学习打卡" scheme="https://xiaoliaozi.com/categories/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1/"/>
    
    
      <category term="C++" scheme="https://xiaoliaozi.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++30天学习打卡（二）</title>
    <link href="https://xiaoliaozi.com/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://xiaoliaozi.com/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%BA%8C%EF%BC%89/</id>
    <published>2020-05-30T13:10:52.000Z</published>
    <updated>2020-05-31T08:01:32.767Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-30天学习打卡（二）"><a href="#C-30天学习打卡（二）" class="headerlink" title="C++30天学习打卡（二）"></a>C++30天学习打卡（二）</h3><h4 id="1-数据类型"><a href="#1-数据类型" class="headerlink" title="1.数据类型"></a>1.数据类型</h4><blockquote><p>C++规定在创建一个变量或者常量时，必须要指定出相应的数据类型，否则无法给变量分配内存。</p><p>数据类型存在的意义：给变量分配合适的内存空间。</p></blockquote><ol><li><h5 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h5><ul><li><p>作用：整型变量表示的是<strong>整数类型</strong>的数据</p></li><li><p>分类：C++中能够表示整型的类型有以下几种方式，<strong>区别在于所占内存空间不同</strong></p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200531124009.png"/></p><a id="more"></a></li></ul></li><li><h5 id="sizeof关键字"><a href="#sizeof关键字" class="headerlink" title="sizeof关键字"></a>sizeof关键字</h5><ul><li><p>作用：利用sizeof关键字可以==统计数据类型所占内存大小==</p></li><li><p>语法：<strong>sizeof（数据类型/变量）</strong></p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"short 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(short) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"int 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">int</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"long 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">long</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"long long 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">long</span> <span class="keyword">long</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="实型（浮点型）"><a href="#实型（浮点型）" class="headerlink" title="实型（浮点型）"></a>实型（浮点型）</h5><ul><li><p>作用：用于==表示小数==</p></li><li><p>分类：浮点型变量分为两种，两者的<strong>区别</strong>在于表示的有效数字范围不同。</p><ol><li>单精度float;</li><li>双精度double;</li></ol><p>| <strong>数据类型</strong> | <strong>占用空间</strong> | <strong>有效数字范围</strong> |<br>| —————— | —————— | ———————— |<br>| float        | 4字节        | 7位有效数字      |<br>| double       | 8字节        | 15～16位有效数字 |</p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 1.单精度</span></span><br><span class="line"><span class="comment">// 2.双精度</span></span><br><span class="line"><span class="comment">// 默认情况下，输出一个小数，会显示6位有效数字</span></span><br><span class="line"><span class="keyword">float</span> fl = <span class="number">3.1415926f</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"fl= "</span> &lt;&lt; fl &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> dl = <span class="number">3.145926</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"dl = "</span> &lt;&lt; dl &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 统计</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"float 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">float</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"double 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">double</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//科学计数法</span></span><br><span class="line"><span class="keyword">float</span> f2 = <span class="number">3e2</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"f2 = "</span> &lt;&lt; f2 &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">float</span> f3 = <span class="number">3e-2</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"f3 = "</span> &lt;&lt; f3 &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="字符型"><a href="#字符型" class="headerlink" title="字符型"></a>字符型</h5><ul><li><p>作用：字符型变量用于显示单个字符</p></li><li><p>语法：<strong>char ch = ‘a’</strong>;</p></li><li><p>注意：</p><ol><li><strong>在显示字符型变量时，用单引号将字符括起来，不要用双引号</strong>；</li><li><strong>单引号内只能有一个字符，不可以是字符串</strong>；</li><li><strong>C和C++中字符型变量只占用1个字节</strong>；</li><li><strong>字符型变量并不是把字符本身放到内存中存储，而是将对应的ASCII编码放入到存储单元</strong>。</li></ol></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 1.字符型变量创建方式</span></span><br><span class="line"><span class="keyword">char</span> ch = <span class="string">'a'</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; ch &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.字符型变量所占内存大小</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"char 字符型变量所占内存为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">char</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.字符型变量常见错误 </span></span><br><span class="line"><span class="comment">// char ch2 = "b"; // 要用单引号</span></span><br><span class="line"><span class="comment">// char ch3 = 'abcdf' // 只能一个字符</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 4.字符型变量对于ASKII码 a-97 A-65</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; (<span class="keyword">int</span>)ch &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a>转义字符</h5><ul><li><p>作用：用于表示一些==不能显示出来的ASCII字符==</p></li><li><p>罗列：现阶段我们常用的转义字符有：<code>\n  \\  \t</code></p><p>| <strong>转义字符</strong> | <strong>含义</strong>                                | <strong>ASCII</strong>码值（十进制） |<br>| —————— | ———————————————————- | ———————————- |<br>| \a           | 警报                                    | 007                     |<br>| \b           | 退格(BS) ，将当前位置移到前一列         | 008                     |<br>| \f           | 换页(FF)，将当前位置移到下页开头        | 012                     |<br>| <strong>\n</strong>       | <strong>换行(LF) ，将当前位置移到下一行开头</strong> | <strong>010</strong>                 |<br>| \r           | 回车(CR) ，将当前位置移到本行开头       | 013                     |<br>| <strong>\t</strong>       | <strong>水平制表(HT)  （跳到下一个TAB位置）</strong> | <strong>009</strong>                 |<br>| \v           | 垂直制表(VT)                            | 011                     |<br>| <strong>\\</strong>     | <strong>代表一个反斜线字符”\”</strong>               | <strong>092</strong>                 |<br>| \’           | 代表一个单引号（撇号）字符              | 039                     |<br>| \”           | 代表一个双引号字符                      | 034                     |<br>| \?           | 代表一个问号                            | 063                     |<br>| \0           | 数字0                                   | 000                     |<br>| \ddd         | 8进制转义字符，d范围0~7                 | 3位8进制                |<br>| \xhh         | 16进制转义字符，h范围0~9，a~f，A~F      | 3位16进制               |</p></li></ul></li><li><h5 id="字符串型"><a href="#字符串型" class="headerlink" title="字符串型"></a>字符串型</h5><ul><li><p>作用：用于表示一串字符</p></li><li><p>两种风格：</p><ol><li>C风格字符串：<code>char 变量名[] = &quot;字符串值&quot;</code></li><li>C++风格字符串：<code>string 变量名 = “字符串”</code></li></ol></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;  // 新版vs自动包含了一些头文件</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// C++风格字符串 注意事项：双引号</span></span><br><span class="line"><span class="built_in">string</span> xlz = <span class="string">"小廖子"</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"我的名字是："</span> &lt;&lt; xlz &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="布尔类型-bool"><a href="#布尔类型-bool" class="headerlink" title="布尔类型 bool"></a>布尔类型 bool</h5><ul><li><p>作用：布尔数据类型代表真或假的值 </p></li><li><p>表达方式：bool类型只有两个值：</p><ul><li>true  —- 真（本质是1）</li><li>false —- 假（本质是0）</li></ul></li><li><p>注意：bool类型占==1个字节==大小</p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 创建bool类型</span></span><br><span class="line"><span class="keyword">bool</span> flag = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; flag &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 1</span></span><br><span class="line">flag = <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; flag &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看bool类型所占内存空间  1</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"bool 类型所占的内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">bool</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="数据的输入"><a href="#数据的输入" class="headerlink" title="数据的输入"></a>数据的输入</h5><ul><li><p>作用：用于从键盘获取数据</p></li><li><p>关键字：<strong>cin</strong></p></li><li><p>语法：<code>cin &gt;&gt; 变量</code></p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 数据输入</span></span><br><span class="line"><span class="comment">// 1.整型</span></span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请给整型变量a赋值："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; a;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"整型变量a的值为："</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.浮点型</span></span><br><span class="line"><span class="keyword">float</span> b = <span class="number">0.01</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"请给浮点型变量b赋值："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="built_in">cin</span> &gt;&gt; b;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"浮点型变量b的值为："</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">     <span class="comment">// 其它都类似</span></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="2-运算符"><a href="#2-运算符" class="headerlink" title="2.运算符"></a>2.运算符</h4><p><strong>作用：</strong>用于执行代码的运算</p><p>本章我们主要讲解以下几类运算符：</p><div class="table-container"><table><thead><tr><th><strong>运算符类型</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>算术运算符</td><td>用于处理四则运算</td></tr><tr><td>赋值运算符</td><td>用于将表达式的值赋给变量</td></tr><tr><td>比较运算符</td><td>用于表达式的比较，并返回一个真值或假值</td></tr><tr><td>逻辑运算符</td><td>用于根据表达式的值返回真值或假值</td></tr></tbody></table></div><ol><li><h5 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h5><ul><li><p>作用：用于处理四则运算 </p></li><li><p>罗列：注意：<strong>两个整数相除，结果依然是整数，将小数部分去除，10/20结果为0；两个小数可以相除，运算结果可以是小数。</strong></p><p>| 运算符<strong> | </strong>术语<strong>   | </strong>示例<strong>    | </strong>结果<em>*  |<br>| ———— | ————— | —————- | ————- |<br>| +        | 正号       | +3          | 3         |<br>| -        | 负号       | -3          | -3        |<br>| +        | 加         | 10 + 5      | 15        |<br>| -        | 减         | 10 - 5      | 5         |<br>| </em>        | 乘         | 10 * 5      | 50        |<br>| /        | 除         | 10 / 5      | 2         |<br>| %        | 取模(取余) | 10 % 3      | 1         |<br>| ++       | 前置递增   | a=2; b=++a; | a=3; b=3; |<br>| ++       | 后置递增   | a=2; b=a++; | a=3; b=2; |<br>| —       | 前置递减   | a=2; b=—a; | a=1; b=1; |<br>| —       | 后置递减   | a=2; b=a—; | a=1; b=2; |</p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 前置递增</span></span><br><span class="line"><span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line">++a;   <span class="comment">// 让变量加1</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a =  "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.后置递增</span></span><br><span class="line"><span class="keyword">int</span> b = <span class="number">10</span>;</span><br><span class="line">b++;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"b = "</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前置递增和后置递增的区别</span></span><br><span class="line"><span class="comment">// 前置递增 先让变量+1 后进行表达是运算</span></span><br><span class="line"><span class="keyword">int</span> a2 = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> b2 = ++a2 * <span class="number">10</span>; </span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a2 = "</span> &lt;&lt; a2 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 11</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"b2 = "</span> &lt;&lt; b2 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 110</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 后置递增 先进行表达是运算 后让变量+1</span></span><br><span class="line"><span class="keyword">int</span> a3 = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> b3 = a3++ * <span class="number">10</span>; </span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a3 = "</span> &lt;&lt; a3 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 11</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"b3 = "</span> &lt;&lt; b3 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 100</span></span><br><span class="line"></span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><h5 id="赋值运算符"><a href="#赋值运算符" class="headerlink" title="赋值运算符"></a>赋值运算符</h5><ul><li><p>作用：用于将表达式的值赋给变量</p></li><li><p>罗列：</p><p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong>   | <strong>结果</strong>  |<br>| ————— | ———— | ————— | ————- |<br>| =          | 赋值     | a=2; b=3;  | a=2; b=3; |<br>| +=         | 加等于   | a=0; a+=2; | a=2;      |<br>| -=         | 减等于   | a=5; a-=3; | a=2;      |<br>| <em>=         | 乘等于   | a=2; a</em>=2; | a=4;      |<br>| /=         | 除等于   | a=4; a/=2; | a=2;      |<br>| %=         | 模等于   | a=3; a%2;  | a=1;      |</p></li></ul></li><li><h5 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h5><ul><li><p>作用：用于表达式的比较，并返回一个真值或假值</p></li><li><p>罗列：注意：C和C++ 语言的比较运算中， ==“真”用数字“1”来表示， “假”用数字“0”来表示。== </p><p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong> | <strong>结果</strong> |<br>| ————— | ———— | ———— | ———— |<br>| ==         | 相等于   | 4 == 3   | 0        |<br>| !=         | 不等于   | 4 != 3   | 1        |<br>| &lt;          | 小于     | 4 &lt; 3    | 0        |<br>| >         | 大于     | 4 &gt; 3    | 1        |<br>| &lt;=         | 小于等于 | 4 &lt;= 3   | 0        |<br>| >=        | 大于等于 | 4 &gt;= 1   | 1        |</p></li></ul></li><li><h5 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h5><ul><li><p>作用：用于根据表达式的值返回真值或假值</p></li><li><p>罗列：</p><p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong> | <strong>结果</strong>                                                 |<br>| ————— | ———— | ———— | ———————————————————————————— |<br>| !          | 非       | !a       | 如果a为假，则!a为真；  如果a为真，则!a为假。             |<br>| &amp;&amp;         | 与       | a &amp;&amp; b   | 如果a和b都为真，则结果为真，否则为假。                   |<br>| ||       | 或       | a || b | 如果a和b有一个为真，则结果为真，二者都为假时，结果为假。 |</p></li></ul></li></ol><h4 id="3-扩展"><a href="#3-扩展" class="headerlink" title="3.扩展"></a>3.扩展</h4><p><strong>ASCII码表格：</strong></p><div class="table-container"><table><thead><tr><th><strong>ASCII</strong>值</th><th><strong>控制字符</strong></th><th><strong>ASCII</strong>值</th><th><strong>字符</strong></th><th><strong>ASCII</strong>值</th><th><strong>字符</strong></th><th><strong>ASCII</strong>值</th><th><strong>字符</strong></th></tr></thead><tbody><tr><td>0</td><td>NUT</td><td>32</td><td>(space)</td><td>64</td><td>@</td><td>96</td><td>、</td></tr><tr><td>1</td><td>SOH</td><td>33</td><td>!</td><td>65</td><td>A</td><td>97</td><td>a</td></tr><tr><td>2</td><td>STX</td><td>34</td><td>“</td><td>66</td><td>B</td><td>98</td><td>b</td></tr><tr><td>3</td><td>ETX</td><td>35</td><td>#</td><td>67</td><td>C</td><td>99</td><td>c</td></tr><tr><td>4</td><td>EOT</td><td>36</td><td>$</td><td>68</td><td>D</td><td>100</td><td>d</td></tr><tr><td>5</td><td>ENQ</td><td>37</td><td>%</td><td>69</td><td>E</td><td>101</td><td>e</td></tr><tr><td>6</td><td>ACK</td><td>38</td><td>&amp;</td><td>70</td><td>F</td><td>102</td><td>f</td></tr><tr><td>7</td><td>BEL</td><td>39</td><td>,</td><td>71</td><td>G</td><td>103</td><td>g</td></tr><tr><td>8</td><td>BS</td><td>40</td><td>(</td><td>72</td><td>H</td><td>104</td><td>h</td></tr><tr><td>9</td><td>HT</td><td>41</td><td>)</td><td>73</td><td>I</td><td>105</td><td>i</td></tr><tr><td>10</td><td>LF</td><td>42</td><td>*</td><td>74</td><td>J</td><td>106</td><td>j</td></tr><tr><td>11</td><td>VT</td><td>43</td><td>+</td><td>75</td><td>K</td><td>107</td><td>k</td></tr><tr><td>12</td><td>FF</td><td>44</td><td>,</td><td>76</td><td>L</td><td>108</td><td>l</td></tr><tr><td>13</td><td>CR</td><td>45</td><td>-</td><td>77</td><td>M</td><td>109</td><td>m</td></tr><tr><td>14</td><td>SO</td><td>46</td><td>.</td><td>78</td><td>N</td><td>110</td><td>n</td></tr><tr><td>15</td><td>SI</td><td>47</td><td>/</td><td>79</td><td>O</td><td>111</td><td>o</td></tr><tr><td>16</td><td>DLE</td><td>48</td><td>0</td><td>80</td><td>P</td><td>112</td><td>p</td></tr><tr><td>17</td><td>DCI</td><td>49</td><td>1</td><td>81</td><td>Q</td><td>113</td><td>q</td></tr><tr><td>18</td><td>DC2</td><td>50</td><td>2</td><td>82</td><td>R</td><td>114</td><td>r</td></tr><tr><td>19</td><td>DC3</td><td>51</td><td>3</td><td>83</td><td>S</td><td>115</td><td>s</td></tr><tr><td>20</td><td>DC4</td><td>52</td><td>4</td><td>84</td><td>T</td><td>116</td><td>t</td></tr><tr><td>21</td><td>NAK</td><td>53</td><td>5</td><td>85</td><td>U</td><td>117</td><td>u</td></tr><tr><td>22</td><td>SYN</td><td>54</td><td>6</td><td>86</td><td>V</td><td>118</td><td>v</td></tr><tr><td>23</td><td>TB</td><td>55</td><td>7</td><td>87</td><td>W</td><td>119</td><td>w</td></tr><tr><td>24</td><td>CAN</td><td>56</td><td>8</td><td>88</td><td>X</td><td>120</td><td>x</td></tr><tr><td>25</td><td>EM</td><td>57</td><td>9</td><td>89</td><td>Y</td><td>121</td><td>y</td></tr><tr><td>26</td><td>SUB</td><td>58</td><td>:</td><td>90</td><td>Z</td><td>122</td><td>z</td></tr><tr><td>27</td><td>ESC</td><td>59</td><td>;</td><td>91</td><td>[</td><td>123</td><td>{</td></tr><tr><td>28</td><td>FS</td><td>60</td><td>&lt;</td><td>92</td><td>/</td><td>124</td><td>\</td><td></td></tr><tr><td>29</td><td>GS</td><td>61</td><td>=</td><td>93</td><td>]</td><td>125</td><td>}</td></tr><tr><td>30</td><td>RS</td><td>62</td><td>&gt;</td><td>94</td><td>^</td><td>126</td><td>`</td></tr><tr><td>31</td><td>US</td><td>63</td><td>?</td><td>95</td><td>_</td><td>127</td><td>DEL</td></tr></tbody></table></div><p>ASCII 码大致由以下<strong>两部分组</strong>成：</p><ul><li>ASCII 非打印控制字符： ASCII 表上的数字 <strong>0-31</strong> 分配给了控制字符，用于控制像打印机等一些外围设备。</li><li>ASCII 打印字符：数字 <strong>32-126</strong> 分配给了能在键盘上找到的字符，当查看或打印文档时就会出现。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-30天学习打卡（二）&quot;&gt;&lt;a href=&quot;#C-30天学习打卡（二）&quot; class=&quot;headerlink&quot; title=&quot;C++30天学习打卡（二）&quot;&gt;&lt;/a&gt;C++30天学习打卡（二）&lt;/h3&gt;&lt;h4 id=&quot;1-数据类型&quot;&gt;&lt;a href=&quot;#1-数据类型&quot; class=&quot;headerlink&quot; title=&quot;1.数据类型&quot;&gt;&lt;/a&gt;1.数据类型&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;C++规定在创建一个变量或者常量时，必须要指定出相应的数据类型，否则无法给变量分配内存。&lt;/p&gt;
&lt;p&gt;数据类型存在的意义：给变量分配合适的内存空间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;h5 id=&quot;整型&quot;&gt;&lt;a href=&quot;#整型&quot; class=&quot;headerlink&quot; title=&quot;整型&quot;&gt;&lt;/a&gt;整型&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;作用：整型变量表示的是&lt;strong&gt;整数类型&lt;/strong&gt;的数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分类：C++中能够表示整型的类型有以下几种方式，&lt;strong&gt;区别在于所占内存空间不同&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200531124009.png&quot;/&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="C++30天学习打卡" scheme="https://xiaoliaozi.com/categories/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1/"/>
    
    
      <category term="C++" scheme="https://xiaoliaozi.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++30天学习打卡（一）</title>
    <link href="https://xiaoliaozi.com/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://xiaoliaozi.com/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2020-05-30T13:04:43.000Z</published>
    <updated>2020-05-30T13:11:19.981Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-30天学习打卡（一）"><a href="#C-30天学习打卡（一）" class="headerlink" title="C++30天学习打卡（一）"></a>C++30天学习打卡（一）</h3><h4 id="1-注释"><a href="#1-注释" class="headerlink" title="1.注释"></a>1.注释</h4><blockquote><ol><li>单行注释：//  描述信息</li><li>多行注释：/<em> 注释信息 </em>/</li></ol></blockquote><h4 id="2-变量"><a href="#2-变量" class="headerlink" title="2.变量"></a>2.变量</h4><ol><li><p>作用：给一段指定的内存空间起名，方便操作这段内存。</p></li><li><p>语法：数据类型   变量名 = 初始值；</p></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 注意：C++在创建变量时，必须给变量一个初始值，否则会报错</span></span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><h4 id="3-常量"><a href="#3-常量" class="headerlink" title="3.常量"></a>3.常量</h4><ol><li><p>作用：用于记录不可更改的数据；</p></li><li><p>定义常量的两种方式：</p><blockquote><ol><li>#define 宏常量：#define  常量名  常量值<ul><li>== 通常在文件上方定义==，表示一个常量</li></ul></li><li>const 修饰的变量：const 数据类型  变量名 = 常量值<ul><li>==通常在变量定义前加关键字const==，修饰该变量为常量，不可修改</li></ul></li></ol></blockquote></li><li><p>示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> day 7</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 常量定义</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"一周共有 "</span> &lt;&lt; day &lt;&lt; <span class="string">" 天"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> month = <span class="number">12</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">"一年有几个 "</span> &lt;&lt; month &lt;&lt; <span class="string">" 月"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">system(<span class="string">"pause"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="4-关键字"><a href="#4-关键字" class="headerlink" title="4.关键字"></a>4.关键字</h4><ol><li><p>作用：关键字是C++中预先保留的单词（标识符）</p></li><li><p>注意：在定义变量或者常量时候，不要用关键字，否则会产生歧义</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200530204651.png"/></p></li></ol><h4 id="5-标识符命名规则"><a href="#5-标识符命名规则" class="headerlink" title="5.标识符命名规则"></a>5.标识符命名规则</h4><ol><li><p>作用：C++规定给标识符（变量、常量）命名时，有一套自己的规则；</p></li><li><p>注意事项：</p><blockquote><ul><li>标识符不能是关键字</li><li>标识符只能由字母、数字、下划线组成</li><li>第一个字符必须为字母或下划线</li><li>标识符中字母区分大小写</li></ul></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-30天学习打卡（一）&quot;&gt;&lt;a href=&quot;#C-30天学习打卡（一）&quot; class=&quot;headerlink&quot; title=&quot;C++30天学习打卡（一）&quot;&gt;&lt;/a&gt;C++30天学习打卡（一）&lt;/h3&gt;&lt;h4 id=&quot;1-注释&quot;&gt;&lt;a href=&quot;#1-注释&quot; class=&quot;headerlink&quot; title=&quot;1.注释&quot;&gt;&lt;/a&gt;1.注释&lt;/h4&gt;&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;单行注释：//  描述信息&lt;/li&gt;
&lt;li&gt;多行注释：/&lt;em&gt; 注释信息 &lt;/em&gt;/&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;2-变量&quot;&gt;&lt;a href=&quot;#2-变量&quot; class=&quot;headerlink&quot; title=&quot;2.变量&quot;&gt;&lt;/a&gt;2.变量&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;作用：给一段指定的内存空间起名，方便操作这段内存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;语法：数据类型   变量名 = 初始值；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;示例：&lt;/p&gt;
&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;meta-string&quot;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; a = &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;string&quot;&gt;&quot;a = &quot;&lt;/span&gt; &amp;lt;&amp;lt; a &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	system(&lt;span class=&quot;string&quot;&gt;&quot;pause&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 注意：C++在创建变量时，必须给变量一个初始值，否则会报错&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="C++30天学习打卡" scheme="https://xiaoliaozi.com/categories/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1/"/>
    
    
      <category term="C++" scheme="https://xiaoliaozi.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>关于Hive</title>
    <link href="https://xiaoliaozi.com/2020/02/13/%E5%85%B3%E4%BA%8EHive/"/>
    <id>https://xiaoliaozi.com/2020/02/13/%E5%85%B3%E4%BA%8EHive/</id>
    <published>2020-02-13T07:03:26.000Z</published>
    <updated>2020-02-28T12:05:46.006Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h4><h5 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h5><ul><li>Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能，底层数据是存储在 HDFS 上。</li><li>Hive 本质: 将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，<strong>是一款基于HDFS 的 MapReduce 计算框架</strong></li><li>主要用途：用来做离线数据分析，比直接用 MapReduce 开发效率更高。</li></ul><a id="more"></a><h5 id="为什么使用Hive"><a href="#为什么使用Hive" class="headerlink" title="为什么使用Hive"></a>为什么使用Hive</h5><ul><li>直接使用 Hadoop MapReduce 处理数据所面临的问题：<ul><li>人员学习成本太高</li><li>MapReduce 实现复杂查询逻辑开发难度太大</li></ul></li><li>使用 Hive<ul><li>操作接口采用类 SQL 语法，提供快速开发的能力</li><li>避免了去写 MapReduce，减少开发人员的学习成本</li><li>功能扩展很方便</li></ul></li></ul><h4 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h4><h5 id="Hive-架构图"><a href="#Hive-架构图" class="headerlink" title="Hive 架构图"></a>Hive 架构图</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200221213219.jpg"/></p><h5 id="Hive-组件"><a href="#Hive-组件" class="headerlink" title="Hive 组件"></a>Hive 组件</h5><ul><li>用户接口：包括 CLI、JDBC/ODBC、WebGUI。<ul><li>CLI(command line interface)为 shell 命令行</li><li>JDBC/ODBC 是 Hive 的 JAVA 实现，与传统数据库JDBC 类似</li><li>WebGUI 是通过浏览器访问 Hive。</li><li>HiveServer2基于Thrift，允许远程客户端使用多种编程语言如Java、Python向Hive提交请求</li></ul></li><li>元数据存储：通常是存储在关系数据库如 mysql/derby 中。<ul><li>Hive 将元数据存储在数据库中。</li><li>Hive 中的元数据包括<ul><li>表的名字</li><li>表的列</li><li>分区及其属性</li><li>表的属性（是否为外部表等）</li><li>表的数据所在目录等。</li></ul></li></ul></li><li>解释器、编译器、优化器、执行器：完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行</li></ul><h5 id="Hive与Hadoop的关系"><a href="#Hive与Hadoop的关系" class="headerlink" title="Hive与Hadoop的关系"></a>Hive与Hadoop的关系</h5><ul><li>Hive 利用 HDFS 存储数据，利用 MapReduce 查询分析数据。</li><li>Hive是数据仓库工具，没有集群的概念，</li><li>如果想提交Hive作业只需要在hadoop集群 Master节点上装Hive就可以了</li></ul><h4 id="Hive与传统数据库对比"><a href="#Hive与传统数据库对比" class="headerlink" title="Hive与传统数据库对比"></a>Hive与传统数据库对比</h4><ul><li>hive 用于海量数据的离线数据分析 </li></ul><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Hive</th><th style="text-align:center">关系型数据库</th></tr></thead><tbody><tr><td style="text-align:center">ANSI SQL</td><td style="text-align:center">不完全支持</td><td style="text-align:center">支持</td></tr><tr><td style="text-align:center">更新</td><td style="text-align:center">INSERT OVERWRITE\INTO TABLE(默认)</td><td style="text-align:center">UPDATE\INSERT\DELETE</td></tr><tr><td style="text-align:center">事务</td><td style="text-align:center">不支持(默认)</td><td style="text-align:center">支持</td></tr><tr><td style="text-align:center">模式</td><td style="text-align:center">读模式</td><td style="text-align:center">写模式</td></tr><tr><td style="text-align:center">查询语言</td><td style="text-align:center">HQL</td><td style="text-align:center">SQL</td></tr><tr><td style="text-align:center">数据存储</td><td style="text-align:center">HDFS</td><td style="text-align:center">Raw Device or Local FS</td></tr><tr><td style="text-align:center">执行</td><td style="text-align:center">MapReduce</td><td style="text-align:center">Executor</td></tr><tr><td style="text-align:center">执行延迟</td><td style="text-align:center">高</td><td style="text-align:center">低</td></tr><tr><td style="text-align:center">子查询</td><td style="text-align:center">只能用在From子句中</td><td style="text-align:center">完全支持</td></tr><tr><td style="text-align:center">处理数据规模</td><td style="text-align:center">大</td><td style="text-align:center">小</td></tr><tr><td style="text-align:center">可扩展性</td><td style="text-align:center">高</td><td style="text-align:center">低</td></tr><tr><td style="text-align:center">索引</td><td style="text-align:center">0.8版本后加入位图索引</td><td style="text-align:center">有复杂的索引</td></tr></tbody></table></div><ul><li>hive支持的数据类型<ul><li>原子数据类型<ul><li>TINYINT SMALLINT INT BIGINT BOOLEAN FLOAT DOUBLE STRING BINARY TIMESTAMP DECIMAL CHAR VARCHAR DATE</li></ul></li><li>复杂数据类型<ul><li>ARRAY  MAP  STRUCT</li></ul></li></ul></li><li>hive中表的类型<ul><li>托管表 (managed table) (内部表)</li><li>外部表</li></ul></li></ul><h4 id="Hive-数据模型"><a href="#Hive-数据模型" class="headerlink" title="Hive 数据模型"></a>Hive 数据模型</h4><ul><li>Hive 中所有的数据都存储在 HDFS 中，没有专门的数据存储格式</li><li>在创建表时指定数据中的分隔符，Hive 就可以映射成功，解析数据。</li><li>Hive 中包含以下数据模型：<ul><li>db：在 hdfs 中表现为 hive.metastore.warehouse.dir 目录下一个文件夹</li><li>table：在 hdfs 中表现所属 db 目录下一个文件夹</li><li>external table：数据存放位置可以在 HDFS 任意指定路径</li><li>partition：在 hdfs 中表现为 table 目录下的子目录</li><li>bucket：在 hdfs 中表现为同一个表目录下根据 hash 散列之后的多个文件</li></ul></li></ul><h4 id="Hive安装部署"><a href="#Hive安装部署" class="headerlink" title="Hive安装部署"></a>Hive安装部署</h4><ul><li><p>Hive 安装前需要安装好 JDK 和 Hadoop。配置好环境变量。 </p></li><li><p>下载Hive的安装包 <a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a> 并解压 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz  -C ~/app/</span><br></pre></td></tr></table></figure></li><li><p>进入到 解压后的hive目录 找到 conf目录, 修改配置文件 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">vi hive-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在hive-env.sh中指定hadoop的路径</span></span><br><span class="line">HADOOP_HOME=/root/bigdata/hadoop</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line"></span><br><span class="line">export HIVE_HOME=/root/bigdata/hive</span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></li><li><p>根据元数据存储的介质不同，分为下面两个版本，其中 derby 属于内嵌模式。实际生产环境中则使用 mysql 来进行元数据的存储。</p><ul><li><p>内置 derby 版： bin/hive 启动即可使用 缺点：不同路径启动 hive，每一个 hive 拥有一套自己的元数据，无法共享 </p></li><li><p>mysql 版 </p><ul><li>上传 mysql驱动到 hive安装目录的lib目录下   mysql-connector-java-5.*.jar </li><li>vi conf/hive-site.xml 配置 Mysql 元数据库信息(MySql安装见文档) </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 插入以下代码 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;&lt;!-- 指定mysql用户名 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;password&lt;/value&gt;&lt;!-- 指定mysql密码 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;mysql</span><br><span class="line">        &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;&lt;!-- 指定mysql数据库地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;!-- 指定mysql驱动 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;!-- 到此结束代码 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.script.wrapper&lt;/name&gt;</span><br><span class="line">    &lt;value/&gt;</span><br><span class="line">    &lt;description/&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>hive启动 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动docker</span></span><br><span class="line">service docker start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过docker 启动mysql</span></span><br><span class="line">docker start mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 hive的metastore元数据服务</span></span><br><span class="line">hive --service metastore</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动hive</span></span><br><span class="line">hive</span><br></pre></td></tr></table></figure></li></ul><h4 id="Hive基本操作"><a href="#Hive基本操作" class="headerlink" title="Hive基本操作"></a>Hive基本操作</h4><ul><li><p>创建数据库 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure></li><li><p>显示所有数据库 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">DATABASES</span>;</span><br></pre></td></tr></table></figure></li><li><p>创建表 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(classNo <span class="keyword">string</span>, stuNo <span class="keyword">string</span>, score <span class="built_in">int</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure><ul><li>row format delimited fields terminated by ‘,’ 指定了字段的分隔符为逗号</li><li>所以load数据的时候，load的文本也要为逗号，否则加载后为NULL。</li><li>hive只支持单个字符的分隔符，hive默认的分隔符是\001 </li></ul></li><li><p>将数据load到表中 </p><ul><li>在本地文件系统创建一个如下的文本文件：/home/hadoop/tmp/student.txt </li></ul><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr"># 数据</span></span><br><span class="line"><span class="attr">C01</span>,<span class="symbol">N0101</span>,<span class="number">82</span></span><br><span class="line">C<span class="number">01</span>,<span class="symbol">N0102</span>,<span class="number">59</span></span><br><span class="line">C<span class="number">01</span>,<span class="symbol">N0103</span>,<span class="number">65</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0201</span>,<span class="number">81</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0202</span>,<span class="number">82</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0203</span>,<span class="number">79</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0301</span>,<span class="number">56</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0302</span>,<span class="number">92</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0306</span>,<span class="number">72</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/tmp/student.txt'</span>overwrite <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure><ul><li>这个命令将student.txt文件复制到hive的warehouse目录中</li><li>这个目录由hive.metastore.warehouse.dir配置项设置，默认值为/user/hive/warehouse。</li><li>Overwrite选项将导致Hive事先删除student目录下所有的文件，并将文件内容映射到表中。</li><li>Hive不会对student.txt做任何格式处理，因为Hive本身并不强调数据的存储格式。 </li></ul></li><li><p>查询表中的数据 跟SQL类似 </p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;select * from student;</span><br></pre></td></tr></table></figure></li><li><p>分组查询group by和统计 count </p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;select classNo,count(score) from student where score&gt;=60 group by classNo;</span><br></pre></td></tr></table></figure></li></ul><h4 id="Hive的内部表和外部表"><a href="#Hive的内部表和外部表" class="headerlink" title="Hive的内部表和外部表"></a>Hive的内部表和外部表</h4><div class="table-container"><table><thead><tr><th></th><th>内部表(managed table)</th><th>外部表(external table)</th></tr></thead><tbody><tr><td>概念</td><td>创建表时无external修饰</td><td>创建表时被external修饰</td></tr><tr><td>数据管理</td><td>由Hive自身管理</td><td>由HDFS管理</td></tr><tr><td>数据保存位置</td><td>hive.metastore.warehouse.dir （默认：/user/hive/warehouse）</td><td>hdfs中任意位置</td></tr><tr><td>删除时影响</td><td>直接删除元数据（metadata）及存储数据</td><td>仅会删除元数据，HDFS上的文件并不会被删除</td></tr><tr><td>表结构修改时影响</td><td>修改会将修改直接同步给元数据</td><td>表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）</td></tr></tbody></table></div><p><strong>小案例</strong></p><ul><li><p>创建一个外部表student2 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建外部表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> student2 (classNo <span class="keyword">string</span>, stuNo <span class="keyword">string</span>, score <span class="built_in">int</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span> location <span class="string">'/tmp/student'</span>;</span><br><span class="line"><span class="comment"># 装载数据</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/tmp/student.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> student2;</span><br></pre></td></tr></table></figure></li><li><p>显示表信息 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted table_name;</span><br></pre></td></tr></table></figure></li><li><p>删除表查看结果 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure></li><li><p>再次创建外部表 student2 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不插入数据直接查询查看结果</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> student2;</span><br><span class="line"><span class="comment"># 能查到数据吗？能</span></span><br><span class="line"><span class="comment"># 外部表只删除元数据，不会删除储存数据</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="Hive分区表"><a href="#Hive分区表" class="headerlink" title="Hive分区表"></a>Hive分区表</h4><ul><li><p>什么是分区表 </p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>随着表的不断增大，对于新纪录的增加，查找，删除等(DML)的维护也更加困难。对于数据库中的超大型表，可以通过把它的数据分成若干个小表，从而简化数据库的管理活动，对于每一个简化后的小表，我们称为一个单个的分区。</span><br><span class="line"><span class="number">2.</span>hive中分区表实际就是对应hdfs文件系统上独立的文件夹，该文件夹内的文件是该分区所有数据文件。</span><br><span class="line"><span class="number">3.</span>分区可以理解为分类，通过分类把不同类型的数据放到不同的目录下。</span><br><span class="line"><span class="number">4.</span>分类的标准就是分区字段，可以一个，也可以多个。</span><br><span class="line"><span class="number">5.</span>分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</span><br></pre></td></tr></table></figure></li><li><p>创建分区表</p></li></ul><ul><li><p>查看表的分区</p></li><li><p>添加分区</p></li><li><p>加载数据到分区</p></li><li><p>如果重复加载同名文件，不会报错，会自动创建一个*_copy_1.txt </p></li><li><p>外部分区表即使有分区的目录结构, 也必须要通过hql添加分区, 才能看到相应的数据 </p></li></ul><p><strong>总结</strong></p><blockquote><p>利用分区表方式减少查询时需要扫描的数据量</p><ul><li>分区字段不是表中的列, 数据文件中没有对应的列</li><li>分区仅仅是一个目录名</li><li>查看数据时, hive会自动添加分区列</li><li>支持多级分区, 多级子目录</li></ul></blockquote><h4 id="Hive动态分区"><a href="#Hive动态分区" class="headerlink" title="Hive动态分区"></a>Hive动态分区</h4><ul><li>在写入数据时自动创建分区(包括目录结构)</li><li>创建表 </li><li>导入数据</li><li>使用动态分区需要设置参数</li></ul><h4 id="Hive函数"><a href="#Hive函数" class="headerlink" title="Hive函数"></a>Hive函数</h4><h5 id="内置运算符"><a href="#内置运算符" class="headerlink" title="内置运算符"></a>内置运算符</h5><h5 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h5><h5 id="Hive-自定义函数和-Transform"><a href="#Hive-自定义函数和-Transform" class="headerlink" title="Hive 自定义函数和 Transform"></a>Hive 自定义函数和 Transform</h5><h4 id="Hive综合案例"><a href="#Hive综合案例" class="headerlink" title="Hive综合案例"></a>Hive综合案例</h4><h4 id="拓展-ANSI-SQL"><a href="#拓展-ANSI-SQL" class="headerlink" title="拓展-ANSI SQL"></a>拓展-ANSI SQL</h4><p>了解一下即可，一般做ORM的需要深入学习，对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。 </p><ul><li><p>ANSI：美国国家标准化组织，是一个核准多种行业标准的组织。</p></li><li><p>SQL</p><ul><li>结构化查询语言</li><li>是与关系型数据库进行通信的标准语言</li><li>最初由IBM公司的E.F.Codd博士论文为原型开发出来的。</li></ul></li><li><p>ANSI SQL：国际标准SQL语法</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Hive简介&quot;&gt;&lt;a href=&quot;#Hive简介&quot; class=&quot;headerlink&quot; title=&quot;Hive简介&quot;&gt;&lt;/a&gt;Hive简介&lt;/h4&gt;&lt;h5 id=&quot;什么是Hive&quot;&gt;&lt;a href=&quot;#什么是Hive&quot; class=&quot;headerlink&quot; title=&quot;什么是Hive&quot;&gt;&lt;/a&gt;什么是Hive&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能，底层数据是存储在 HDFS 上。&lt;/li&gt;
&lt;li&gt;Hive 本质: 将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，&lt;strong&gt;是一款基于HDFS 的 MapReduce 计算框架&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;主要用途：用来做离线数据分析，比直接用 MapReduce 开发效率更高。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Hive" scheme="https://xiaoliaozi.com/tags/Hive/"/>
    
      <category term="Hive架构" scheme="https://xiaoliaozi.com/tags/Hive%E6%9E%B6%E6%9E%84/"/>
    
      <category term="Hive与Hadoop的关系" scheme="https://xiaoliaozi.com/tags/Hive%E4%B8%8EHadoop%E7%9A%84%E5%85%B3%E7%B3%BB/"/>
    
      <category term="Hive与传统数据库对比" scheme="https://xiaoliaozi.com/tags/Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E6%AF%94/"/>
    
      <category term="Hive基本操作" scheme="https://xiaoliaozi.com/tags/Hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    
      <category term="Hive函数" scheme="https://xiaoliaozi.com/tags/Hive%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>HADOOP概念扩展</title>
    <link href="https://xiaoliaozi.com/2020/02/12/HADOOP%E6%A6%82%E5%BF%B5%E6%89%A9%E5%B1%95/"/>
    <id>https://xiaoliaozi.com/2020/02/12/HADOOP%E6%A6%82%E5%BF%B5%E6%89%A9%E5%B1%95/</id>
    <published>2020-02-12T01:45:09.000Z</published>
    <updated>2020-02-27T12:37:53.482Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h4><h5 id="狭义的Hadoop-VS-广义的Hadoop"><a href="#狭义的Hadoop-VS-广义的Hadoop" class="headerlink" title="狭义的Hadoop VS 广义的Hadoop"></a>狭义的Hadoop VS 广义的Hadoop</h5><p> 广义的Hadoop：指的是Hadoop生态系统，Hadoop生态系统是一个很庞大的概念，hadoop是其中最重要最基础的一个部分，生态系统中每一子系统只解决某一个特定的问题域（甚至可能更窄），不搞统一型的全能系统，而是小而精的多个小系统。</p><a id="more"></a><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203527.png"/> </p><ul><li>Hive：数据仓库</li><li>R：数据分析</li><li>Mahout：机器学习库</li><li>pig：脚本语言，跟Hive类似</li><li>Oozie：工作流引擎，管理作业执行顺序</li><li>Zookeeper：用户无感知，主节点挂掉选择从节点作为主的</li><li>Flume：日志收集框架</li><li>Sqoop：数据交换框架，例如：关系型数据库与HDFS之间的数据交换</li><li>Hbase : 海量数据中的查询，相当于分布式文件系统中的数据库</li><li><p>Spark: 分布式的计算框架基于内存</p><ul><li>spark core</li><li>spark sql</li><li>spark streaming 准实时 不算是一个标准的流式计算</li><li>spark ML spark MLlib</li></ul></li><li><p>Kafka: 消息队列</p></li><li>Storm: 分布式的流式计算框架 python操作storm</li><li>Flink: 分布式的流式计算框架</li></ul><h5 id="Hadoop生态系统的特点"><a href="#Hadoop生态系统的特点" class="headerlink" title="Hadoop生态系统的特点"></a><strong>Hadoop生态系统的特点</strong></h5><ul><li>开源、社区活跃</li><li>囊括了大数据处理的方方面面</li><li>成熟的生态圈</li></ul><h4 id="HDFS-读写流程-amp-高可用"><a href="#HDFS-读写流程-amp-高可用" class="headerlink" title="HDFS 读写流程&amp; 高可用"></a>HDFS 读写流程&amp; 高可用</h4><h5 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203608.jpg"/> </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203557.jpg"/> </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203543.jpg"/> </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203536.jpg"/> </p><ul><li>客户端向NameNode发出写文件请求。 </li><li>检查是否已存在文件、检查权限。若通过检查，直接先将操作写入EditLog，并返回输出流对象。 （注：WAL，write ahead log，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）</li><li>client端按128MB的块切分文件。</li><li>client将NameNode返回的分配的可写的DataNode列表和Data数据一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。 （注：并不是写好一个块或一整个文件后才向后分发）</li><li>每个DataNode写完一个块后，会返回确认信息。 （注：并不是每写完一个packet后就返回确认信息，个人觉得因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）</li><li>写完数据，关闭输输出流。</li><li>发送完成信号给NameNode。（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）。</li></ul><h5 id="HDFS如何实现高可用-HA"><a href="#HDFS如何实现高可用-HA" class="headerlink" title="HDFS如何实现高可用(HA)"></a>HDFS如何实现高可用(HA)</h5><ul><li><strong>数据存储故障容错</strong> <ul><li>磁盘介质在存储过程中受环境或者老化影响，数据可能错乱</li><li>对于存储在 DataNode 上的数据块，计算并存储校验和（CheckSum)</li><li>读取数据的时候，重新计算读取出来的数据校验和， 校验不正确抛出异常，从其它DataNode上读取备份数据</li></ul></li><li><strong>磁盘故障容错</strong><ul><li>DataNode 监测到本机的某块磁盘损坏</li><li>将该块磁盘上存储的所有 BlockID 报告给 NameNode</li><li>NameNode 检查这些数据块在哪些DataNode上有备份,</li><li>通知相应DataNode, 将数据复制到其他服务器上</li></ul></li><li><strong>DataNode故障容错</strong><ul><li>通过心跳和NameNode保持通讯</li><li>超时未发送心跳， NameNode会认为这个DataNode已经宕机</li><li>NameNode查找这个DataNode上有哪些数据块，以及这些数据在其它DataNode服务器上的存储情况</li><li>从其它DataNode服务器上复制数据</li></ul></li><li><strong>NameNode故障容错</strong><ul><li>主从热备 secondary namenode</li><li>zookeeper配合 master节点选举</li></ul></li></ul><h4 id="Hadoop发行版的选择"><a href="#Hadoop发行版的选择" class="headerlink" title="Hadoop发行版的选择"></a>Hadoop发行版的选择</h4><h5 id="社区版-Apache-Hadoop"><a href="#社区版-Apache-Hadoop" class="headerlink" title="社区版 Apache Hadoop"></a>社区版 Apache Hadoop</h5><ul><li><p>开源，技术最新；</p></li><li><p>最新的Hadoop版本都是从Apache Hadoop发布的，可以在 xxx.apache.org上进行软件的下载；</p></li><li><p>当涉及到的大数据工具比较多的时候，比较容易出现兼容性的问题，所以我们以后在选择发行版本的时候，<strong>一般选择CDH的版本</strong>，如果选择社区版可能因为兼容问题，耽误大量时间，并且可能还解决不了问题。</p></li></ul><h5 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h5><ul><li>部分内容没有开源，技术会有滞后</li><li>Cloudera 在社区版的基础上做了一些修改</li><li>在<a href="http://archive.cloudera.com/cdh5/cdh/5/进行下载" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/进行下载</a></li><li>hadoop-2.6.0-cdh-5.7.0 和 Flume<strong>*</strong>-cdh5.7.0 cdh版本一致 的各个组件配合是有不会有兼容性问题</li><li>一般情况下建议使用CDH版本</li></ul><h5 id="HDP"><a href="#HDP" class="headerlink" title="HDP"></a>HDP</h5><ul><li>商用的版本，用得比较少</li></ul><h4 id="大数据产品与互联网产品结合"><a href="#大数据产品与互联网产品结合" class="headerlink" title="大数据产品与互联网产品结合"></a>大数据产品与互联网产品结合</h4><p>1、分布式系统执行任务瓶颈: 延迟高 MapReduce 几分钟 Spark几秒钟</p><p>2、互联网产品要求</p><ul><li>毫秒级响应(1秒以内完成)</li><li>需要通过大数据实现 统计分析 数据挖掘 关联推荐 用户画像</li></ul><p>3、大数据平台</p><ul><li>整合网站应用和大数据系统之间的差异, 将应用产生的数据导入到大数据系统, 经过处理计算后再导出给应用程序使用</li></ul><p>4、互联网大数据平台架构</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203551.png"/> </p><p>5、数据采集</p><ul><li>App/Web 产生的数据&amp;日志同步到大数据系统</li><li>数据库同步:Sqoop，日志同步:Flume， 打点: Kafka</li><li>不同数据源产生的数据质量可能差别很大<ul><li>数据库 也许可以直接用</li><li>日志 爬虫 大量的清洗,转化处理</li></ul></li></ul><p>6、数据处理</p><ul><li>大数据存储与计算的核心</li><li>数据同步后导入HDFS</li><li>MapReduce Hive Spark 读取数据进行计算 结果再保存到HDFS</li><li>MapReduce Hive Spark 离线计算，HDFS 离线存储<ul><li>离线计算通常针对(某一类别)全体数据，比如 历史上所有订单</li><li>离线计算特点: 数据规模大, 运行时间长</li></ul></li><li>流式计算<ul><li>淘宝双11 每秒产生订单数 监控宣传</li><li>Storm(毫秒) SparkStreaming(秒)</li></ul></li></ul><p>7、数据输出与展示</p><ul><li>HDFS需要把数据导出交给应用程序，让用户实时展示 ECharts<ul><li>淘宝卖家量子魔方</li></ul></li><li>给运营和决策层提供各种统计报告，数据需要写入数据库<ul><li>很多运营管理人员，上班后就会登陆后台数据系统</li></ul></li></ul><p>8、任务调度系统</p><ul><li>将上面三个部分整合起来</li></ul><h4 id="拓展：大数据应用-数据分析"><a href="#拓展：大数据应用-数据分析" class="headerlink" title="拓展：大数据应用-数据分析"></a>拓展：大数据应用-数据分析</h4><p>1、通过数据分析指标监控企业运营状态，及时调整运营和产品策略,是大数据技术的关键价值之一</p><p>2、大数据平台(互联网企业)运行的绝大多数大数据计算都是关于数据分析的</p><ul><li>统计指标</li><li>关联分析,</li><li>汇总报告,</li></ul><p>3、运营数据是公司管理的基础</p><ul><li>了解公司目前发展的状况</li><li>数据驱动运营: 调节指标对公司进行管理</li></ul><p>4、运营数据的获取需要大数据平台的支持</p><ul><li>埋点采集数据</li><li>数据库，日志 三方采集数据</li><li>对数据清洗 转换 存储</li><li>利用SQL进行数据统计 汇总 分析</li><li>得到需要的运营数据报告</li></ul><p>5、运营常用数据指标</p><ul><li><p>新增用户数 UG user growth 用户增长</p><ul><li>产品增长性的关键指标</li><li>新增访问网站(新下载APP)的用户数</li></ul></li><li><p>用户留存率</p><ul><li>用户留存率 = 留存用户数 / 当期新增用户数</li><li>3日留存 5日留存 7日留存</li></ul></li><li><p>活跃用户数</p><ul><li>打开使用产品的用户</li><li>日活</li><li>月活</li><li>提升活跃是网站运营的重要目标</li></ul></li><li><p>PV Page View</p><ul><li>打开产品就算活跃</li><li>打开以后是否频繁操作就用PV衡量, 每次点击, 页面跳转都记一次PV</li></ul></li><li><p>GMV</p><ul><li>成交总金额(Gross Merchandise Volume) 电商网站统计营业额, 反应网站应收能力的重要指标</li><li>GMV相关的指标: 订单量 客单价</li></ul></li><li><p>转化率</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">转化率 = 有购买行为的用户数 / 总访问用户数</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Hadoop生态系统&quot;&gt;&lt;a href=&quot;#Hadoop生态系统&quot; class=&quot;headerlink&quot; title=&quot;Hadoop生态系统&quot;&gt;&lt;/a&gt;Hadoop生态系统&lt;/h4&gt;&lt;h5 id=&quot;狭义的Hadoop-VS-广义的Hadoop&quot;&gt;&lt;a href=&quot;#狭义的Hadoop-VS-广义的Hadoop&quot; class=&quot;headerlink&quot; title=&quot;狭义的Hadoop VS 广义的Hadoop&quot;&gt;&lt;/a&gt;狭义的Hadoop VS 广义的Hadoop&lt;/h5&gt;&lt;p&gt; 广义的Hadoop：指的是Hadoop生态系统，Hadoop生态系统是一个很庞大的概念，hadoop是其中最重要最基础的一个部分，生态系统中每一子系统只解决某一个特定的问题域（甚至可能更窄），不搞统一型的全能系统，而是小而精的多个小系统。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Hadoop生态系统" scheme="https://xiaoliaozi.com/tags/Hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="HDFS 读写流程&amp;高可用" scheme="https://xiaoliaozi.com/tags/HDFS-%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B-%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="Hadoop发行版的选择" scheme="https://xiaoliaozi.com/tags/Hadoop%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84%E9%80%89%E6%8B%A9/"/>
    
  </entry>
  
  <entry>
    <title>YARN和MAPREDUCE</title>
    <link href="https://xiaoliaozi.com/2020/02/12/YARN%E5%92%8CMAPREDUCE/"/>
    <id>https://xiaoliaozi.com/2020/02/12/YARN%E5%92%8CMAPREDUCE/</id>
    <published>2020-02-12T01:42:27.000Z</published>
    <updated>2020-02-27T12:24:04.354Z</updated>
    
    <content type="html"><![CDATA[<h4 id="资源调度框架-YARN"><a href="#资源调度框架-YARN" class="headerlink" title="资源调度框架 YARN"></a>资源调度框架 YARN</h4><h5 id="什么是YARN"><a href="#什么是YARN" class="headerlink" title="什么是YARN"></a>什么是YARN</h5><ul><li>Yet Another Resource Negotiator, 另一种资源协调者</li><li>通用资源管理系统</li><li>为上层应用提供统一的资源管理和调度，为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处</li></ul><a id="more"></a><h5 id="YARN产生背景"><a href="#YARN产生背景" class="headerlink" title="YARN产生背景"></a>YARN产生背景</h5><ul><li><p>通用资源管理系统</p><ul><li>Hadoop数据分布式存储（数据分块，冗余存储）</li><li>当多个MapReduce任务要用到相同的hdfs数据， 需要进行资源调度管理</li><li>Hadoop1.x时并没有YARN，MapReduce 既负责进行计算作业又处理服务器集群资源调度管理</li></ul></li><li><p>服务器集群资源调度管理和MapReduce执行过程耦合在一起带来的问题</p><ul><li>Hadoop早期, 技术只有Hadoop, 这个问题不明显</li><li>随着大数据技术的发展，Spark Storm … 计算框架都要用到服务器集群资源</li><li><p>如果没有通用资源管理系统，只能为多个集群分别提供数据</p><ul><li>资源利用率低 运维成本高</li></ul></li><li><p>Yarn (Yet Another Resource Negotiator) 另一种资源调度器</p><ul><li>Mesos 大数据资源管理产品</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171624.png"/></p></li><li><p>不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171624.png"/></p></li></ul><h5 id="YARN的架构和执行流程"><a href="#YARN的架构和执行流程" class="headerlink" title="YARN的架构和执行流程"></a>YARN的架构和执行流程</h5><ul><li>ResourceManager: RM 资源管理器 整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度 处理客户端的请求： submit, kill 监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理</li><li>NodeManager: NM 节点管理器 整个集群中有多个，负责自己本身节点资源管理和使用 定时向RM汇报本节点的资源使用情况 接收并处理来自RM的各种命令：启动Container 处理来自AM的命令</li><li>ApplicationMaster: AM 每个应用程序对应一个：MR、Spark，负责应用程序的管理 为应用程序向RM申请资源（core、memory），分配给内部task 需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面</li><li>Container 容器: 封装了CPU、Memory等资源的一个容器,是一个任务运行环境的抽象</li><li><p>Client: 提交作业，查询作业的运行进度，杀死作业</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227165923.png"/></p></li></ul><blockquote><p> 1.Client提交作业请求</p><p>2.ResourceManager 进程和 NodeManager 进程通信，根据集群资源，为用户程序分配第一个Container(容器)，并将 ApplicationMaster 分发到这个容器上面</p><p>3.在启动的Container中创建ApplicationMaster</p><p>4.ApplicationMaster启动后向ResourceManager注册进程,申请资源</p><p>5.ApplicationMaster申请到资源后，向对应的NodeManager申请启动Container，将要执行的程序分发到NodeManager上</p><p>6.Container启动后，执行对应的任务</p><p>7.Tast执行完毕之后，向ApplicationMaster返回结果</p><p>8.ApplicationMaster向ResourceManager 请求kill</p></blockquote><h5 id="YARN环境搭建"><a href="#YARN环境搭建" class="headerlink" title="YARN环境搭建"></a>YARN环境搭建</h5><p>1）mapred-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2）yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>3) 启动YARN相关的进程 sbin/start-yarn.sh</p><p>4）验证 jps ResourceManager NodeManager <a href="http://192,168.19.137:8088" target="_blank" rel="noopener">http://192,168.19.137:8088</a></p><p>5）停止YARN相关的进程 sbin/stop-yarn.sh</p><h4 id="分布式处理框架-MapReduce"><a href="#分布式处理框架-MapReduce" class="headerlink" title="分布式处理框架 MapReduce"></a>分布式处理框架 MapReduce</h4><h5 id="什么是MapReduce"><a href="#什么是MapReduce" class="headerlink" title="什么是MapReduce"></a>什么是MapReduce</h5><ul><li>定义： 分布式计算框架</li><li>作用： 海量数据的离线处理</li><li>MapReduce优点: 海量数据离线处理&amp;易开发</li><li>MapReduce缺点: 实时流式计算</li></ul><h5 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h5><ul><li>MapReduce分而治之的思想 </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">数钱实例：一堆钞票，各种面值分别是多少</span><br><span class="line">单点策略：一个人数所有的钞票，数出各种面值有多少张</span><br><span class="line">分治策略：</span><br><span class="line">每个人分得一堆钞票，数出各种面值有多少张</span><br><span class="line">汇总，每个人负责统计一种面值</span><br><span class="line">解决数据可以切割进行计算的应用</span><br></pre></td></tr></table></figure><ul><li>MapReduce编程分Map和Reduce阶段 <ul><li>将作业拆分成Map阶段和Reduce阶段</li><li>Map阶段 Map Tasks 分：把复杂的问题分解为若干”简单的任务”</li><li>Reduce阶段: Reduce Tasks 合：reduce</li></ul></li><li><p>MapReduce编程执行步骤 </p><ul><li>准备MapReduce的输入数据</li><li>准备Mapper数据</li><li>Shuffle</li><li>Reduce处理</li><li>结果输出</li></ul></li><li><p>编程模型 </p></li></ul><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">借鉴函数式编程方式</span><br><span class="line">用户只需要实现两个函数接口：</span><br><span class="line"><span class="constructor">Map(<span class="params">in_key</span>,<span class="params">in_value</span>)</span></span><br><span class="line">---&gt;(out_key,intermediate_value) <span class="built_in">list</span></span><br><span class="line"><span class="constructor">Reduce(<span class="params">out_key</span>,<span class="params">intermediate_value</span>)</span> <span class="built_in">list</span></span><br><span class="line">---&gt;out_value <span class="built_in">list</span></span><br></pre></td></tr></table></figure><ul><li>Word Count 词频统计案例 </li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171715.png"/> </p><h4 id="MapReduce实战"><a href="#MapReduce实战" class="headerlink" title="MapReduce实战"></a>MapReduce实战</h4><h5 id="MRJob编写和运行MapReduce代码"><a href="#MRJob编写和运行MapReduce代码" class="headerlink" title="MRJob编写和运行MapReduce代码"></a>MRJob编写和运行MapReduce代码</h5><p>1.<strong>mrjob 简介</strong></p><ul><li>使用python开发在Hadoop上运行的程序, mrjob是最简单的方式</li><li>mrjob程序可以在本地测试运行也可以部署到Hadoop集群上运行</li><li>如果不想成为hadoop专家, 但是需要利用Hadoop写MapReduce代码，mrJob是很好的选择</li></ul><p>2.<strong>mrjob 安装</strong></p><ul><li>使用pip安装：pip install mrjob</li></ul><p>3.<strong>mrjob实现WordCount</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRWordCount</span><span class="params">(MRJob)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#每一行从line中输入</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(self, _, line)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line.split():</span><br><span class="line">            <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># word相同的 会走到同一个reduce</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span><span class="params">(self, word, counts)</span>:</span>python</span><br><span class="line">        <span class="keyword">yield</span> word, sum(counts)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    MRWordCount.run()</span><br></pre></td></tr></table></figure><p>4.<strong>运行WordCount代码</strong> </p><p>打开命令行, 找到一篇文本文档, 敲如下命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python mr_word_count.py my_file.txt</span><br></pre></td></tr></table></figure><h5 id="运行MRJOB的不同方式"><a href="#运行MRJOB的不同方式" class="headerlink" title="运行MRJOB的不同方式"></a>运行MRJOB的不同方式</h5><p>1.<strong>内嵌(-r inline)方式</strong></p><ul><li>特点是调试方便</li><li>启动单一进程模拟任务执行状态和结果，默认(-r inline)可以省略</li><li>输出文件使用 &gt; output-file 或-o output-file</li><li><p>比如下面两种运行方式是等价的</p><ul><li>python word_count.py -r inline input.txt &gt; output.txt </li><li>python word_count.py input.txt &gt; output.txt</li></ul><p>2.<strong>本地(-r local)方式</strong> </p></li><li><p>用于本地模拟Hadoop调试</p></li><li>与内嵌(inline)方式的区别是启动了多进程执行每一个任务</li><li><p>如：python word_count.py -r local input.txt &gt; output1.txt</p><p>3.<strong>Hadoop(-r hadoop)方式</strong> </p></li><li><p>用于hadoop环境，支持Hadoop运行调度控制参数</p></li><li><p>如：指定Hadoop任务调度优先级(VERY_HIGH|HIGH)</p><ul><li>—jobconf mapreduce.job.priority=VERY_HIGH。</li></ul></li><li><p>如：Map及Reduce任务个数限制</p><ul><li>—jobconf mapreduce.map.tasks=2 —jobconf mapreduce.reduce.tasks=5</li></ul></li><li><p>python word_count.py -r hadoop hdfs:///test.txt -o hdfs:///output</p></li></ul><h5 id="mrjob-实现-topN统计"><a href="#mrjob-实现-topN统计" class="headerlink" title="mrjob 实现 topN统计"></a>mrjob 实现 topN统计</h5><p> 统计数据中出现次数最多的前n个数据 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob,MRStep</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopNWords</span><span class="params">(MRJob)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(self, _, line)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> line.strip() != <span class="string">""</span>:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> line.strip().split():</span><br><span class="line">                <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#介于mapper和reducer之间，用于临时的将mapper输出的数据进行统计</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combiner</span><span class="params">(self, word, counts)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> word,sum(counts)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer_sum</span><span class="params">(self, word, counts)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="literal">None</span>,(sum(counts),word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#利用heapq将数据进行排序，将最大的2个取出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top_n_reducer</span><span class="params">(self,_,word_cnts)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> cnt,word <span class="keyword">in</span> heapq.nlargest(<span class="number">2</span>,word_cnts):</span><br><span class="line">            <span class="keyword">yield</span> word,cnt</span><br><span class="line"></span><br><span class="line">    <span class="comment">#实现steps方法用于指定自定义的mapper，comnbiner和reducer方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">steps</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#传入两个step 定义了执行的顺序</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            MRStep(mapper=self.mapper,</span><br><span class="line">                   combiner=self.combiner,</span><br><span class="line">                   reducer=self.reducer_sum),</span><br><span class="line">            MRStep(reducer=self.top_n_reducer)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    TopNWords.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h4 id="MapReduce原理"><a href="#MapReduce原理" class="headerlink" title="MapReduce原理"></a>MapReduce原理</h4><h5 id="单机程序计算流程"><a href="#单机程序计算流程" class="headerlink" title="单机程序计算流程"></a>单机程序计算流程</h5><p>输入数据—-&gt;读取数据—-&gt;处理数据—-&gt;写入数据—-&gt;输出数据</p><h5 id="Hadoop计算流程"><a href="#Hadoop计算流程" class="headerlink" title="Hadoop计算流程"></a>Hadoop计算流程</h5><p>input data：输入数据</p><p>InputFormat：对数据进行切分，格式化处理</p><p>map：将前面切分的数据做map处理(将数据进行分类，输出(k,v)键值对数据)</p><p>shuffle&amp;sort:将相同的数据放在一起，并对数据进行排序处理</p><p>reduce：将map输出的数据进行hash计算，对每个map数据进行统计计算</p><p>OutputFormat：格式化输出数据</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171452.png"/></p><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171230.png"/></p><p> <img src="YARN%E5%92%8CMAPREDUCE/mp5.png" alt="img"></p><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227165931.png"/></p><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171503.png"/></p><p> map：将数据进行处理</p><p>buffer in memory：达到80%数据时，将数据锁在内存上，将这部分输出到磁盘上</p><p>partitions：在磁盘上有很多”小的数据”，将这些数据进行归并排序。</p><p>merge on disk：将所有的”小的数据”进行合并。</p><p>reduce：不同的reduce任务，会从map中对应的任务中copy数据</p><p> 在reduce中同样要进行merge操作</p><h4 id="MapReduce架构"><a href="#MapReduce架构" class="headerlink" title="MapReduce架构"></a>MapReduce架构</h4><h5 id="MapReduce架构-1-X"><a href="#MapReduce架构-1-X" class="headerlink" title="MapReduce架构 1.X"></a>MapReduce架构 1.X</h5><ul><li>JobTracker:负责接收客户作业提交，负责任务到作业节点上运行，检查作业的状态</li><li><p>TaskTracker：由JobTracker指派任务，定期向JobTracker汇报状态，在每一个工作节点上永远只会有一个TaskTracker</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171707.png"/></p></li></ul><h5 id="MapReduce2-X架构"><a href="#MapReduce2-X架构" class="headerlink" title="MapReduce2.X架构"></a>MapReduce2.X架构</h5><ul><li>ResourceManager：负责资源的管理，负责提交任务到NodeManager所在的节点运行，检查节点的状态</li><li>NodeManager：由ResourceManager指派任务，定期向ResourceManager汇报状态</li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171651.png"/></p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;资源调度框架-YARN&quot;&gt;&lt;a href=&quot;#资源调度框架-YARN&quot; class=&quot;headerlink&quot; title=&quot;资源调度框架 YARN&quot;&gt;&lt;/a&gt;资源调度框架 YARN&lt;/h4&gt;&lt;h5 id=&quot;什么是YARN&quot;&gt;&lt;a href=&quot;#什么是YARN&quot; class=&quot;headerlink&quot; title=&quot;什么是YARN&quot;&gt;&lt;/a&gt;什么是YARN&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;Yet Another Resource Negotiator, 另一种资源协调者&lt;/li&gt;
&lt;li&gt;通用资源管理系统&lt;/li&gt;
&lt;li&gt;为上层应用提供统一的资源管理和调度，为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="资源调度框架YARN" scheme="https://xiaoliaozi.com/tags/%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E6%A1%86%E6%9E%B6YARN/"/>
    
      <category term="分布式处理框架MapReduce" scheme="https://xiaoliaozi.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6MapReduce/"/>
    
      <category term="MapReduce实战" scheme="https://xiaoliaozi.com/tags/MapReduce%E5%AE%9E%E6%88%98/"/>
    
      <category term="MapReduce原理" scheme="https://xiaoliaozi.com/tags/MapReduce%E5%8E%9F%E7%90%86/"/>
    
      <category term="MapReduce架构" scheme="https://xiaoliaozi.com/tags/MapReduce%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>分布式文件系统HDFS</title>
    <link href="https://xiaoliaozi.com/2020/02/11/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS/"/>
    <id>https://xiaoliaozi.com/2020/02/11/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS/</id>
    <published>2020-02-11T07:30:04.000Z</published>
    <updated>2020-02-27T08:00:50.234Z</updated>
    
    <content type="html"><![CDATA[<h4 id="HDFS概念"><a href="#HDFS概念" class="headerlink" title="HDFS概念"></a>HDFS概念</h4><p>Hadoop 附带了一个名为 HDFS(Hadoop分布式文件系统)的分布式文件系统，基于 Hadoop 的应用程序使用 HDFS 。HDFS 是专为存储超大数据文件，运行在集群的商品硬件上。它是容错的，可伸缩的，并且非常易于扩展。</p><a id="more"></a><h4 id="HDFS的使用"><a href="#HDFS的使用" class="headerlink" title="HDFS的使用"></a>HDFS的使用</h4><p><strong>启动HDFS</strong> </p><ul><li><p>来到$HADOOP_HOME/sbin目录下</p></li><li><p>执行start-dfs.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure></li><li><p>可以看到 namenode和 datanode启动的日志信息 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Starting namenodes on [hadoop00]</span><br><span class="line">hadoop00: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-hadoop00.out</span><br><span class="line">localhost: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-hadoop00.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-secondarynamenode-hadoop00.out</span><br></pre></td></tr></table></figure></li><li><p>通过jps命令查看当前运行的进程 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ jps</span><br><span class="line">4416 DataNode</span><br><span class="line">4770 Jps</span><br><span class="line">4631 SecondaryNameNode</span><br><span class="line">4251 NameNode</span><br></pre></td></tr></table></figure></li><li><p>可以看到 NameNode DataNode 以及 SecondaryNameNode 说明启动成功 </p></li></ul><p><strong>通过可视化界面查看HDFS的运行情况</strong> </p><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155955.png"/> </p><h4 id="HDFS-shell操作"><a href="#HDFS-shell操作" class="headerlink" title="HDFS shell操作"></a>HDFS shell操作</h4><h5 id="HDFS-shell常见操作"><a href="#HDFS-shell常见操作" class="headerlink" title="HDFS shell常见操作"></a>HDFS shell常见操作</h5><p><strong>ls</strong></p><ul><li><p>hadoop fs -ls </p></li><li><p>如果是文件，则按照如下格式返回文件信息： 文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID </p></li><li>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下： 目录名  修改日期  修改时间  权限  用户ID 组ID </li><li>示例<ul><li>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2</li><li>hadoop fs -ls hdfs://host:port/user/hadoop/dir1 /nonexistentfile </li><li>返回值： 成功返回0，失败返回-1</li></ul></li></ul><h5 id="text"><a href="#text" class="headerlink" title="text"></a><strong>text</strong></h5><ul><li>使用方法：hadoop fs -text</li><li>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream</li></ul><p><strong>mv</strong></p><ul><li>使用方法：hadoop fs -mv URI [URI …]</li><li>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。 示例：<ul><li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li><li>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</li><li>返回值：成功返回0，失败返回-1</li></ul></li></ul><p><strong>put</strong></p><ul><li>使用方法：hadoop fs -put …</li><li>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。<ul><li>hadoop fs -put localfile /user/hadoop/hadoopfile</li><li>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</li><li>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</li><li>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile 从标准输入中读取输入。</li><li>返回值：成功返回0，失败返回-1</li></ul></li></ul><p>参考网址： <a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</a> </p><h5 id="HDFS-shell操作练习"><a href="#HDFS-shell操作练习" class="headerlink" title="HDFS shell操作练习"></a>HDFS shell操作练习</h5><ul><li>在centos 中创建 test.txt</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch test.txt</span><br></pre></td></tr></table></figure><ul><li>在centos中为test.txt 添加文本内容 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi test.txt</span><br></pre></td></tr></table></figure><ul><li>在HDFS中创建 hadoop001/test 文件夹 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /hadoop001/test</span><br></pre></td></tr></table></figure><ul><li>把text.txt文件上传到HDFS中 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put test.txt /hadoop001/test/</span><br></pre></td></tr></table></figure><ul><li>查看hdfs中 hadoop001/test/test.txt 文件内容 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /hadoop001/test/test.txt</span><br></pre></td></tr></table></figure><ul><li>将hdfs中 hadoop001/test/test.txt文件下载到centos </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /hadoop001/test/test.txt test.txt</span><br></pre></td></tr></table></figure><ul><li>删除HDFS中 hadoop001/test/ </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -r /hadoop001</span><br></pre></td></tr></table></figure><h4 id="HDFS设计思路"><a href="#HDFS设计思路" class="headerlink" title="HDFS设计思路"></a>HDFS设计思路</h4><ul><li><p>分布式文件系统的设计思路：</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155952.png"/></p></li><li><p>HDFS的设计目标 </p><ul><li>适合运行在通用硬件(commodity hardware)上的分布式文件系统</li><li>高度容错性的系统，适合部署在廉价的机器上</li><li>HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用</li><li>容易扩展，为用户提供性能不错的文件存储服务</li></ul></li></ul><h4 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h4><ul><li>1个NameNode/NN(Master) 带 DataNode/DN(Slaves) (Master-Slave结构)</li><li>1个文件会被拆分成多个Block</li><li>NameNode(NN)<ul><li>负责客户端请求的响应</li><li>负责元数据（文件的名称、副本系数、Block存放的DN）的管理<ul><li>元数据 MetaData 描述数据的数据</li></ul></li><li>监控DataNode健康状况 10分钟没有收到DataNode报告认为Datanode死掉了</li></ul></li><li>DataNode(DN)<ul><li>存储用户的文件对应的数据块(Block)</li><li>要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况</li></ul></li><li><p>分布式集群NameNode和DataNode部署在不同机器上</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227160002.jpg"/> </p></li></ul><h4 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h4><ul><li>优点<ul><li>数据冗余 硬件容错</li><li>适合存储大文件</li><li>处理流式数据</li><li>可构建在廉价机器上</li></ul></li><li>缺点<ul><li>低延迟的数据访问</li><li>小文件存储</li></ul></li></ul><h4 id="HDFS环境搭建"><a href="#HDFS环境搭建" class="headerlink" title="HDFS环境搭建"></a>HDFS环境搭建</h4><ul><li><p>下载jdk 和 hadoop 放到 ~/software目录下 然后解压到 ~/app目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf 压缩包名字 -C ~/app/</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export JAVA_HOME=/root/bigdata/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export HADOOP_HOME=/root/bigdata/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">保存退出后</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></li><li><p>进入到解压后的hadoop目录 修改配置文件</p><ul><li>配置文件作用<ul><li>core-site.xml 指定hdfs的访问方式</li><li>hdfs-site.xml 指定namenode 和 datanode 的数据存储位置</li><li>mapred-site.xml 配置mapreduce</li><li>yarn-site.xml 配置yarn</li></ul></li><li>修改hadoop-env.sh</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd etc/hadoop</span><br><span class="line">vi hadoop-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">找到下面内容添加java home</span></span><br><span class="line">export_JAVA_HOME=/root/bigdata/jdk</span><br></pre></td></tr></table></figure><ul><li>修改 core-site.xml 在 节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/root/bigdata/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改hdfs-site.xml 在 configuration节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/bigdata/hadoop/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/bigdata/hadoop/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改 mapred-site.xml</li><li>默认没有这个 从模板文件复制</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure><p> 在mapred-site.xml 的configuration 节点中添加</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改yarn-site.xml configuration 节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>来到hadoop的bin目录格式化namenode</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hadoop namenode -format (这个命令只运行一次)</span><br></pre></td></tr></table></figure></li><li><p>启动hdfs 进入到 sbin</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure></li><li><p>启动启动yarn 在sbin中</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;HDFS概念&quot;&gt;&lt;a href=&quot;#HDFS概念&quot; class=&quot;headerlink&quot; title=&quot;HDFS概念&quot;&gt;&lt;/a&gt;HDFS概念&lt;/h4&gt;&lt;p&gt;Hadoop 附带了一个名为 HDFS(Hadoop分布式文件系统)的分布式文件系统，基于 Hadoop 的应用程序使用 HDFS 。HDFS 是专为存储超大数据文件，运行在集群的商品硬件上。它是容错的，可伸缩的，并且非常易于扩展。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="HDFS" scheme="https://xiaoliaozi.com/tags/HDFS/"/>
    
      <category term="HDFS概念" scheme="https://xiaoliaozi.com/tags/HDFS%E6%A6%82%E5%BF%B5/"/>
    
      <category term="HDFS shell操作" scheme="https://xiaoliaozi.com/tags/HDFS-shell%E6%93%8D%E4%BD%9C/"/>
    
      <category term="HDFS架构" scheme="https://xiaoliaozi.com/tags/HDFS%E6%9E%B6%E6%9E%84/"/>
    
      <category term="HDFS环境搭建" scheme="https://xiaoliaozi.com/tags/HDFS%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="HDFS优缺点" scheme="https://xiaoliaozi.com/tags/HDFS%E4%BC%98%E7%BC%BA%E7%82%B9/"/>
    
  </entry>
  
  <entry>
    <title>HADOOP概述</title>
    <link href="https://xiaoliaozi.com/2020/02/11/HADOOP%E6%A6%82%E8%BF%B0/"/>
    <id>https://xiaoliaozi.com/2020/02/11/HADOOP%E6%A6%82%E8%BF%B0/</id>
    <published>2020-02-11T07:29:44.000Z</published>
    <updated>2020-02-27T07:59:38.132Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Hadoop的概念"><a href="#Hadoop的概念" class="headerlink" title="Hadoop的概念"></a>Hadoop的概念</h4><ul><li>Apache™ Hadoop® 是一个开源的，<strong>可靠的</strong>(reliable)，<strong>可扩展</strong>的(scalable)<strong>分布式计算框架</strong> <ul><li>允许使用简单的编程模型跨计算机集群分布式处理大型数据集 </li><li><strong>可扩展</strong>: 从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储</li><li><strong>可靠的</strong>: 不依靠硬件来提供高可用性(high-availability)，而是在应用层检测和处理故障，从而在计算机集群之上提供高可用服务</li></ul></li></ul><a id="more"></a><h4 id="Hadoop能做什么"><a href="#Hadoop能做什么" class="headerlink" title="Hadoop能做什么?"></a>Hadoop能做什么?</h4><ul><li><p>搭建大型数据仓库</p></li><li><p>PB级数据的存储 处理 分析 统计等业务</p><ul><li><p>搜索引擎</p></li><li><p>日志分析</p></li><li><p>数据挖掘</p></li><li><p>商业智能(Business Intelligence，简称：BI)</p><blockquote><p>商业智能通常被理解为将企业中现有的数据(订单、库存、交易账目、客户和供应商等数据)转化为知识，帮助企业做出明智的业务经营决策的工具。从技术层面上讲，是数据仓库、数据挖掘等技术的综合运用。</p></blockquote></li></ul></li></ul><h4 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h4><ul><li><p>Hadoop是所有搜索引擎的共性问题的廉价解决方案 </p><ul><li>如何存储持续增长的海量网页: 单节点 V.S. 分布式存储</li><li>如何对持续增长的海量网页进行排序: 超算 V.S. 分布式计算</li><li>HDFS 解决分布式存储问题</li><li>MapReduce 解决分布式计算问题</li></ul></li><li><p>Hadoop Common：协调其他组件的通用工具</p></li><li><p>HDFS：一个基于网络的分布式文件存储系统</p><ul><li>Hadoop Distributed File System (HDFS™) </li><li>HDFS的特点:扩展性&amp;容错性&amp;海量数量存储</li><li>将文件切分成指定大小的数据块, 并在多台机器上保存多个副本</li><li>数据切分、多副本、容错等操作对用户是透明的</li></ul><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">下面这张图是数据块多份复制存储的示意</span><br><span class="line">图中对于文件 /users/sameerp/data/part<span class="number">-0</span>，其复制备份数设置为<span class="number">2</span>, 存储的BlockID分别为<span class="number">1</span>、<span class="number">3</span>。</span><br><span class="line">Block1的两个备份存储在DataNode0和DataNode2两个服务器上</span><br><span class="line">Block3的两个备份存储在DataNode4和DataNode6两个服务器上</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155845.png"/> </p></li><li><p>Hadoop MapReduce ： 基于yarn的大数据集并行处理系统 </p><ul><li>分布式计算框架</li><li>MapReduce是GoogleMapReduce的开源实现</li><li>MapReduce特点:扩展性&amp;容错性&amp;海量数据离线处理</li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155815.png"/> </p></li><li><p>YARN： 作业调度和集群资源管理的框架 </p><ul><li>YARN: Yet Another Resource Negotiator</li><li>负责整个集群资源的管理和调度</li><li>YARN特点:扩展性&amp;容错性&amp;多框架资源统一调度</li></ul></li></ul><h4 id="Hadoop优势"><a href="#Hadoop优势" class="headerlink" title="Hadoop优势"></a>Hadoop优势</h4><ul><li>高可靠<ul><li>数据存储: 数据块多副本</li><li>数据计算: 某个节点崩溃, 会自动重新调度作业计算</li></ul></li><li>高扩展性<ul><li>存储/计算资源不够时，可以横向的线性扩展机器</li><li>一个集群中可以包含数以千计的节点</li><li>集群可以使用廉价机器，成本低</li></ul></li><li>Hadoop生态系统成熟</li></ul><h4 id="拓展-数据仓库"><a href="#拓展-数据仓库" class="headerlink" title="拓展-数据仓库"></a>拓展-数据仓库</h4><h5 id="数据库两大基本类型"><a href="#数据库两大基本类型" class="headerlink" title="数据库两大基本类型"></a>数据库两大基本类型</h5><blockquote><p> <strong>操作型数据库</strong> ： 主要用于业务支撑。一个公司往往会使用并维护若干个数据库，这些数据库保存着公司的日常操作数据，比如商品购买、酒店预订、学生成绩录入等； </p><p> <strong>分析型数据库</strong> ： 主要用于历史数据分析。这类数据库作为公司的单独数据存储，负责利用历史数据对公司各主题域进行统计分析； </p></blockquote><h5 id="数据仓库定义"><a href="#数据仓库定义" class="headerlink" title="数据仓库定义"></a>数据仓库定义</h5><p>数据仓库是决策支持系统和联机分析应用数据源的结构化数据环境。数据仓库研究和解决从数据库中获取信息的问题。数据仓库的特征在于面向主题、集成性、稳定性和时变性 </p><h5 id="数据仓库特点"><a href="#数据仓库特点" class="headerlink" title="数据仓库特点"></a>数据仓库特点</h5><ol><li><strong>面向主题</strong></li></ol><p>​    面向主题特性是数据仓库和操作型数据库的根本区别。操作型数据库是为了支撑各种业务而建立，而分析型数据库则是为了对从各种繁杂业务中抽象出来的分析主题(如用户、成本、商品等)进行分析而建立；</p><ol><li><strong>集成性</strong></li></ol><p>​    集成性是指数据仓库会将不同源数据库中的数据汇总到一起；</p><ol><li><strong>企业范围</strong></li></ol><p>​    数据仓库内的数据是面向公司全局的。比如某个主题域为成本，则全公司和成本有关的信息都会被汇集进来；</p><ol><li><strong>历史性</strong></li></ol><p>​    较之操作型数据库，数据仓库的时间跨度通常比较长。前者通常保存几个月，后者可能几年甚至几十年；</p><ol><li><strong>时变性</strong></li></ol><p>​    时变性是指数据仓库包含来自其时间范围不同时间段的数据快照。有了这些数据快照以后，用户便可将其汇总，生成各历史阶段的数据分析报告；</p><h5 id="数据仓库组件"><a href="#数据仓库组件" class="headerlink" title="数据仓库组件"></a>数据仓库组件</h5><p> 数据仓库的核心组件有四个：各源数据库，ETL，数据仓库，前端应用。如下图所示： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155904.jpg"/> </p><ol><li><p><strong>业务系统</strong></p><p> 业务系统包含各种源数据库，这些源数据库既为业务系统提供数据支撑，同时也作为数据仓库的数据源(注：除了业务系统，数据仓库也可从其他外部数据源获取数据)； </p></li><li><p><strong>ETL</strong></p><p> ETL分别代表：提取extraction、转换transformation、加载load。其中提取过程表示操作型数据库搜集指定数据，转换过程表示将数据转化为指定格式并进行数据清洗保证数据质量，加载过程表示将转换过后满足指定格式的数据加载进数据仓库。数据仓库会周期不断地从源数据库提取清洗好了的数据，因此也被称为”目标系统”； </p></li><li><p><strong>前端应用</strong></p><p>  和操作型数据库一样，数据仓库通常提供具有直接访问数据仓库功能的前端应用，这些应用也被称为BI(商务智能)应用； </p></li></ol><h5 id="数据仓库开发流程"><a href="#数据仓库开发流程" class="headerlink" title="数据仓库开发流程"></a>数据仓库开发流程</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155858.jpg"/> </p><p> 最后：在大数据时代，数据仓库的重要性更胜以往。Hadoop平台下的Hive，Spark平台下的Spark SQL都是各自生态圈内应用最热门的配套工具，而它们的本质就是开源分布式数据仓库。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Hadoop的概念&quot;&gt;&lt;a href=&quot;#Hadoop的概念&quot; class=&quot;headerlink&quot; title=&quot;Hadoop的概念&quot;&gt;&lt;/a&gt;Hadoop的概念&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Apache™ Hadoop® 是一个开源的，&lt;strong&gt;可靠的&lt;/strong&gt;(reliable)，&lt;strong&gt;可扩展&lt;/strong&gt;的(scalable)&lt;strong&gt;分布式计算框架&lt;/strong&gt; &lt;ul&gt;
&lt;li&gt;允许使用简单的编程模型跨计算机集群分布式处理大型数据集 &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展&lt;/strong&gt;: 从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可靠的&lt;/strong&gt;: 不依靠硬件来提供高可用性(high-availability)，而是在应用层检测和处理故障，从而在计算机集群之上提供高可用服务&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="Hadoop的概念" scheme="https://xiaoliaozi.com/tags/Hadoop%E7%9A%84%E6%A6%82%E5%BF%B5/"/>
    
      <category term="Hadoop核心组件" scheme="https://xiaoliaozi.com/tags/Hadoop%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Hadoop优势" scheme="https://xiaoliaozi.com/tags/Hadoop%E4%BC%98%E5%8A%BF/"/>
    
      <category term="数据仓库" scheme="https://xiaoliaozi.com/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>基于模型的协同过滤推荐</title>
    <link href="https://xiaoliaozi.com/2020/02/11/%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/"/>
    <id>https://xiaoliaozi.com/2020/02/11/%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</id>
    <published>2020-02-11T06:43:28.000Z</published>
    <updated>2020-02-27T07:57:55.714Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Model-Based-协同过滤算法"><a href="#Model-Based-协同过滤算法" class="headerlink" title="Model-Based 协同过滤算法"></a>Model-Based 协同过滤算法</h4><p>随着机器学习技术的逐渐发展与完善，推荐系统也逐渐运用机器学习的思想来进行推荐。将机器学习应用到推荐系统中的方案真是不胜枚举。以下对Model-Based CF算法做一个大致的分类：</p><ul><li>基于分类算法、回归算法、聚类算法</li><li>基于矩阵分解的推荐</li><li>基于神经网络算法</li><li>基于图模型算法</li></ul><p>几种应用较多的方案：</p><ul><li><strong>基于回归模型的协同过滤推荐</strong></li><li><strong>基于矩阵分解的协同过滤推荐</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Model-Based-协同过滤算法&quot;&gt;&lt;a href=&quot;#Model-Based-协同过滤算法&quot; class=&quot;headerlink&quot; title=&quot;Model-Based 协同过滤算法&quot;&gt;&lt;/a&gt;Model-Based 协同过滤算法&lt;/h4&gt;&lt;p&gt;随着机器学习
      
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="基于模型的推荐算法" scheme="https://xiaoliaozi.com/tags/%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统的冷启动问题</title>
    <link href="https://xiaoliaozi.com/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/"/>
    <id>https://xiaoliaozi.com/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/</id>
    <published>2020-02-10T02:30:55.000Z</published>
    <updated>2020-02-27T07:57:29.280Z</updated>
    
    <content type="html"><![CDATA[<h4 id="推荐系统冷启动概念"><a href="#推荐系统冷启动概念" class="headerlink" title="推荐系统冷启动概念"></a>推荐系统冷启动概念</h4><ul><li>⽤户冷启动：如何为新⽤户做个性化推荐</li><li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li><li>系统冷启动：⽤户冷启动+物品冷启动</li><li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li></ul><a id="more"></a><h4 id="处理推荐系统冷启动问题的常用方法"><a href="#处理推荐系统冷启动问题的常用方法" class="headerlink" title="处理推荐系统冷启动问题的常用方法"></a>处理推荐系统冷启动问题的常用方法</h4><h5 id="用户冷启动"><a href="#用户冷启动" class="headerlink" title="用户冷启动"></a>用户冷启动</h5><ul><li><p>收集⽤户特征</p><ul><li>⽤户注册信息：性别、年龄、地域</li><li>设备信息：定位、⼿机型号、app列表</li><li>社交信息、推⼴素材、安装来源</li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155703.png"/></p></li><li><p>引导用户填写兴趣 </p></li><li>使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</li><li>新老用户推荐策略的差异<ul><li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li><li>Explore Exploit⼒度</li><li>使⽤单独的特征和模型预估</li></ul></li></ul><h5 id="物品冷启动"><a href="#物品冷启动" class="headerlink" title="物品冷启动"></a>物品冷启动</h5><ul><li>给物品打标签</li><li><p>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155708.png"/> </p></li></ul><h5 id="系统冷启动"><a href="#系统冷启动" class="headerlink" title="系统冷启动"></a>系统冷启动</h5><ul><li>基于内容的推荐 系统早期</li><li>基于内容的推荐逐渐过渡到协同过滤</li><li>基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;推荐系统冷启动概念&quot;&gt;&lt;a href=&quot;#推荐系统冷启动概念&quot; class=&quot;headerlink&quot; title=&quot;推荐系统冷启动概念&quot;&gt;&lt;/a&gt;推荐系统冷启动概念&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;⽤户冷启动：如何为新⽤户做个性化推荐&lt;/li&gt;
&lt;li&gt;物品冷启动：如何将新物品推荐给⽤户（协同过滤）&lt;/li&gt;
&lt;li&gt;系统冷启动：⽤户冷启动+物品冷启动&lt;/li&gt;
&lt;li&gt;本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统冷启动" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统评估</title>
    <link href="https://xiaoliaozi.com/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/"/>
    <id>https://xiaoliaozi.com/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/</id>
    <published>2020-02-10T02:30:27.000Z</published>
    <updated>2020-02-27T07:56:54.509Z</updated>
    
    <content type="html"><![CDATA[<h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li>了解推荐系统的常用评估指标</li><li>了解推荐系统的评估方法</li></ul><a id="more"></a><h4 id="推荐系统的评估指标"><a href="#推荐系统的评估指标" class="headerlink" title="推荐系统的评估指标"></a>推荐系统的评估指标</h4><ul><li><p>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155643.png"/> </p></li><li><p>评估数据来源显示反馈和隐式反馈 </p></li></ul><div class="table-container"><table><thead><tr><th></th><th>显式反馈</th><th>隐式反馈</th></tr></thead><tbody><tr><td>例子</td><td>电影/书籍评分 是否喜欢这个推荐</td><td>播放/点击 评论 下载 购买</td></tr><tr><td>准确性</td><td>高</td><td>低</td></tr><tr><td>数量</td><td>少</td><td>多</td></tr><tr><td>获取成本</td><td>高</td><td>低</td></tr></tbody></table></div><ul><li><p>常用评估指标 </p><blockquote><p>• 准确性 • 信任度 • 满意度 • 实时性 • 覆盖率 • 鲁棒性<br>• 多样性 • 可扩展性 • 新颖性 • 商业⽬标 • 惊喜度 • ⽤户留存 </p></blockquote><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">- </span>准确性 (理论角度) Netflix 美国录像带租赁</span><br><span class="line"><span class="bullet">  - </span>评分预测</span><br><span class="line"><span class="bullet">    - </span>RMSE MAE</span><br><span class="line"><span class="bullet">  - </span>topN推荐</span><br><span class="line"><span class="bullet">    - </span>召回率 精准率</span><br><span class="line"><span class="bullet">- </span>准确性 (业务角度)</span><br><span class="line"><span class="bullet">- </span>覆盖度</span><br><span class="line"><span class="bullet">  - </span>信息熵 对于推荐越大越好</span><br><span class="line"><span class="bullet">  - </span>覆盖率</span><br><span class="line"><span class="bullet">- </span>多样性&amp;新颖性&amp;惊喜性</span><br><span class="line"><span class="bullet">  - </span>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</span><br><span class="line"><span class="bullet">  - </span>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</span><br><span class="line"><span class="bullet">  - </span>惊喜性：历史不相似（惊）但很满意（喜）</span><br><span class="line"><span class="bullet">  - </span>往往需要牺牲准确性</span><br><span class="line"><span class="bullet">  - </span>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</span><br><span class="line"><span class="bullet">  - </span>系统过度强调实时性</span><br><span class="line"><span class="bullet">- </span>Exploitation &amp; Exploration 探索与利用问题</span><br><span class="line"><span class="bullet">  - </span>Exploitation(开发 利用)：选择现在可能最佳的⽅案</span><br><span class="line"><span class="bullet">  - </span>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</span><br><span class="line"><span class="bullet">  - </span>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化 长期的⽬标</span><br><span class="line"><span class="bullet">- </span>EE问题实践</span><br><span class="line"><span class="bullet">  - </span>兴趣扩展: 相似话题, 搭配推荐</span><br><span class="line"><span class="bullet">  - </span>人群算法: userCF 用户聚类</span><br><span class="line"><span class="bullet">  - </span>平衡个性化推荐和热门推荐比例</span><br><span class="line"><span class="bullet">  - </span>随机丢弃用户行为历史</span><br><span class="line"><span class="bullet">  - </span>随机扰动模型参数</span><br><span class="line"><span class="bullet">- </span>EE可能带来的问题</span><br><span class="line"><span class="bullet">  - </span>探索伤害用户体验, 可能导致用户流失</span><br><span class="line"><span class="bullet">  - </span>探索带来的长期收益(留存率)评估周期长, KPI压力大</span><br><span class="line"><span class="bullet">  - </span>如何平衡实时兴趣和长期兴趣</span><br><span class="line"><span class="bullet">  - </span>如何平衡短期产品体验和长期系统生态</span><br><span class="line"><span class="bullet">  - </span>如何平衡大众口味和小众需求</span><br></pre></td></tr></table></figure></li></ul><h4 id="推荐系统评估方法"><a href="#推荐系统评估方法" class="headerlink" title="推荐系统评估方法"></a>推荐系统评估方法</h4><p>评估方法</p><ul><li>问卷调查: 成本高</li><li>离线评估:<ul><li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li><li>只能评估少数指标</li><li>速度快, 不损害用户体验</li></ul></li><li>在线评估: 灰度发布 &amp; A/B测试 50% 全量上线</li><li>实践: 离线评估和在线评估结合，定期做问卷调查</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;学习目标&quot;&gt;&lt;a href=&quot;#学习目标&quot; class=&quot;headerlink&quot; title=&quot;学习目标&quot;&gt;&lt;/a&gt;学习目标&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;了解推荐系统的常用评估指标&lt;/li&gt;
&lt;li&gt;了解推荐系统的评估方法&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统的评估指标" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
    
      <category term="推荐系统评估方法" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>案例-基于协同过滤的电影推荐</title>
    <link href="https://xiaoliaozi.com/2020/02/09/%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/"/>
    <id>https://xiaoliaozi.com/2020/02/09/%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</id>
    <published>2020-02-09T02:30:03.000Z</published>
    <updated>2020-02-27T07:56:35.185Z</updated>
    
    <content type="html"><![CDATA[<h4 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h4><ul><li>应用基于用户的协同过滤实现电影评分预测</li><li>应用基于物品的协同过滤实现电影评分预测</li></ul><a id="more"></a><h4 id="User-Based-CF-预测电影评分"><a href="#User-Based-CF-预测电影评分" class="headerlink" title="User-Based CF 预测电影评分"></a>User-Based CF 预测电影评分</h4><ul><li><p>据集下载</p><ul><li>下载地址：<a href="https://grouplens.org/datasets/movielens/latest/" target="_blank" rel="noopener">MovieLens Latest Datasets Small</a></li><li>建议下载<a href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" target="_blank" rel="noopener">ml-latest-small.zip</a>，数据量小，便于我们单机使用和运行</li></ul></li><li><p>加载ratings.csv，转换为用户-电影评分矩阵并计算用户之间相似度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">DATA_PATH = <span class="string">"./datasets/ml-latest-small/ratings.csv"</span></span><br><span class="line"></span><br><span class="line">dtype = &#123;<span class="string">"userId"</span>: np.int32, <span class="string">"movieId"</span>: np.int32, <span class="string">"rating"</span>: np.float32&#125;</span><br><span class="line"><span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵</span></span><br><span class="line">ratings_matrix = ratings.pivot_table(index=[<span class="string">"userId"</span>], columns=[<span class="string">"movieId"</span>],values=<span class="string">"rating"</span>)</span><br><span class="line"><span class="comment">#计算用户之间相似度</span></span><br><span class="line">user_similar = ratings_matrix.T.corr()</span><br></pre></td></tr></table></figure></li><li><p>预测用户对物品的评分 （以用户1对电影1评分为例） </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155449.png"/></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">similar_users = user_similar[<span class="number">1</span>].drop([<span class="number">1</span>]).dropna()</span><br><span class="line"><span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line"><span class="comment"># 2. 从用户1的近邻相似用户中筛选出对物品1有评分记录的近邻用户</span></span><br><span class="line">ids = set(ratings_matrix[<span class="number">1</span>].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">finally_similar_users = similar_users.ix[list(<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line"><span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">    <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">    sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">    <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">    sim_user_rating_for_item = sim_user_rated_movies[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算分子的值</span></span><br><span class="line">    numerator += similarity * sim_user_rating_for_item</span><br><span class="line">    <span class="comment"># 计算分母的值</span></span><br><span class="line">    denominator += similarity</span><br><span class="line"><span class="comment"># 4 计算预测的评分值</span></span><br><span class="line">predict_rating = numerator/denominator</span><br><span class="line">print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (<span class="number">1</span>, <span class="number">1</span>, predict_rating))</span><br></pre></td></tr></table></figure></li><li><p>封装成方法 预测任意用户对任意电影的评分 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(uid, iid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测给定用户对给定物品的评分值</span></span><br><span class="line"><span class="string">    :param uid: 用户ID</span></span><br><span class="line"><span class="string">    :param iid: 物品ID</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两相似度矩阵</span></span><br><span class="line"><span class="string">    :return: 预测的评分值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    print(<span class="string">"开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."</span>%(uid, iid))</span><br><span class="line">    <span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">    similar_users = user_similar[uid].drop([uid]).dropna()</span><br><span class="line">    <span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">    similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line">    <span class="keyword">if</span> similar_users.empty <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"用户&lt;%d&gt;没有相似的用户"</span> % uid)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户</span></span><br><span class="line">    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">    finally_similar_users = similar_users.ix[list(ids)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">    numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">    denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">    <span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">        <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">        <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">        sim_user_rating_for_item = sim_user_rated_movies[iid]</span><br><span class="line">        <span class="comment"># 计算分子的值</span></span><br><span class="line">        numerator += similarity * sim_user_rating_for_item</span><br><span class="line">        <span class="comment"># 计算分母的值</span></span><br><span class="line">        denominator += similarity</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">    predict_rating = numerator/denominator</span><br><span class="line">    print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br><span class="line">    <span class="keyword">return</span> round(predict_rating, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></li><li><p>为某一用户预测所有电影评分 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(uid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测全部评分</span></span><br><span class="line"><span class="string">    :param uid: 用户id</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品打分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两间的相似度</span></span><br><span class="line"><span class="string">    :return: 生成器，逐个返回预测评分</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 准备要预测的物品的id列表</span></span><br><span class="line">    item_ids = ratings_matrix.columns</span><br><span class="line">    <span class="comment"># 逐个预测</span></span><br><span class="line">    <span class="keyword">for</span> iid <span class="keyword">in</span> item_ids:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rating = predict(uid, iid, ratings_matrix, user_similar)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> uid, iid, rating</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predict_all(<span class="number">1</span>, ratings_matrix, user_similar):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>根据评分为指定用户推荐topN个电影 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k_rs_result</span><span class="params">(k)</span>:</span></span><br><span class="line">    results = predict_all(<span class="number">1</span>, ratings_matrix, user_similar)</span><br><span class="line">    <span class="keyword">return</span> sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="literal">True</span>)[:k]</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    result = top_k_rs_result(<span class="number">20</span>)</span><br><span class="line">    pprint(result)</span><br></pre></td></tr></table></figure></li></ul><h4 id="Item-Based-CF-预测电影评分"><a href="#Item-Based-CF-预测电影评分" class="headerlink" title="Item-Based CF 预测电影评分"></a>Item-Based CF 预测电影评分</h4><ul><li><p>加载ratings.csv，转换为用户-电影评分矩阵并计算用户之间相似度 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">DATA_PATH = <span class="string">"./datasets/ml-latest-small/ratings.csv"</span></span><br><span class="line"></span><br><span class="line">dtype = &#123;<span class="string">"userId"</span>: np.int32, <span class="string">"movieId"</span>: np.int32, <span class="string">"rating"</span>: np.float32&#125;</span><br><span class="line"><span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵</span></span><br><span class="line">ratings_matrix = ratings.pivot_table(index=[<span class="string">"userId"</span>], columns=[<span class="string">"movieId"</span>],values=<span class="string">"rating"</span>)</span><br><span class="line"><span class="comment">#计算用户之间相似度</span></span><br><span class="line">item_similar = ratings_matrix.corr()</span><br></pre></td></tr></table></figure></li><li><p>预测用户对物品的评分 （以用户1对电影1评分为例） </p></li><li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155455.png"/></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 找出iid物品的相似物品</span></span><br><span class="line">  similar_items = item_similar[<span class="number">1</span>].drop([<span class="number">1</span>]).dropna()</span><br><span class="line">  <span class="comment"># 相似物品筛选规则：正相关的物品</span></span><br><span class="line">  similar_items = similar_items.where(similar_items&gt;<span class="number">0</span>).dropna()</span><br><span class="line">  <span class="comment"># 2. 从iid物品的近邻相似物品中筛选出uid用户评分过的物品</span></span><br><span class="line">  ids = set(ratings_matrix.ix[<span class="number">1</span>].dropna().index)&amp;set(similar_items.index)</span><br><span class="line">  finally_similar_items = similar_items.ix[list(ids)]</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3. 结合iid物品与其相似物品的相似度和uid用户对其相似物品的评分，预测uid对iid的评分</span></span><br><span class="line">  numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">  denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">  <span class="keyword">for</span> sim_iid, similarity <span class="keyword">in</span> finally_similar_items.iteritems():</span><br><span class="line">      <span class="comment"># 近邻物品的评分数据</span></span><br><span class="line">      sim_item_rated_movies = ratings_matrix[sim_iid].dropna()</span><br><span class="line">      <span class="comment"># 1用户对相似物品物品的评分</span></span><br><span class="line">      sim_item_rating_from_user = sim_item_rated_movies[<span class="number">1</span>]</span><br><span class="line">      <span class="comment"># 计算分子的值</span></span><br><span class="line">      numerator += similarity * sim_item_rating_from_user</span><br><span class="line">      <span class="comment"># 计算分母的值</span></span><br><span class="line">      denominator += similarity</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">  predict_rating = sum_up/sum_down</span><br><span class="line">  print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br></pre></td></tr></table></figure></li><li><p>封装成方法 预测任意用户对任意电影的评分 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(uid, iid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测给定用户对给定物品的评分值</span></span><br><span class="line"><span class="string">    :param uid: 用户ID</span></span><br><span class="line"><span class="string">    :param iid: 物品ID</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两相似度矩阵</span></span><br><span class="line"><span class="string">    :return: 预测的评分值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    print(<span class="string">"开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."</span>%(uid, iid))</span><br><span class="line">    <span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">    similar_users = user_similar[uid].drop([uid]).dropna()</span><br><span class="line">    <span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">    similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line">    <span class="keyword">if</span> similar_users.empty <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"用户&lt;%d&gt;没有相似的用户"</span> % uid)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户</span></span><br><span class="line">    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">    finally_similar_users = similar_users.ix[list(ids)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">    numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">    denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">    <span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">        <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">        <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">        sim_user_rating_for_item = sim_user_rated_movies[iid]</span><br><span class="line">        <span class="comment"># 计算分子的值</span></span><br><span class="line">        numerator += similarity * sim_user_rating_for_item</span><br><span class="line">        <span class="comment"># 计算分母的值</span></span><br><span class="line">        denominator += similarity</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">    predict_rating = numerator/denominator</span><br><span class="line">    print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br><span class="line">    <span class="keyword">return</span> round(predict_rating, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></li><li><p>为某一用户预测所有电影评分 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(uid, ratings_matrix, item_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测全部评分</span></span><br><span class="line"><span class="string">    :param uid: 用户id</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品打分矩阵</span></span><br><span class="line"><span class="string">    :param item_similar: 物品两两间的相似度</span></span><br><span class="line"><span class="string">    :return: 生成器，逐个返回预测评分</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 准备要预测的物品的id列表</span></span><br><span class="line">    item_ids = ratings_matrix.columns</span><br><span class="line">    <span class="comment"># 逐个预测</span></span><br><span class="line">    <span class="keyword">for</span> iid <span class="keyword">in</span> item_ids:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rating = predict(uid, iid, ratings_matrix, item_similar)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> uid, iid, rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predict_all(<span class="number">1</span>, ratings_matrix, item_similar):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></li><li><p>根据评分为指定用户推荐topN个电影 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k_rs_result</span><span class="params">(k)</span>:</span></span><br><span class="line">    results = predict_all(<span class="number">1</span>, ratings_matrix, item_similar)</span><br><span class="line">    <span class="keyword">return</span> sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="literal">True</span>)[:k]</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    result = top_k_rs_result(<span class="number">20</span>)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;学习目标&quot;&gt;&lt;a href=&quot;#学习目标&quot; class=&quot;headerlink&quot; title=&quot;学习目标&quot;&gt;&lt;/a&gt;学习目标&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;应用基于用户的协同过滤实现电影评分预测&lt;/li&gt;
&lt;li&gt;应用基于物品的协同过滤实现电影评分预测&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="基于用户的协同过滤" scheme="https://xiaoliaozi.com/tags/%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"/>
    
      <category term="基于物品的协同过滤" scheme="https://xiaoliaozi.com/tags/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>特征工程-特征降维</title>
    <link href="https://xiaoliaozi.com/2020/02/03/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"/>
    <id>https://xiaoliaozi.com/2020/02/03/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/</id>
    <published>2020-02-03T04:52:16.000Z</published>
    <updated>2020-02-27T07:42:45.410Z</updated>
    
    <content type="html"><![CDATA[<h4 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h4><ul><li>了解降维的定义</li><li>知道通过低方差过滤实现降维过程</li><li>知道相关系数实现降维的过程</li><li>知道主成分分析法实现过程</li></ul><a id="more"></a><h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p> <strong>降维</strong>是指在某些限定条件下，<strong>降低随机变量(特征)个数</strong>，得到<strong>一组“不相关”主变量</strong>的过程 </p><ul><li><p>降低随机变量的个数 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154011.png"/></p></li><li><p>相关特征(correlated feature)</p><ul><li>相对湿度与降雨量之间的相关</li><li>等等</li></ul></li></ul><blockquote><p>正是因为在进行训练的时候，我们都是使用特征进行学习。如果特征本身存在问题或者特征之间相关性较强，对于算法学习预测会影响较大 </p></blockquote><h5 id="降维的两种方式"><a href="#降维的两种方式" class="headerlink" title="降维的两种方式"></a>降维的两种方式</h5><ul><li>特征选择</li><li>主成分分析（可以理解一种特征提取的方式）</li></ul><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><h5 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h5><p> 数据中包含<strong>冗余或无关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出主要特征</strong>。 </p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ul><li>Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联<ul><li><strong>方差选择法：低方差特征过滤</strong></li><li><strong>相关系数</strong></li></ul></li><li>Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul><li><strong>决策树:信息熵、信息增益</strong></li><li><strong>正则化：L1、L2</strong></li><li><strong>深度学习：卷积等</strong></li></ul></li></ul><h5 id="低方差特征过滤"><a href="#低方差特征过滤" class="headerlink" title="低方差特征过滤"></a>低方差特征过滤</h5><p>1.<strong>定义</strong></p><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">删除低方差的一些特征，前面讲过方差的意义。再结合方差的大小来考虑这个方式的角度。</span><br><span class="line"><span class="bullet">- </span>特征方差小：某个特征大多样本的值比较相近</span><br><span class="line"><span class="bullet">- </span>特征方差大：某个特征很多样本的值都有差别</span><br></pre></td></tr></table></figure><p>2.<strong>API</strong></p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.<span class="constructor">VarianceThreshold(<span class="params">threshold</span> = 0.0)</span></span><br><span class="line">删除所有低方差特征</span><br><span class="line"><span class="module-access"><span class="module"><span class="identifier">Variance</span>.</span></span>fit<span class="constructor">_transform(X)</span></span><br><span class="line">X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">返回值：训练集差异低于threshold的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。</span><br></pre></td></tr></table></figure><p>3.<strong>案例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">“”“</span><br><span class="line">我们对某些股票的指标特征之间进行一个筛选，除去<span class="string">'index,'</span>date<span class="string">','</span><span class="keyword">return</span><span class="string">'列不考虑（这些类型不匹配，也不是所需要指标）</span></span><br><span class="line"><span class="string">”“”</span></span><br><span class="line"><span class="string">import pandas as pd</span></span><br><span class="line"><span class="string">from sklearn.feature_selection import VarianceThreshold</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">def var_thr():</span></span><br><span class="line"><span class="string">    """低方差过滤"""</span></span><br><span class="line"><span class="string">    data = pd.read_csv("./data/factor_returns.csv")</span></span><br><span class="line"><span class="string">    # print(data)</span></span><br><span class="line"><span class="string">    print(data.shape)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # 实例化一个对象</span></span><br><span class="line"><span class="string">    tranfer = VarianceThreshold(threshold=1)</span></span><br><span class="line"><span class="string">    # 转换</span></span><br><span class="line"><span class="string">    tranfer_data = tranfer.fit_transform(data.iloc[:, 1:10])</span></span><br><span class="line"><span class="string">    # print(tranfer_data)</span></span><br><span class="line"><span class="string">    print(tranfer_data.shape)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if __name__ == '</span>__main__<span class="string">':</span></span><br><span class="line"><span class="string">    var_thr()</span></span><br></pre></td></tr></table></figure><p>4.<strong>相关系数</strong></p><p>主要实现方式：</p><ul><li>皮尔逊相关系数</li><li>斯皮尔曼相关系数</li></ul><p>1.<strong>皮尔逊相关系数</strong>(Pearson Correlation Coefficient)</p><p><strong>作用</strong>： 反映变量之间相关关系密切程度的统计指标 </p><p><strong>公式</strong>： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154029.png"/> </p><p> <strong>举例</strong>:</p><p>  比如说我们计算年广告费投入与月均销售额 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154004.png"/></p><p> 那么之间的相关系数怎么计算</p><p> <img src="%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B01.png" alt="img"> </p><p> 最终计算： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154000.png"/> </p><p>= 0.9942</p><p><strong>所以我们最终得出结论是广告投入费与月平均销售额之间有高度的正相关关系。</strong></p><p><strong>特点</strong>：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">相关系数的值介于–<span class="number">1</span>与+<span class="number">1</span>之间，即–<span class="number">1</span>≤ r ≤+<span class="number">1</span>。其性质如下：</span><br><span class="line">当r&gt;<span class="number">0</span>时，表示两变量正相关，r&lt;<span class="number">0</span>时，两变量为负相关</span><br><span class="line">当|r|=<span class="number">1</span>时，表示两变量为完全相关，当r=<span class="number">0</span>时，表示两变量间无相关关系</span><br><span class="line">当<span class="number">0</span>&lt;|r|&lt;<span class="number">1</span>时，表示两变量存在一定程度的相关。且|r|越接近<span class="number">1</span>，两变量间线性关系越密切；|r|越接近于<span class="number">0</span>，表示两变量的线性相关越弱</span><br><span class="line">一般可按三级划分：|r|&lt;<span class="number">0.4</span>为低度相关；<span class="number">0.4</span>≤|r|&lt;<span class="number">0.7</span>为显著性相关；<span class="number">0.7</span>≤|r|&lt;<span class="number">1</span>为高度线性相关</span><br></pre></td></tr></table></figure><p><strong>API</strong>：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">x : (N,) <span class="built_in">array</span>_like</span><br><span class="line">y : (N,) <span class="built_in">array</span>_like Returns: (Pearson’s correlation coefficient, p-value)</span><br></pre></td></tr></table></figure><p><strong>案例</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pea_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""皮尔逊相关系数"""</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    x1 = [<span class="number">12.5</span>, <span class="number">15.3</span>, <span class="number">23.2</span>, <span class="number">26.4</span>, <span class="number">33.5</span>, <span class="number">34.4</span>, <span class="number">39.4</span>, <span class="number">45.2</span>, <span class="number">55.4</span>, <span class="number">60.9</span>]</span><br><span class="line">    x2 = [<span class="number">21.2</span>, <span class="number">23.9</span>, <span class="number">32.9</span>, <span class="number">34.1</span>, <span class="number">42.5</span>, <span class="number">43.2</span>, <span class="number">49.0</span>, <span class="number">52.8</span>, <span class="number">59.4</span>, <span class="number">63.5</span>]</span><br><span class="line">    <span class="comment"># 判断</span></span><br><span class="line">    ret = pearsonr(x1, x2)</span><br><span class="line">    print(<span class="string">"皮尔逊相关系数:\n"</span>, ret)</span><br><span class="line">     </span><br><span class="line">pea_demo()</span><br><span class="line"><span class="comment"># (0.9941983762371883, 4.9220899554573455e-09)</span></span><br></pre></td></tr></table></figure><p>2.<strong>斯皮尔曼相关系数</strong>(Rank IC)</p><p><strong>作用</strong>： 反映变量之间相关关系密切程度的统计指标 </p><p><strong>公式</strong>：  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154022.png"/> </p><p>n为等级个数，d为二列成对变量的等级差数 </p><p><strong>特点</strong>：</p><figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">斯皮尔曼相关系数表明 <span class="keyword">X</span> (自变量) 和 <span class="keyword">Y</span> (因变量)的相关方向。 如果当<span class="keyword">X</span>增加时， <span class="keyword">Y</span> 趋向于增加, 斯皮尔曼相关系数则为正</span><br><span class="line">与之前的皮尔逊相关系数大小性质一样，取值 [<span class="number">-1</span>, <span class="number">1</span>]之间</span><br><span class="line">注意：斯皮尔曼相关系数比皮尔逊相关系数应用更加广泛</span><br></pre></td></tr></table></figure><p><strong>API</strong></p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br></pre></td></tr></table></figure><p><strong>案例</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spear_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""斯皮尔曼相关系数"""</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    x1 = [<span class="number">12.5</span>, <span class="number">15.3</span>, <span class="number">23.2</span>, <span class="number">26.4</span>, <span class="number">33.5</span>, <span class="number">34.4</span>, <span class="number">39.4</span>, <span class="number">45.2</span>, <span class="number">55.4</span>, <span class="number">60.9</span>]</span><br><span class="line">    x2 = [<span class="number">21.2</span>, <span class="number">23.9</span>, <span class="number">32.9</span>, <span class="number">34.1</span>, <span class="number">42.5</span>, <span class="number">43.2</span>, <span class="number">49.0</span>, <span class="number">52.8</span>, <span class="number">59.4</span>, <span class="number">63.5</span>]</span><br><span class="line">    <span class="comment"># 判断</span></span><br><span class="line">    ret = spearmanr(x1, x2)</span><br><span class="line">    print(<span class="string">"斯皮尔曼相关系数：\n"</span>, ret)</span><br><span class="line">    </span><br><span class="line">spear_demo()</span><br></pre></td></tr></table></figure><h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><h5 id="什么是主成分分析"><a href="#什么是主成分分析" class="headerlink" title="什么是主成分分析"></a>什么是主成分分析</h5><ul><li>定义：<strong>高维数据转化为低维数据的过程</strong>，在此过程中<strong>可能会舍弃原有数据、创造新的变量</strong></li><li>作用：<strong>是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。</strong></li><li>应用：回归分析或者聚类分析当中</li><li><strong>图示</strong>： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154036.png"/> </li></ul><h5 id="API"><a href="#API" class="headerlink" title="API"></a>API</h5><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.<span class="constructor">PCA(<span class="params">n_components</span>=None)</span></span><br><span class="line">- 将数据分解为较低维数空间</span><br><span class="line">- n_components:</span><br><span class="line">  - 小数：表示保留百分之多少的信息</span><br><span class="line">  - 整数：减少到多少特征</span><br><span class="line">- <span class="module-access"><span class="module"><span class="identifier">PCA</span>.</span></span>fit<span class="constructor">_transform(X)</span> X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">- 返回值：转换后指定维度的<span class="built_in">array</span></span><br></pre></td></tr></table></figure><h5 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对数据进行PCA降维</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>], [<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化PCA, 小数——保留多少信息</span></span><br><span class="line">    transfer = PCA(n_components=<span class="number">0.9</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data1 = transfer.fit_transform(data)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"保留90%的信息，降维结果为：\n"</span>, data1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化PCA, 整数——指定降维到的维数</span></span><br><span class="line">    transfer2 = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data2 = transfer2.fit_transform(data)</span><br><span class="line">    print(<span class="string">"降维到3维的结果：\n"</span>, data2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pca_demo()</span><br><span class="line">    </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">保留90%的信息，降维结果为：</span></span><br><span class="line"><span class="string"> [[ -3.13587302e-16   3.82970843e+00]</span></span><br><span class="line"><span class="string"> [ -5.74456265e+00  -1.91485422e+00]</span></span><br><span class="line"><span class="string"> [  5.74456265e+00  -1.91485422e+00]]</span></span><br><span class="line"><span class="string">降维到3维的结果：</span></span><br><span class="line"><span class="string"> [[ -3.13587302e-16   3.82970843e+00   4.59544715e-16]</span></span><br><span class="line"><span class="string"> [ -5.74456265e+00  -1.91485422e+00   4.59544715e-16]</span></span><br><span class="line"><span class="string"> [  5.74456265e+00  -1.91485422e+00   4.59544715e-16]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">降维的定义：就是改变特征值，选择哪列保留，哪列删除，目标是得到一组”不相关“的主变量</span><br><span class="line">降维的两种方式：<span class="number">1.</span>特征选择，<span class="number">2.</span>主成分分析（可以理解一种特征提取的方式）</span><br><span class="line">特征选择</span><br><span class="line">定义：提出数据中的冗余变量</span><br><span class="line">方法：</span><br><span class="line">Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联</span><br><span class="line">方差选择法：低方差特征过滤</span><br><span class="line">相关系数</span><br><span class="line">Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）</span><br><span class="line">决策树:信息熵、信息增益</span><br><span class="line">正则化：L1、L2</span><br><span class="line">低方差特征过滤:把方差比较小的某一列进行剔除</span><br><span class="line">api:sklearn.feature_selection.VarianceThreshold(threshold = <span class="number">0.0</span>)</span><br><span class="line">删除所有低方差特征</span><br><span class="line">注意，参数threshold一定要进行值的指定</span><br><span class="line">相关系数</span><br><span class="line">主要实现方式：</span><br><span class="line">皮尔逊相关系数</span><br><span class="line">通过具体值的大小进行计算</span><br><span class="line">相对复杂</span><br><span class="line">api:<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">返回值，越接近|<span class="number">1</span>|，相关性越强；越接近<span class="number">0</span>，相关性越弱</span><br><span class="line">斯皮尔曼相关系数</span><br><span class="line">通过等级差进行计算</span><br><span class="line">比上一个简单</span><br><span class="line">api:<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br><span class="line">返回值，越接近|<span class="number">1</span>|，相关性越强；越接近<span class="number">0</span>，相关性越弱</span><br><span class="line">主成分分析pca</span><br><span class="line">定义：高维数据转换为低维数据，然后产生了新的变量</span><br><span class="line">api:sklearn.decomposition.PCA(n_components=None)</span><br><span class="line">n_components</span><br><span class="line">整数 -- 表示降低到几维</span><br><span class="line">小数 -- 保留百分之多少的信息</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;学习目标&quot;&gt;&lt;a href=&quot;#学习目标&quot; class=&quot;headerlink&quot; title=&quot;学习目标&quot;&gt;&lt;/a&gt;学习目标&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;了解降维的定义&lt;/li&gt;
&lt;li&gt;知道通过低方差过滤实现降维过程&lt;/li&gt;
&lt;li&gt;知道相关系数实现降维的过程&lt;/li&gt;
&lt;li&gt;知道主成分分析法实现过程&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="特征工程" scheme="https://xiaoliaozi.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="特征降维" scheme="https://xiaoliaozi.com/tags/%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"/>
    
      <category term="特征选择" scheme="https://xiaoliaozi.com/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="主成分分析" scheme="https://xiaoliaozi.com/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>聚类算法</title>
    <link href="https://xiaoliaozi.com/2020/02/01/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>https://xiaoliaozi.com/2020/02/01/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</id>
    <published>2020-02-01T05:09:38.000Z</published>
    <updated>2020-02-27T07:43:11.565Z</updated>
    
    <content type="html"><![CDATA[<h4 id="聚类算法简介"><a href="#聚类算法简介" class="headerlink" title="聚类算法简介"></a>聚类算法简介</h4><p> <strong>使用不同的聚类准则，产生的聚类结果不同</strong>。 </p><a id="more"></a><ol><li><h5 id="聚类算法在现实中的应用"><a href="#聚类算法在现实中的应用" class="headerlink" title="聚类算法在现实中的应用"></a>聚类算法在现实中的应用</h5><ul><li>用户画像，广告推荐，Data Segmentation，搜索引擎的流量推荐，恶意流量识别</li><li>基于位置信息的商业推送，新闻聚类，筛选排序</li><li>图像分割，降维，识别；离群点检测；信用卡异常消费；发掘相同功能的基因片段</li></ul></li><li><h5 id="聚类算法的概念"><a href="#聚类算法的概念" class="headerlink" title="聚类算法的概念"></a>聚类算法的概念</h5><p>一种典型的<strong>无监督</strong>学习算法，主要用于将相似的样本自动归到一个类别中。在聚类算法中根据样本之间的相似性，将样本划分到不同的类别中，对于不同的相似度计算方法，会得到不同的聚类结果，常用的相似度计算方法有欧式距离法。</p></li><li><h5 id="聚类算法与分类算法最大的区别"><a href="#聚类算法与分类算法最大的区别" class="headerlink" title="聚类算法与分类算法最大的区别"></a>聚类算法与分类算法最大的区别</h5><p> 聚类算法是无监督的学习算法，而分类算法属于监督的学习算法。 </p></li></ol><h4 id="聚类算法API"><a href="#聚类算法API" class="headerlink" title="聚类算法API"></a>聚类算法API</h4><ol><li><h5 id="API介绍"><a href="#API介绍" class="headerlink" title="API介绍"></a>API介绍</h5><figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans(n_clusters=<span class="number">8</span>)</span><br><span class="line">参数:</span><br><span class="line">n_clusters:开始的聚类中心数量</span><br><span class="line">整型，缺省值=<span class="number">8</span>，生成的聚类数，即产生的质心（centroids）数。</span><br><span class="line">方法:</span><br><span class="line">estimator.fit(<span class="symbol">x</span>)</span><br><span class="line">estimator.predict(<span class="symbol">x</span>)</span><br><span class="line">estimator.fit_predict(<span class="symbol">x</span>)</span><br><span class="line">计算聚类中心并预测每个样本属于哪个类别,相当于先调用fit(<span class="symbol">x</span>),然后再调用predict(<span class="symbol">x</span>)</span><br></pre></td></tr></table></figure></li><li><h5 id="小案例"><a href="#小案例" class="headerlink" title="小案例"></a>小案例</h5><p> 随机创建不同二维数据集作为训练集，并结合k-means算法将其聚类，你可以尝试分别聚类不同数量的簇，并观察聚类效果： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112324.png"/> </p><p> 聚类参数n_cluster传值不同，得到的聚类结果不同 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227141148.png"/> </p><p>1.<strong>流程分析</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112232.png"/> </p><p>2.<strong>代码实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> calinski_harabaz_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建数据集</span></span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，</span></span><br><span class="line"><span class="comment"># 簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2, 0.2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>, centers=[[<span class="number">-1</span>, <span class="number">-1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line">                  cluster_std=[<span class="number">0.4</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span><br><span class="line">                  random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集可视化</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">'o'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.使用k-means进行聚类,并使用CH方法评估</span></span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=<span class="number">9</span>).fit_predict(X)</span><br><span class="line"><span class="comment"># 分别尝试n_cluses=2\3\4,然后查看聚类效果</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用Calinski-Harabasz Index评估的聚类分数</span></span><br><span class="line">print(calinski_harabaz_score(X, y_pred))</span><br></pre></td></tr></table></figure></li></ol><h4 id="聚类算法实现流程"><a href="#聚类算法实现流程" class="headerlink" title="聚类算法实现流程"></a>聚类算法实现流程</h4><blockquote><p><strong>k-means其实包含两层内容：</strong></p><ul><li>K : 初始中心点个数（计划聚类数）</li><li>means：求中心点到其他数据点距离的平均值</li></ul></blockquote><h5 id="1-k-means聚类步骤"><a href="#1-k-means聚类步骤" class="headerlink" title="1. k-means聚类步骤"></a>1. k-means聚类步骤</h5><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、随机设置K个特征空间内的点作为初始的聚类中心</span><br><span class="line"><span class="number">2</span>、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</span><br><span class="line"><span class="number">3</span>、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</span><br><span class="line"><span class="number">4</span>、如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程</span><br></pre></td></tr></table></figure><p> 通过下图解释实现流程： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111050.png"/></p><p>  k聚类动态效果图 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227141741.png"/></p><h5 id="2-案例练习"><a href="#2-案例练习" class="headerlink" title="2.案例练习"></a>2.案例练习</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112202.png"/></p><p>  1.随机设置K个特征空间内的点作为初始的聚类中心（本案例中设置p1和p2） </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112154.png"/></p><p>  2.对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112148.png"/></p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112139.png"/></p><p>  3.接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值） </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112132.png"/></p><p> 4.如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程【经过判断，需要重复上述步骤，开始新一轮迭代】 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112123.png"/></p><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112119.png"/> </p><p>  5.当每次迭代结果不变时，认为算法收敛，聚类完成，<strong>K-Means一定会停下，不可能陷入一直选质心的过程。</strong> </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112105.png"/></p><h4 id="聚类算法模型评估"><a href="#聚类算法模型评估" class="headerlink" title="聚类算法模型评估"></a>聚类算法模型评估</h4><h5 id="1-误差平方和-SSE-The-sum-of-squares-due-to-error"><a href="#1-误差平方和-SSE-The-sum-of-squares-due-to-error" class="headerlink" title="1.误差平方和(SSE \The sum of squares due to error)"></a>1.误差平方和(SSE \The sum of squares due to error)</h5><p> 举例:(下图中数据-0.2, 0.4, -0.8, 1.3, -0.7, 均为真实值和预测值的差) </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110835.png"/></p><p>  在k-means中的应用: </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110825.png"/></p><p>  <img src="%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/sse3.png" alt="image-20190219173610490"> </p><p> 公式各部分内容: </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110811.png"/></p><p> 上图中: k=2</p><ul><li><p><strong>SSE图最终的结果，对图松散度的衡量.</strong>(eg: **SSE(左图))</p></li><li><p>SSE随着聚类迭代，其值会越来越小，直到最后趋于稳定</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110737.png"/> </p></li><li><p>如果质心的初始值选择不好，SSE只会达到一个不怎么好的局部最优解. </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227101738.png"/> </p></li></ul><h5 id="2-“肘”方法-Elbow-method-—-K值确定"><a href="#2-“肘”方法-Elbow-method-—-K值确定" class="headerlink" title="2.“肘”方法 (Elbow method) — K值确定"></a>2.“肘”方法 (Elbow method) — K值确定</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112225.png"/></p><p> （1）对于n个点的数据集，迭代计算k from 1 to n，每次聚类完成后计算每个点到其所属的簇中心的距离的平方和；</p><p>（2）平方和是会逐渐变小的，直到k==n时平方和为0，因为每个点都是它所在的簇中心本身。</p><p>（3）在这个平方和变化过程中，会出现一个拐点也即“肘”点，<strong>下降率突然变缓时即认为是最佳的k值</strong>。</p><p>在决定什么时候停止训练时，肘形判据同样有效，数据通常有更多的噪音，在<strong>增加分类无法带来更多回报时，我们停止增加类别</strong>。</p><h5 id="3-轮廓系数法（Silhouette-Coefficient）"><a href="#3-轮廓系数法（Silhouette-Coefficient）" class="headerlink" title="3.轮廓系数法（Silhouette Coefficient）"></a>3.轮廓系数法（Silhouette Coefficient）</h5><p> 结合了聚类的凝聚度（Cohesion）和分离度（Separation），用于评估聚类的效果： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111035.png"/></p><p> <strong>目的：</strong> 内部距离最小化，外部距离最大化</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110928.png"/> </p><p>计算样本$i$到同簇其他样本的平均距离$a_i$，$a_i$ 越小样本i的簇内不相似度越小，说明样本$i$越应该被聚类到该簇。</p><p>计算样本i到最近簇$C<em>j$ 的所有样本的平均距离$b</em>(ij)$，称样本$i$与最近簇$C_j$ 的不相似度，定义为样本i的簇间不相似度：</p><p>$b<em>i =min{b</em>(i1), b<em>(i2), …, b</em>(ik)}$，$b_i$越大，说明样本$i$越不属于其他簇。</p><p>求出所有样本的轮廓系数后再求平均值就得到了<strong>平均轮廓系数</strong>。</p><p>平均轮廓系数的取值范围为[-1,1]，系数越大，聚类效果越好。</p><p>簇内样本的距离越近，簇间样本距离越远</p><p><strong>案例：</strong></p><p>下图是500个样本含有2个feature的数据分布情况，我们对它进行SC系数效果衡量：</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110915.png"/> </p><p><strong>n_clusters = 2 The average silhouette_score is : 0.7049787496083262</strong></p><p>n_clusters = 3 The average silhouette_score is : 0.5882004012129721</p><p><strong>n_clusters = 4 The average silhouette_score is : 0.6505186632729437</strong></p><p>n_clusters = 5 The average silhouette_score is : 0.56376469026194</p><p>n_clusters = 6 The average silhouette_score is : 0.4504666294372765</p><p>n_clusters 分别为 2，3，4，5，6时，SC系数如下，是介于[-1,1]之间的度量指标：</p><p><strong>每次聚类后，每个样本都会得到一个轮廓系数，当它为1时，说明这个点与周围簇距离较远，结果非常好，当它为0，说明这个点可能处在两个簇的边界上，当值为负时，暗含该点可能被误分了。</strong></p><p>从平均SC系数结果来看，K取3，5，6是不好的，那么2和4呢？</p><p>k=2的情况：</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110855.png"/></p><p>  k=4的情况： </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227142806.png"/></p><p> n_clusters = 2时，第0簇的宽度远宽于第1簇；</p><p>n_clusters = 4时，所聚的簇宽度相差不大，因此选择K=4，作为最终聚类个数。</p><h5 id="4-CH系数（Calinski-Harabasz-Index）"><a href="#4-CH系数（Calinski-Harabasz-Index）" class="headerlink" title="4.CH系数（Calinski-Harabasz Index）"></a>4.CH系数（Calinski-Harabasz Index）</h5><p><strong>Calinski-Harabasz：</strong>类别内部数据的协方差越小越好，类别之间的协方差越大越好（换句话说：类别内部数据的距离平方和越小越好，类别之间的距离平方和越大越好），</p><p>这样的Calinski-Harabasz分数s会高，分数s高则聚类效果越好。</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112338.png"/> </p><p>tr为<strong>矩阵的迹</strong>, Bk为类别之间的协方差矩阵，Wk为类别内部数据的协方差矩阵;</p><p>m为训练集样本数，k为类别数。</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112330.png"/></p><p> 使用矩阵的迹进行求解的理解：</p><p>矩阵的对角线可以表示一个物体的相似性</p><p>在机器学习里，主要为了获取数据的特征值，那么就是说，在任何一个矩阵计算出来之后，都可以简单化，只要获取矩阵的迹，就可以表示这一块数据的最重要的特征了，这样就可以把很多无关紧要的数据删除掉，达到简化数据，提高处理速度。</p><p>CH需要达到的目的：<strong>用尽量少的类别聚类尽量多的样本，同时获得较好的聚类效果。</strong></p><h4 id="聚类算法算法优化"><a href="#聚类算法算法优化" class="headerlink" title="聚类算法算法优化"></a>聚类算法算法优化</h4><p><strong>k-means算法小结</strong></p><p><strong>优点：</strong></p><p> 1.原理简单（靠近中心点），实现容易</p><p> 2.聚类效果中上（依赖K的选择）</p><p> 3.空间复杂度o(N)，时间复杂度o(I<em>K</em>N)</p><blockquote><p>N为样本点个数，K为中心点个数，I为迭代次数</p></blockquote><p><strong>缺点：</strong></p><p> 1.对离群点，噪声敏感 （中心点易偏移）</p><p> 2.很难发现大小差别很大的簇及进行增量计算</p><p> 3.结果不一定是全局最优，只能保证局部最优（与K的个数及初值选取有关）</p><h5 id="1-Canopy算法配合初始聚类"><a href="#1-Canopy算法配合初始聚类" class="headerlink" title="1.Canopy算法配合初始聚类"></a>1.Canopy算法配合初始聚类</h5><p>Canopy算法配合初始聚类实现流程：</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112345.png"/></p><p> 优点：</p><ol><li><p>Kmeans对噪声抗干扰较弱，通过Canopy对比，将较小的NumPoint的Cluster直接去掉有利于抗干扰。</p></li><li><p>Canopy选择出来的每个Canopy的centerPoint作为K会更精确。</p></li><li><p>只是针对每个Canopy的内做Kmeans聚类，减少相似计算的数量。</p></li></ol><p>缺点：</p><p> 算法中 T1、T2的确定问题 ，依旧可能落入局部最优解</p><h5 id="2-K-means"><a href="#2-K-means" class="headerlink" title="2.K-means++"></a>2.K-means++</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111237.png"/> </p><p>  其中： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111057.png"/></p><p>  为方便后面表示，把其记为A </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111217.png"/></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111212.png"/> </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111104.png"/></p><p> kmeans++目的，让选择的质心尽可能的分散</p><p>如下图中，如果第一个质心选择在圆心，那么最优可能选择到的下一个点在P(A)这个区域（根据颜色进行划分）</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111230.png"/></p><h5 id="3-二分k-means"><a href="#3-二分k-means" class="headerlink" title="3.二分k-means"></a>3.二分k-means</h5><p>实现流程:</p><ol><li><p>所有点作为一个簇</p></li><li><p>将该簇一分为二</p></li><li><p>选择能最大限度降低聚类代价函数（也就是误差平方和）的簇划分为两个簇。</p></li><li><p>以此进行下去，直到簇的数目等于用户给定的数目k为止。</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112217.png"/> </p></li></ol><p><strong>隐含的一个原则</strong></p><p>因为聚类的误差平方和能够衡量聚类性能，该值越小表示数据点越接近于他们的质心，聚类效果就越好。所以需要对误差平方和最大的簇进行再一次划分，因为误差平方和越大，表示该簇聚类效果越不好，越有可能是多个簇被当成了一个簇，所以我们首先需要对这个簇进行划分。</p><p>二分K均值算法可以加速K-means算法的执行速度，因为它的相似度计算少了并且不受初始化问题的影响，因为这里不存在随机点的选取，且每一步都保证了误差最小</p><h5 id="4-k-medoids（k-中心聚类算法）"><a href="#4-k-medoids（k-中心聚类算法）" class="headerlink" title="4.k-medoids（k-中心聚类算法）"></a>4.k-medoids（k-中心聚类算法）</h5><p>K-medoids和K-means是有区别的，<strong>不一样的地方在于中心点的选取</strong></p><ul><li>K-means中，将中心点取为当前cluster中所有数据点的平均值，对异常点很敏感!</li><li><p>K-medoids中，将从当前cluster 中选取到其他所有（当前cluster中的）点的距离之和最小的点作为中心点。</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111042.png"/></p><p>算法流程：</p></li></ul><p>　　 ( 1 )总体n个样本点中任意选取k个点作为medoids</p><p>　　 ( 2 )按照与medoids最近的原则，将剩余的n-k个点分配到当前最佳的medoids代表的类中</p><p>　　 ( 3 )对于第i个类中除对应medoids点外的所有其他点，按顺序计算当其为新的medoids时，代价函数的值，遍历所有可能，选取代价函数最小时对应的点作为新的medoids</p><p>　　 ( 4 )重复2-3的过程，直到所有的medoids点不再发生变化或已达到设定的最大迭代次数</p><p>　　 ( 5 )产出最终确定的k个类</p><p><strong>k-medoids对噪声鲁棒性好。</strong></p><p>例：当一个cluster样本点只有少数几个，如（1,1）（1,2）（2,1）（1000,1000）。其中（1000,1000）是噪声。如果按照k-means质心大致会处在（1,1）（1000,1000）中间，这显然不是我们想要的。这时k-medoids就可以避免这种情况，他会在（1,1）（1,2）（2,1）（1000,1000）中选出一个样本点使cluster的绝对误差最小，计算可知一定会在前三个点中选取。</p><p>k-medoids只能对小样本起作用，样本大，速度就太慢了，当样本多的时候，少数几个噪音对k-means的质心影响也没有想象中的那么重，所以k-means的应用明显比k-medoids多。</p><h5 id="5-Kernel-k-means"><a href="#5-Kernel-k-means" class="headerlink" title="5.Kernel k-means"></a>5.Kernel k-means</h5><p> kernel k-means实际上，就是将每个样本进行一个投射到高维空间的处理，然后再将处理后的数据使用普通的k-means算法思想进行聚类。 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112209.png"/></p><h5 id="6-ISODATA"><a href="#6-ISODATA" class="headerlink" title="6.ISODATA"></a>6.ISODATA</h5><p>类别数目随着聚类过程而变化；</p><p>对类别数会进行合并，分裂，</p><p>“合并”：（当聚类结果某一类中样本数太少，或两个类间的距离太近时）</p><p>“分裂”：（当聚类结果中某一类的类内方差太大，将该类进行分裂）</p><h5 id="7-Mini-Batch-K-Means"><a href="#7-Mini-Batch-K-Means" class="headerlink" title="7.Mini Batch K-Means"></a>7.Mini Batch K-Means</h5><p>适合大数据的聚类算法</p><p>大数据量是什么量级？通常当样本量大于1万做聚类时，就需要考虑选用Mini Batch K-Means算法。</p><p>Mini Batch KMeans使用了Mini Batch（分批处理）的方法对数据点之间的距离进行计算。</p><p>Mini Batch计算过程中不必使用所有的数据样本，而是从不同类别的样本中抽取一部分样本来代表各自类型进行计算。由于计算样本量少，所以会相应的减少运行时间，但另一方面抽样也必然会带来准确度的下降。</p><p>该算法的迭代步骤有两步：</p><p>(1)从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</p><p>(2)更新质心</p><p> 与Kmeans相比，数据的更新在每一个小的样本集上。对于每一个小批量，通过计算平均值得到更新质心，并把小批量里的数据分配给该质心，随着迭代次数的增加，这些质心的变化是逐渐减小的，直到质心稳定或者达到指定的迭代次数，停止计算。</p><p><strong>总结</strong></p><div class="table-container"><table><thead><tr><th><strong>优化方法</strong></th><th><strong>思路</strong></th></tr></thead><tbody><tr><td>Canopy+kmeans</td><td>Canopy粗聚类配合kmeans</td></tr><tr><td>kmeans++</td><td>距离越远越容易成为新的质心</td></tr><tr><td>二分k-means</td><td>拆除SSE最大的簇</td></tr><tr><td>k-medoids</td><td>和kmeans选取中心点的方式不同</td></tr><tr><td>kernel kmeans</td><td>映射到高维空间</td></tr><tr><td>ISODATA</td><td>动态聚类，可以更改K值大小</td></tr><tr><td>Mini-batch K-Means</td><td>大数据集分批聚类</td></tr></tbody></table></div><h4 id="案例-探究用户对物品类别的喜好细分"><a href="#案例-探究用户对物品类别的喜好细分" class="headerlink" title="案例-探究用户对物品类别的喜好细分"></a>案例-探究用户对物品类别的喜好细分</h4><h5 id="1-数据介绍"><a href="#1-数据介绍" class="headerlink" title="1.数据介绍"></a>1.数据介绍</h5><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">数据如下：</span><br><span class="line"><span class="keyword">order_products__prior.csv：订单与商品信息</span></span><br><span class="line"><span class="keyword">字段：order_id, </span>product_id, <span class="keyword">add_to_cart_order, </span>reordered</span><br><span class="line">products.csv：商品信息</span><br><span class="line">字段：product_id, product_name, aisle_id, department_id</span><br><span class="line"><span class="keyword">orders.csv：用户的订单信息</span></span><br><span class="line"><span class="keyword">字段：order_id,user_id,eval_set,order_number,….</span></span><br><span class="line"><span class="keyword">aisles.csv：商品所属具体物品类别</span></span><br><span class="line"><span class="keyword">字段： </span>aisle_id, aisle</span><br></pre></td></tr></table></figure><h5 id="2-需求分析"><a href="#2-需求分析" class="headerlink" title="2.需求分析"></a>2.需求分析</h5><ol><li><p>获取数据</p></li><li><p>数据基本处理</p><p>2.1  合并表格</p><p>2.2 交叉表合并</p><p>2.3 数据截取</p></li><li><p>特征工程 — pca</p></li><li><p>机器学习（k-means）</p></li><li><p>模型评估</p><p>sklearn.metrics.silhouette_score(X, labels)</p><p>计算所有样本的平均轮廓系数</p><p>X：特征值</p><p>labels：被聚类标记的目标值</p></li></ol><h5 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3.代码实现"></a>3.代码实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据</span></span><br><span class="line">order_product = pd.read_csv(<span class="string">"./data/instacart/order_products__prior.csv"</span>)</span><br><span class="line">products = pd.read_csv(<span class="string">"./data/instacart/products.csv"</span>)</span><br><span class="line">orders = pd.read_csv(<span class="string">"./data/instacart/orders.csv"</span>)</span><br><span class="line">aisles = pd.read_csv(<span class="string">"./data/instacart/aisles.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据基本处理</span></span><br><span class="line"><span class="comment"># 2.1 合并表格</span></span><br><span class="line">table1 = pd.merge(order_product, products, on=[<span class="string">"product_id"</span>, <span class="string">"product_id"</span>])</span><br><span class="line">table2 = pd.merge(table1, orders, on=[<span class="string">"order_id"</span>, <span class="string">"order_id"</span>])</span><br><span class="line">table = pd.merge(table2, aisles, on=[<span class="string">"aisle_id"</span>, <span class="string">"aisle_id"</span>])</span><br><span class="line"><span class="comment"># 2.2 交叉表合并</span></span><br><span class="line">table = pd.crosstab(table[<span class="string">"user_id"</span>], table[<span class="string">"aisle"</span>])</span><br><span class="line"><span class="comment"># 2.3 数据截取</span></span><br><span class="line">table = table[:<span class="number">1000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程 — pca</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">0.9</span>)</span><br><span class="line">data = transfer.fit_transform(table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.机器学习（k-means）</span></span><br><span class="line">estimator = KMeans(n_clusters=<span class="number">8</span>, random_state=<span class="number">22</span>)</span><br><span class="line">estimator.fit_predict(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line">silhouette_score(data, y_predict)</span><br></pre></td></tr></table></figure><h4 id="拓展-算法选择指导"><a href="#拓展-算法选择指导" class="headerlink" title="拓展-算法选择指导"></a>拓展-算法选择指导</h4><p><strong>关于在计算的过程中，如何选择合适的算法进行计算，可以参考scikit learn官方给的指导意见：</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110840.png"/> </p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;聚类算法简介&quot;&gt;&lt;a href=&quot;#聚类算法简介&quot; class=&quot;headerlink&quot; title=&quot;聚类算法简介&quot;&gt;&lt;/a&gt;聚类算法简介&lt;/h4&gt;&lt;p&gt; &lt;strong&gt;使用不同的聚类准则，产生的聚类结果不同&lt;/strong&gt;。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习算法" scheme="https://xiaoliaozi.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="机器" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8/"/>
    
      <category term="学习机器学习算法" scheme="https://xiaoliaozi.com/tags/%E5%AD%A6%E4%B9%A0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
      <category term="聚类算法" scheme="https://xiaoliaozi.com/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
      <category term="无监督学习算法" scheme="https://xiaoliaozi.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>推荐算法</title>
    <link href="https://xiaoliaozi.com/2020/01/15/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    <id>https://xiaoliaozi.com/2020/01/15/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</id>
    <published>2020-01-15T03:12:49.000Z</published>
    <updated>2020-02-27T07:54:30.607Z</updated>
    
    <content type="html"><![CDATA[<h4 id="推荐模型构建流程"><a href="#推荐模型构建流程" class="headerlink" title="推荐模型构建流程"></a>推荐模型构建流程</h4><blockquote><p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(选择算法训练模型)-&gt;Prediction Output(预测输出) </p></blockquote><a id="more"></a><ul><li><p>数据清洗/数据处理 </p><ul><li><p>数据来源</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- 显性数据</span><br><span class="line">  - Rating 打分</span><br><span class="line">  - Comments 评论/评价</span><br><span class="line">- 隐形数据</span><br><span class="line">  -  Order history 历史订单</span><br><span class="line">  -  Cart events 加购物车</span><br><span class="line">  - <span class="built_in"> Page </span>views 页面浏览</span><br><span class="line">  -  Click-thru 点击</span><br><span class="line">  -  Search log 搜索记录</span><br></pre></td></tr></table></figure></li><li><p>数据量/数据能否满足要求</p></li></ul></li><li><p>特征工程 </p><ul><li><p>从数据中筛选特征</p><ul><li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li><li>使用用户行为数据描述商品</li></ul></li><li><p>用数据表示特征</p><ul><li>将所有用户行为合并在一起 ，形成一个user-item 矩阵</li></ul></li></ul></li><li><p>选择合适的算法 </p><ul><li><p><strong>协同过滤</strong></p></li><li><p>基于内容</p></li></ul></li><li><p>产生推荐结果</p><ul><li>对推荐结果进行评估（评估方法后面章节介绍），评估通过后上线</li></ul></li></ul><h4 id="最经典的推荐算法：协同过滤推荐算法"><a href="#最经典的推荐算法：协同过滤推荐算法" class="headerlink" title="最经典的推荐算法：协同过滤推荐算法"></a>最经典的推荐算法：协同过滤推荐算法</h4><p>协同过滤推荐算法（Collaborative Filtering）</p><p>算法思想： <strong>物以类聚，人以群分</strong> </p><p> 基本的协同过滤推荐算法基于以下假设： </p><ul><li>“跟你喜好<strong>相似的人</strong>喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）</li><li><p>“跟你喜欢的东西<strong>相似的东西</strong>你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）</p><p>实现协同过滤推荐步骤： </p></li></ul><p>1.<strong>找出最相似的人或物品：TOP-N相似的人或物品</strong></p><p>通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品</p><p>2.<strong>根据相似的人或物品产生推荐结果</strong></p><p>利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品</p><p>简单例子：</p><p>  User-Based CF <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154653.png"/></p><p> Item-Based CF   <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154700.png"/> </p><h4 id="相似度计算-Similarity-Calculation"><a href="#相似度计算-Similarity-Calculation" class="headerlink" title="相似度计算(Similarity Calculation)"></a>相似度计算(Similarity Calculation)</h4><h5 id="相似度的计算方法"><a href="#相似度的计算方法" class="headerlink" title="相似度的计算方法"></a>相似度的计算方法</h5><p>1.<strong>欧氏距离</strong>， 是一个欧式空间下度量距离的方法. 两个物体， 都在同一个空间下表示为两个点,，假如叫做p，q， 分别都是n个坐标，那么欧式距离就是衡量这两个点之间的距离.。欧氏距离不适用于布尔向量之间。</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155047.png"/></p><p>  欧氏距离的值是一个非负数, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154824.png"/></p><p>2.<strong>余弦相似度</strong> </p><ul><li>度量的是两个向量之间的夹角，用夹角的余弦值来度量相似的情况</li><li>两个向量的夹角为0是，余弦值为1，当夹角为90度是余弦值为0，为180度是余弦值为-1</li><li>余弦相似度在度量文本相似度, 用户相似度 物品相似度的时候较为常用</li><li><p>余弦相似度的特点， 与向量长度无关，余弦相似度计算要对向量长度归一化， 两个向量只要方向一致，无论程度强弱，都可以视为’相似’</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155116.png"/></p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154815.png"/></p></li></ul><h5 id="皮尔逊相关系数Pearson"><a href="#皮尔逊相关系数Pearson" class="headerlink" title="皮尔逊相关系数Pearson"></a>皮尔逊相关系数Pearson</h5><ul><li>实际上也是余弦相似度，不过先对向量做了中心化，向量a，b各自减去向量的均值后, 再计算余弦相似度</li><li>皮尔逊相似度计算结果在-1，1之间 -1表示负相关， 1表示正相关</li><li>度量两个变量是不是同增同减</li><li><p>皮尔逊相关系数度量的是两个变量的变化趋势是否一致，<strong>不适合计算布尔值向量之间的相关度</strong></p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154731.png"/> </p></li></ul><h5 id="杰卡德相似度-Jaccard"><a href="#杰卡德相似度-Jaccard" class="headerlink" title="杰卡德相似度 Jaccard"></a>杰卡德相似度 Jaccard</h5><ul><li>两个集合的交集元素个数在并集中所占的比例，非常适用于布尔向量表示</li><li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li><li><p>分母是两个布尔向量做或运算， 再求元素和</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154906.png"/> </p></li></ul><h5 id="如何选择余弦相似度"><a href="#如何选择余弦相似度" class="headerlink" title="如何选择余弦相似度"></a>如何选择余弦相似度</h5><ul><li>余弦相似度/皮尔逊相关系数适合用户评分数据(实数值)；</li><li>杰卡德相似度适用于隐式反馈数据(0，1布尔值 是否收藏，是否点击，是否加购物车)</li></ul><h4 id="协同过滤推荐算法代码案例"><a href="#协同过滤推荐算法代码案例" class="headerlink" title="协同过滤推荐算法代码案例"></a>协同过滤推荐算法代码案例</h4><p>1.构建数据集 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 构建数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>2.计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的： </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure><p>3 .有了数据集，接下来我们就可以进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。这里我们选择使用杰卡德相似系数[0,1] </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> jaccard_similarity_score</span><br><span class="line"><span class="comment"># 直接计算某两项的杰卡德相似系数</span></span><br><span class="line"><span class="comment"># 计算Item A 和Item B的相似度</span></span><br><span class="line">print(jaccard_similarity_score(df[<span class="string">"Item A"</span>], df[<span class="string">"Item B"</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line">print(user_similar)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">print(item_similar)</span><br></pre></td></tr></table></figure><p> 有了两两的相似度，接下来就可以筛选TOP-N相似结果，并进行推荐了 </p><p>4.User-Based CF </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度  1-杰卡德距离=杰卡德相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line">print(user_similar)</span><br><span class="line"></span><br><span class="line">topN_users = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> user_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = user_similar.loc[i].drop([i])</span><br><span class="line">    <span class="comment">#sort_values 排序 按照相似度降序排列</span></span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 从排序之后的结果中切片 取出前两条（相似度最高的两个）</span></span><br><span class="line">    top2 = list(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_users[i] = top2</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Top2相似用户："</span>)</span><br><span class="line">pprint(topN_users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备空白dict用来保存推荐结果</span></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment">#遍历所有的最相似用户</span></span><br><span class="line"><span class="keyword">for</span> user, sim_users <span class="keyword">in</span> topN_users.items():</span><br><span class="line">    rs_result = set()    <span class="comment"># 存储推荐结果</span></span><br><span class="line">    <span class="keyword">for</span> sim_user <span class="keyword">in</span> sim_users:</span><br><span class="line">        <span class="comment"># 构建初始的推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(set(df.ix[sim_user].replace(<span class="number">0</span>,np.nan).dropna().index))</span><br><span class="line">    <span class="comment"># 过滤掉已经购买过的物品</span></span><br><span class="line">    rs_result -= set(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line">print(<span class="string">"最终推荐结果："</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure><p>5.Item-Based CF </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">print(item_similar)</span><br><span class="line"></span><br><span class="line">topN_items = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> item_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = item_similar.loc[i].drop([i])</span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    top2 = list(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_items[i] = top2</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Top2相似物品："</span>)</span><br><span class="line">pprint(topN_items)</span><br><span class="line"></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment"># 构建推荐结果</span></span><br><span class="line"><span class="keyword">for</span> user <span class="keyword">in</span> df.index:    <span class="comment"># 遍历所有用户</span></span><br><span class="line">    rs_result = set()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index:   <span class="comment"># 取出每个用户当前已购物品列表</span></span><br><span class="line">        <span class="comment"># 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(topN_items[item])</span><br><span class="line">    <span class="comment"># 过滤掉用户已购的物品</span></span><br><span class="line">    rs_result -= set(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    <span class="comment"># 添加到结果中</span></span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line"></span><br><span class="line">print(<span class="string">"最终推荐结果："</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure><h4 id="关于协同过滤推荐算法使用的数据集"><a href="#关于协同过滤推荐算法使用的数据集" class="headerlink" title="关于协同过滤推荐算法使用的数据集"></a>关于协同过滤推荐算法使用的数据集</h4><p>在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测。</p><p>因此在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据。</p><h5 id="关于用户-物品评分矩阵"><a href="#关于用户-物品评分矩阵" class="headerlink" title="关于用户-物品评分矩阵"></a>关于用户-物品评分矩阵</h5><p> 用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案 </p><ul><li><p><strong>稠密评分矩阵</strong> </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154715.png"/> </p></li><li><p><strong>稀疏评分矩阵</strong> </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154645.png"/> </p></li></ul><h4 id="使用协同过滤推荐算法对用户进行评分预测"><a href="#使用协同过滤推荐算法对用户进行评分预测" class="headerlink" title="使用协同过滤推荐算法对用户进行评分预测"></a>使用协同过滤推荐算法对用户进行评分预测</h4><ul><li><p>数据集 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154709.png"/></p><p> <strong>目的：预测用户1对物品E的评分</strong> </p></li><li><p>构建数据集：注意这里构建评分数据时，对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li><li><p>计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关</p><blockquote><p>pandas中corr方法可直接用于计算皮尔逊相关系数 </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line"><span class="comment"># 直接计算皮尔逊相关系数</span></span><br><span class="line"><span class="comment"># 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置</span></span><br><span class="line">user_similar = df.T.corr()</span><br><span class="line">print(user_similar.round(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">item_similar = df.corr()</span><br><span class="line">print(item_similar.round(<span class="number">4</span>))</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行结果：</span></span><br><span class="line"><span class="string">用户之间的两两相似度：</span></span><br><span class="line">        <span class="string">User1</span>   <span class="string">User2</span>   <span class="string">User3</span>   <span class="string">User4</span>   <span class="string">User5</span></span><br><span class="line"><span class="string">User1</span>  <span class="number">1.0000</span>  <span class="number">0.8528</span>  <span class="number">0.7071</span>  <span class="number">0.0000</span> <span class="number">-0.7921</span></span><br><span class="line"><span class="string">User2</span>  <span class="number">0.8528</span>  <span class="number">1.0000</span>  <span class="number">0.4677</span>  <span class="number">0.4900</span> <span class="number">-0.9001</span></span><br><span class="line"><span class="string">User3</span>  <span class="number">0.7071</span>  <span class="number">0.4677</span>  <span class="number">1.0000</span> <span class="number">-0.1612</span> <span class="number">-0.4666</span></span><br><span class="line"><span class="string">User4</span>  <span class="number">0.0000</span>  <span class="number">0.4900</span> <span class="number">-0.1612</span>  <span class="number">1.0000</span> <span class="number">-0.6415</span></span><br><span class="line"><span class="string">User5</span> <span class="number">-0.7921</span> <span class="number">-0.9001</span> <span class="number">-0.4666</span> <span class="number">-0.6415</span>  <span class="number">1.0000</span></span><br><span class="line"><span class="string">物品之间的两两相似度：</span></span><br><span class="line">        <span class="string">Item</span> <span class="string">A</span>  <span class="string">Item</span> <span class="string">B</span>  <span class="string">Item</span> <span class="string">C</span>  <span class="string">Item</span> <span class="string">D</span>  <span class="string">Item</span> <span class="string">E</span></span><br><span class="line"><span class="string">Item</span> <span class="string">A</span>  <span class="number">1.0000</span> <span class="number">-0.4767</span> <span class="number">-0.1231</span>  <span class="number">0.5322</span>  <span class="number">0.9695</span></span><br><span class="line"><span class="string">Item</span> <span class="string">B</span> <span class="number">-0.4767</span>  <span class="number">1.0000</span>  <span class="number">0.6455</span> <span class="number">-0.3101</span> <span class="number">-0.4781</span></span><br><span class="line"><span class="string">Item</span> <span class="string">C</span> <span class="number">-0.1231</span>  <span class="number">0.6455</span>  <span class="number">1.0000</span> <span class="number">-0.7206</span> <span class="number">-0.4276</span></span><br><span class="line"><span class="string">Item</span> <span class="string">D</span>  <span class="number">0.5322</span> <span class="number">-0.3101</span> <span class="number">-0.7206</span>  <span class="number">1.0000</span>  <span class="number">0.5817</span></span><br><span class="line"><span class="string">Item</span> <span class="string">E</span>  <span class="number">0.9695</span> <span class="number">-0.4781</span> <span class="number">-0.4276</span>  <span class="number">0.5817</span>  <span class="number">1.0000</span></span><br></pre></td></tr></table></figure><p>可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。</p><p><strong>注意：</strong>我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。</p></li><li><p><strong>评分预测：</strong> </p><p><strong>User-Based CF 评分预测：使用用户间的相似度进行预测</strong> </p><p>关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，该方案考虑了用户本身的评分评分以及近邻用户的加权平均相似度打分来进行预测： </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155128.png"/></p><p>我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：$pred(u_1,i_5)=(0.85∗3+0.71∗5)/(0.85+0.71)=3.91$最终预测出用户1对物品5的评分为3.91</p><p><strong>Item-Based CF 评分预测：使用物品间的相似度进行预测</strong> </p><p>这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155120.png"/></p><p>户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，计算如下： $pred(u1,i5)=(0.97∗5+0.58∗4)/(0.97+0.58)=4.63$ 对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但具体哪一种更佳，必须经过合理的效果评估，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。 </p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;推荐模型构建流程&quot;&gt;&lt;a href=&quot;#推荐模型构建流程&quot; class=&quot;headerlink&quot; title=&quot;推荐模型构建流程&quot;&gt;&lt;/a&gt;推荐模型构建流程&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Data(数据)-&amp;gt;Features(特征)-&amp;gt;ML Algorithm(选择算法训练模型)-&amp;gt;Prediction Output(预测输出) &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐模型构建流程" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/"/>
    
      <category term="推荐算法" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="协同过滤推荐算法" scheme="https://xiaoliaozi.com/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="相似度计算" scheme="https://xiaoliaozi.com/tags/%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统</title>
    <link href="https://xiaoliaozi.com/2020/01/15/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    <id>https://xiaoliaozi.com/2020/01/15/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-01-15T01:33:02.000Z</published>
    <updated>2020-02-27T07:46:11.842Z</updated>
    
    <content type="html"><![CDATA[<h4 id="推荐系统概念"><a href="#推荐系统概念" class="headerlink" title="推荐系统概念"></a>推荐系统概念</h4><h5 id="什么是推荐系统"><a href="#什么是推荐系统" class="headerlink" title="什么是推荐系统"></a>什么是推荐系统</h5><p>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载，系统通过一定的规则对物品进行排序，并将排在前面的物品展示给用户，这样的系统就是推荐系统 。</p><h5 id="信息过载-amp-用户需求不明确"><a href="#信息过载-amp-用户需求不明确" class="headerlink" title="信息过载 &amp; 用户需求不明确"></a>信息过载 &amp; 用户需求不明确</h5><ul><li>分类⽬录（1990s）：覆盖少量热门⽹站。典型应用：Hao123 Yahoo</li><li>搜索引擎（2000s）：通过搜索词明确需求。典型应用：Google Baidu</li><li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤ 户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能 够满⾜他们兴趣和需求的信息。</li></ul><a id="more"></a><h5 id="推荐系统与搜索引擎"><a href="#推荐系统与搜索引擎" class="headerlink" title="推荐系统与搜索引擎"></a>推荐系统与搜索引擎</h5><div class="table-container"><table><thead><tr><th></th><th>搜索</th><th>推荐</th></tr></thead><tbody><tr><td>行为方式</td><td>主动</td><td>被动</td></tr><tr><td>意图</td><td>明确</td><td>模糊</td></tr><tr><td>个性化</td><td>弱</td><td>强</td></tr><tr><td>流量分布</td><td>马太效应</td><td>长尾效应</td></tr><tr><td>目标</td><td>快速满足</td><td>持续服务</td></tr><tr><td>评估指标</td><td>简明</td><td>复杂</td></tr></tbody></table></div><h4 id="推荐系统的工作原理"><a href="#推荐系统的工作原理" class="headerlink" title="推荐系统的工作原理"></a>推荐系统的工作原理</h4><ul><li><strong>社会化推荐</strong> 例如：向朋友咨询，社会化推荐，让好友给自己推荐物品</li><li><strong>基于内容的推荐</strong> 例如：打开搜索引擎，输入自己喜欢的演员的名字，然后看看返回结果中还有什么电影是自己没看过的</li><li><strong>基于流行度的推荐</strong> 例如：查看票房排行榜</li><li><strong>基于协同过滤的推荐</strong> 例如：找到和自己历史兴趣相似的用户，看看他们最近在看什么电影</li></ul><h4 id="推荐系统的作用"><a href="#推荐系统的作用" class="headerlink" title="推荐系统的作用"></a>推荐系统的作用</h4><ul><li>高效连接用户和物品</li><li>提高用户停留时间和用户活跃程度</li><li>有效的帮助产品实现其商业价值</li></ul><h4 id="推荐系统的应用场景"><a href="#推荐系统的应用场景" class="headerlink" title="推荐系统的应用场景"></a>推荐系统的应用场景</h4><ul><li>头条</li><li>淘宝京东</li><li>抖音</li></ul><h4 id="推荐系统和Web项目的区别"><a href="#推荐系统和Web项目的区别" class="headerlink" title="推荐系统和Web项目的区别"></a>推荐系统和Web项目的区别</h4><ul><li>通过信息过滤实现目标提升 V.S. 稳定的信息流通系统<ul><li>web项目: 处理复杂业务逻辑，处理高并发，为用户构建一个稳定的信息流通服务</li><li>推荐系统: 追求指标增长， 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li></ul></li><li>确定 V.S. 不确定思维<ul><li>web项目: 对结果有确定预期</li><li>推荐系统: 结果是概率问题</li></ul></li></ul><h4 id="推荐系统要素"><a href="#推荐系统要素" class="headerlink" title="推荐系统要素"></a>推荐系统要素</h4><ul><li>UI 和 UE(前端界面)</li><li>数据 (Lambda架构)</li><li>业务知识</li><li>算法</li></ul><h4 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h4><h5 id="推荐系统整体架构"><a href="#推荐系统整体架构" class="headerlink" title="推荐系统整体架构"></a>推荐系统整体架构</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154506.png"/></p><h5 id="大数据Lambda架构"><a href="#大数据Lambda架构" class="headerlink" title="大数据Lambda架构"></a>大数据Lambda架构</h5><ul><li>Lambda架构是由实时大数据处理框架Storm的作者Nathan Marz提出的一个实时大数据处理框架。</li><li>Lambda架构的将离线计算和实时计算整合，设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。</li><li>分层架构<ul><li>批处理层（离线计算）<ul><li>数据不可变, 可进行任何计算, 可水平扩展</li><li>高延迟 几分钟~几小时(计算量和数据量不同)</li><li>日志收集： Flume</li><li>分布式存储： Hadoop</li><li>分布式计算： Hadoop、Spark</li><li>视图存储数据库<ul><li>nosql(HBase/Cassandra)</li><li>Redis/memcache</li><li>MySQL</li></ul></li></ul></li><li>实时处理层<ul><li>流式处理, 持续计算</li><li>存储和分析某个窗口期内的数据（一段时间的热销排行，实时热搜等）</li><li>实时数据收集 flume-日志收集 &amp; kafka-消息队列（数据的实时收集）</li><li>实时数据分析 spark streaming/storm/flink</li></ul></li><li>服务层<ul><li>支持随机读</li><li>需要在非常短的时间内返回结果</li><li>读取批处理层和实时处理层结果并对其归并</li></ul></li></ul></li><li><p>Lambda架构图</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154322.png"/></p></li></ul><h5 id="推荐算法架构"><a href="#推荐算法架构" class="headerlink" title="推荐算法架构"></a>推荐算法架构</h5><ul><li>召回阶段 (海选)<ul><li>召回决定了最终推荐结果的天花板</li><li>常用算法:<ul><li>协同过滤</li><li>基于内容</li></ul></li></ul></li><li>排序阶段 （精选）<ul><li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li><li>CTR预估 (点击率预估 使用LR算法) 估计用户是否会点击某个商品 需要用户的点击数据</li></ul></li><li>过滤<ul><li>法律规则</li><li>没有库存问题</li><li>反复曝光都没看</li></ul></li><li><p>规则调整</p><ul><li>商业合作</li><li>政策问题</li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154421.jpeg"/></p></li></ul><h5 id="推荐系统的整体架构"><a href="#推荐系统的整体架构" class="headerlink" title="推荐系统的整体架构"></a>推荐系统的整体架构</h5><p> 推荐系统业务架构</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154452.png"/></p><p>  推荐系统技术架构</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154427.png"/> </p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;推荐系统概念&quot;&gt;&lt;a href=&quot;#推荐系统概念&quot; class=&quot;headerlink&quot; title=&quot;推荐系统概念&quot;&gt;&lt;/a&gt;推荐系统概念&lt;/h4&gt;&lt;h5 id=&quot;什么是推荐系统&quot;&gt;&lt;a href=&quot;#什么是推荐系统&quot; class=&quot;headerlink&quot; title=&quot;什么是推荐系统&quot;&gt;&lt;/a&gt;什么是推荐系统&lt;/h5&gt;&lt;p&gt;没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载，系统通过一定的规则对物品进行排序，并将排在前面的物品展示给用户，这样的系统就是推荐系统 。&lt;/p&gt;
&lt;h5 id=&quot;信息过载-amp-用户需求不明确&quot;&gt;&lt;a href=&quot;#信息过载-amp-用户需求不明确&quot; class=&quot;headerlink&quot; title=&quot;信息过载 &amp;amp; 用户需求不明确&quot;&gt;&lt;/a&gt;信息过载 &amp;amp; 用户需求不明确&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;分类⽬录（1990s）：覆盖少量热门⽹站。典型应用：Hao123 Yahoo&lt;/li&gt;
&lt;li&gt;搜索引擎（2000s）：通过搜索词明确需求。典型应用：Google Baidu&lt;/li&gt;
&lt;li&gt;推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤ 户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能 够满⾜他们兴趣和需求的信息。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="大数据推荐系统" scheme="https://xiaoliaozi.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐系统简介" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/"/>
    
      <category term="推荐系统架构" scheme="https://xiaoliaozi.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>五大常用算法</title>
    <link href="https://xiaoliaozi.com/2020/01/13/%E4%BA%94%E5%A4%A7%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"/>
    <id>https://xiaoliaozi.com/2020/01/13/%E4%BA%94%E5%A4%A7%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/</id>
    <published>2020-01-13T06:40:47.000Z</published>
    <updated>2020-01-14T06:30:47.546Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>据说有人归纳了计算机的五大常用算法，它们是贪婪算法，动态规划算法，分治算法，回溯算法以及分支限界算法。这五个算法是有很多应用场景的，最优化问题大多可以利用这些算法解决。算法的本质就是解决问题。当数据量比较小时，其实根本就不需要什么算法，写一些for循环完全就可以很快速的搞定了，但是当数据量比较大，场景比较复杂的时候，算法就尤为重要了，本文先归纳这几个算法及应用场景，随后在细细品味。</p><a id="more"></a><h4 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h4><h5 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h5><p>穷举法也叫枚举法， 在进行归纳推理时，如果逐个考察了某类事件的所有可能情况，因而得出一般结论，那么这结论是可靠的，这种归纳方法叫做枚举法。枚举法是利用计算机运算速度快、精确度高的特点，对要解决问题的所有可能情况，一个不漏地进行检验，从中找出符合要求的答案，因此枚举法是通过牺牲时间来换取答案的全面性 。穷举法属于暴力破解法， 暴力破解法，就是把所有条件，相关情况统统考虑进去，让计算机进行检索，指导得出与之所有条件符合的结果 。</p><h5 id="2-基本思想"><a href="#2-基本思想" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol><li>确定枚举对象、枚举范围和判定条件</li><li>枚举可能的解，验证是否是问题的解</li></ol><h5 id="3-应用实例"><a href="#3-应用实例" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>百钱买鸡问题</li><li>鸡兔同笼问题</li><li>搬砖块问题</li><li>猜数字</li><li>韩信点兵 </li></ol><h4 id="贪婪算法"><a href="#贪婪算法" class="headerlink" title="贪婪算法"></a>贪婪算法</h4><h5 id="1-定义-1"><a href="#1-定义-1" class="headerlink" title="1.定义"></a>1.定义</h5><p>贪婪算法(贪心算法)是指在对问题进行求解时，在每一步选择中都采取最好或者最优(即最有利)的选择，从而希望能够导致结果是最好或者最优的算法。贪婪算法所得到的结果往往不是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果。</p><h5 id="2-基本思想-1"><a href="#2-基本思想-1" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol><li><p>建立数学模型来描述问题</p></li><li><p>把求解的问题分成若干个子问题</p></li><li><p>对每一子问题求解，得到子问题的局部最优解</p></li><li><p>把子问题对应的局部最优解合成原来整个问题的一个近似最优解</p></li></ol><h5 id="3-应用实例-1"><a href="#3-应用实例-1" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>钱币找零问题 </li><li>区间调度问题</li><li>背包问题 </li><li>均分纸牌 </li><li>最大整数</li></ol><h4 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h4><h5 id="1-定义-2"><a href="#1-定义-2" class="headerlink" title="1.定义"></a>1.定义</h5><p> 动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。 </p><h5 id="2-基本思想-2"><a href="#2-基本思想-2" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol><li>将待求解的问题分解为若干个子问题（阶段）</li><li>按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息</li><li>在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解</li><li>依次解决各子问题，最后一个子问题就是初始问题的解。 </li></ol><h5 id="3-应用实例-2"><a href="#3-应用实例-2" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>数字三角形问题</li><li>找零钱问题</li><li>走方格问题</li><li>最长公共序列数</li></ol><h4 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h4><h5 id="1-定义-3"><a href="#1-定义-3" class="headerlink" title="1.定义"></a>1.定义</h5><p> 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。即一种分目标完成程序算法，简单问题可用二分法完成。 </p><h5 id="2-基本思想-3"><a href="#2-基本思想-3" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol><li>先把问题分解成几个子问题</li><li>求出这几个子问题的解法</li><li>再找到合适的方法，把它们组合成求整个问题的解法。</li><li>如果这些子问题还较大，难以解决，可以再把它们分成几个更小的子问题</li><li>以此类推，直至可以直接求出解为止</li></ol><h5 id="3-应用实例-3"><a href="#3-应用实例-3" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>找出伪币</li><li>二分搜索</li><li>汉诺塔</li><li>归并排序</li><li>快速排序</li><li>大整数乘法</li></ol><h4 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h4><h5 id="1-定义-4"><a href="#1-定义-4" class="headerlink" title="1.定义"></a>1.定义</h5><p> 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 </p><h5 id="2-基本思想-4"><a href="#2-基本思想-4" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><p> 从一条路往前走，能进则进，不能进则退回来，换一条路再试 </p><h5 id="3-应用实例-4"><a href="#3-应用实例-4" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>八皇后问题</li><li>图的着色问题 </li><li>装载问题 </li><li>批处理作业调度问题 </li><li>背包问题 </li><li>最大团问题 </li></ol><h4 id="分支限界算法"><a href="#分支限界算法" class="headerlink" title="分支限界算法"></a>分支限界算法</h4><h5 id="1-定义-5"><a href="#1-定义-5" class="headerlink" title="1.定义"></a>1.定义</h5><p>分支限界算法是按照广度优先的方式对解空间树（状态空间树）进行搜索，从而求得最优解的算法。</p><h5 id="2-基本思想-5"><a href="#2-基本思想-5" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><p>在搜索的过程中，采用<strong>限界函数</strong>（bound function）估算所有子节点的目标函数的可能取值，从而选择使目标函数取极值（极大值或者极小值）的节点作为扩展结点（如果限界值没有超过目前的最优解，则剪枝）进行下一步搜索（重复 BFS -&gt; 计算所有子节点限界 -&gt; 选择最优子节点作为扩展结点的过程），从而不断调整搜索的方向，尽快找到问题的最优解。分支限界的思想类似于：图的广度优先搜索，树的层序遍历。</p><h5 id="3-应用实例-5"><a href="#3-应用实例-5" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol><li>单源最短路径问题</li><li>装载问题</li><li>布线问题</li><li>0-1背包问题</li><li>最大团问题</li><li>旅行售货员问题</li></ol><h4 id="总结说明"><a href="#总结说明" class="headerlink" title="总结说明"></a>总结说明</h4><p>对于一个应用实例可能会有多种算法解决，算法是一种解决问题的思想，任意一个算法绝对不是一两篇文章可以讲清楚的。当然也不是通过一两道题目可以完全学会。学习算法的关键是<strong>用算法的思想去想问题，去解决实际问题</strong>，多刷题是养成算法思维解决问题的基础。</p><h4 id="学习算法方法"><a href="#学习算法方法" class="headerlink" title="学习算法方法"></a>学习算法方法</h4><h5 id="1-书籍"><a href="#1-书籍" class="headerlink" title="1.书籍"></a>1.书籍</h5><ol><li>数据结构</li><li>数据结构与算法分析 </li><li>算法导论</li></ol><h5 id="2-刷题"><a href="#2-刷题" class="headerlink" title="2.刷题"></a>2.刷题</h5><ol><li>牛客</li><li>LeeCode</li></ol><h5 id="3-在线视频课程"><a href="#3-在线视频课程" class="headerlink" title="3.在线视频课程"></a>3.在线视频课程</h5><ol><li>慕课</li><li>网易云课程（强烈推荐）</li></ol><h5 id="4-可视化工具"><a href="#4-可视化工具" class="headerlink" title="4.可视化工具"></a>4.可视化工具</h5><ul><li><a href="https://visualgo.net/" target="_blank" rel="noopener">visualgo 网址 </a> </li></ul><p>最重要的是耐心，自律，有毅力，坚持。</p><p>作为才入门的程序员，我已经沉浸在知识海洋中无法自拔，深深感受到了自己的渺小。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;据说有人归纳了计算机的五大常用算法，它们是贪婪算法，动态规划算法，分治算法，回溯算法以及分支限界算法。这五个算法是有很多应用场景的，最优化问题大多可以利用这些算法解决。算法的本质就是解决问题。当数据量比较小时，其实根本就不需要什么算法，写一些for循环完全就可以很快速的搞定了，但是当数据量比较大，场景比较复杂的时候，算法就尤为重要了，本文先归纳这几个算法及应用场景，随后在细细品味。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机常用算法" scheme="https://xiaoliaozi.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="计算机常用算法" scheme="https://xiaoliaozi.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/"/>
    
      <category term="算法思想" scheme="https://xiaoliaozi.com/tags/%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>集成学习</title>
    <link href="https://xiaoliaozi.com/2020/01/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    <id>https://xiaoliaozi.com/2020/01/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-01-13T03:11:47.000Z</published>
    <updated>2020-02-27T07:39:20.703Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是集成学习"><a href="#什么是集成学习" class="headerlink" title="什么是集成学习"></a>什么是集成学习</h4><p> 集成学习通过建立几个模型来解决单一预测问题。它的工作原理是<strong>生成多个分类器/模型</strong>，各自独立地学习和作出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。</strong> </p><a id="more"></a><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143703.png"/></p><h4 id="机器学习的两个核心任务"><a href="#机器学习的两个核心任务" class="headerlink" title="机器学习的两个核心任务"></a>机器学习的两个核心任务</h4><ul><li>任务一：<strong>如何优化训练数据</strong> —&gt; 主要用于<strong>解决欠拟合问题</strong></li><li>任务二：<strong>如何提升泛化性能</strong> —&gt; 主要用于<strong>解决过拟合问题</strong></li></ul><h4 id="集成学习中boosting和Bagging"><a href="#集成学习中boosting和Bagging" class="headerlink" title="集成学习中boosting和Bagging"></a>集成学习中boosting和Bagging</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143653.png"/> </p><p><strong>只要单分类器的表现不太差，集成学习的结果总是要好于单分类器的</strong></p><h4 id="Bagging集成原理"><a href="#Bagging集成原理" class="headerlink" title="Bagging集成原理"></a>Bagging集成原理</h4><p> 目标：把下面的圈和方块进行分类 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227153011.png"/> </p><p>实现过程：</p><p>1.采样不同数据集</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152903.png"/></p><p> 2.训练分类器 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152657.png"/> </p><ol><li><p>平权投票，获取最终结果 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152648.png"/></p><p>4.主要实现过程小结 </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152622.png"/> </p></li></ol><h4 id="随机森林构造过程"><a href="#随机森林构造过程" class="headerlink" title="随机森林构造过程"></a>随机森林构造过程</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定。</p><p><strong>随机森林</strong> <strong>= Bagging +</strong> <strong>决策树</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143311.png"/></p><h4 id="随机森林api介绍"><a href="#随机森林api介绍" class="headerlink" title="随机森林api介绍"></a>随机森林api介绍</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestClassifier(<span class="attribute">n_estimators</span>=10, <span class="attribute">criterion</span>=’gini’, <span class="attribute">max_depth</span>=None, <span class="attribute">bootstrap</span>=<span class="literal">True</span>, <span class="attribute">random_state</span>=None, <span class="attribute">min_samples_split</span>=2)</span><br><span class="line">n_estimators：integer，optional（default = 10）森林里的树木数量120,200,300,500,800,1200</span><br><span class="line">Criterion：string，可选（default =“gini”）分割特征的测量方法</span><br><span class="line">max_depth：integer或None，可选（默认=无）树的最大深度 5,8,15,25,30</span><br><span class="line"><span class="attribute">max_features</span>=<span class="string">"auto”,每个决策树的最大特征数量</span></span><br><span class="line"><span class="string">If "</span>auto", then <span class="attribute">max_features</span>=sqrt(n_features).</span><br><span class="line"><span class="keyword">If</span> <span class="string">"sqrt"</span>, then <span class="attribute">max_features</span>=sqrt(n_features)(same as <span class="string">"auto"</span>).</span><br><span class="line"><span class="keyword">If</span> <span class="string">"log2"</span>, then <span class="attribute">max_features</span>=log2(n_features).</span><br><span class="line"><span class="keyword">If</span> None, then <span class="attribute">max_features</span>=n_features.</span><br><span class="line">bootstrap：boolean，optional（default = <span class="literal">True</span>）是否在构建树时使用放回抽样</span><br><span class="line">min_samples_split:节点划分最少样本数</span><br><span class="line">min_samples_leaf:叶子节点的最小样本数</span><br><span class="line">超参数：n_estimator, max_depth, min_samples_split,min_samples_leaf</span><br></pre></td></tr></table></figure><h4 id="随机森林预测案例"><a href="#随机森林预测案例" class="headerlink" title="随机森林预测案例"></a>随机森林预测案例</h4><ul><li>实例化随机森林</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林去进行预测</span></span><br><span class="line">rf = RandomForestClassifier()</span><br></pre></td></tr></table></figure><ul><li>定义超参数的选择列表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">param = &#123;<span class="string">"n_estimators"</span>: [<span class="number">120</span>,<span class="number">200</span>,<span class="number">300</span>,<span class="number">500</span>,<span class="number">800</span>,<span class="number">1200</span>], <span class="string">"max_depth"</span>: [<span class="number">5</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">30</span>]&#125;</span><br></pre></td></tr></table></figure><ul><li>使用GridSearchCV进行网格搜索</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 超参数调优</span></span><br><span class="line">gc = GridSearchCV(rf, param_grid=param, cv=<span class="number">2</span>)</span><br><span class="line">gc.fit(x_train, y_train)</span><br><span class="line">print(<span class="string">"随机森林预测的准确率为："</span>, gc.score(x_test, y_test))</span><br></pre></td></tr></table></figure><blockquote><p>注意</p><ul><li>随机森林的建立过程</li><li>树的深度、树的个数等需要进行超参数调优</li></ul></blockquote><h4 id="bagging集成优点"><a href="#bagging集成优点" class="headerlink" title="bagging集成优点"></a>bagging集成优点</h4><p><strong>Bagging + 决策树/线性回归/逻辑回归/深度学习… = bagging集成学习方法</strong></p><p>经过上面方式组成的集成学习方法:</p><ol><li><strong>均可在原有算法上提高约2%左右的泛化正确率</strong></li><li><strong>简单, 方便, 通用</strong></li></ol><h4 id="boosting集成原理"><a href="#boosting集成原理" class="headerlink" title="boosting集成原理"></a>boosting集成原理</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152607.png"/> </p><p><strong>随着学习的积累从弱到强</strong></p><p><strong>简而言之：每新加入一个弱学习器，整体能力就会得到提升</strong></p><p>代表算法：Adaboost，GBDT，XGBoost</p><h4 id="boosting实现过程"><a href="#boosting实现过程" class="headerlink" title="boosting实现过程"></a>boosting实现过程</h4><p>1.<strong>训练第一个学习器</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152557.png"/></p><p> 2.<strong>调整数据分布</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143933.png"/></p><p> 3.<strong>训练第二个学习器</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152614.png"/></p><p> 4.<strong>再次调整数据分布</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143839.png"/></p><p> 5.<strong>依次训练学习器，调整数据分布</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143802.png"/></p><p> 6.<strong>整体过程实现</strong></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143754.png"/> </p><blockquote><p>关键点：<br>如何确认投票权重？<br>如何调整数据分布？</p></blockquote><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143743.png"/></p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143717.png"/>  </p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143710.png"/> </p><h4 id="bagging与boosting比较"><a href="#bagging与boosting比较" class="headerlink" title="bagging与boosting比较"></a>bagging与boosting比较</h4><blockquote><p>区别一：数据方面</p><p>​    Bagging：对数据进行采样训练；</p><p>​    Boosting：根据前一轮学习结果调整数据的重要性。</p><p>区别二：投票方面</p><p>​    Bagging：所有学习器平权投票；</p><p>​    Boosting：对学习器进行加权投票。</p><p>区别三：学习顺序</p><p>​    Bagging的学习是并行的，每个学习器没有依赖关系；</p><p>​    Boosting学习是串行，学习有先后顺序。</p><p>区别四：主要作用</p><p>​    Bagging主要用于提高泛化性能（解决过拟合，也可以说降低方差）</p><p>​    Boosting主要用于提高训练精度 （解决欠拟合，也可以说降低偏差）</p></blockquote><h4 id="boostingAPI介绍"><a href="#boostingAPI介绍" class="headerlink" title="boostingAPI介绍"></a>boostingAPI介绍</h4><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">api链接<span class="symbol">:https</span><span class="symbol">://scikit-learn</span>.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html<span class="comment">#sklearn.ensemble.AdaBoostClassifier</span></span><br></pre></td></tr></table></figure><h4 id="梯度提升决策树-GBDT"><a href="#梯度提升决策树-GBDT" class="headerlink" title="梯度提升决策树 GBDT"></a>梯度提升决策树 GBDT</h4><h5 id="1-GBDT定义"><a href="#1-GBDT定义" class="headerlink" title="1.GBDT定义"></a>1.GBDT定义</h5><p>梯度提升决策树(GBDT Gradient Boosting Decision Tree) <strong>是一种迭代的决策树算法</strong>，<strong>该算法由多棵决策树组成，所有树的结论累加起来做最终答案。</strong>它在被提出之初就被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。</p><p><strong>GBDT = 梯度下降 + Boosting + 决策树</strong></p><h5 id="2-GBDT执行流程"><a href="#2-GBDT执行流程" class="headerlink" title="2.GBDT执行流程"></a>2.GBDT执行流程</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143646.png"/></p><p>如果上式中的$h_i(x)=$决策树模型,则上式就变为:</p><p><strong>GBDT = 梯度下降 + Boosting + 决策树</strong></p><h5 id="3-GBDT案例"><a href="#3-GBDT案例" class="headerlink" title="3.GBDT案例"></a>3.GBDT案例</h5><p>预测编号5的身高：<br>| 编号 | 年龄(岁) | 体重(KG) | 身高(M) |<br>| —— | ———— | ———— | ———- |<br>| 1    | 5        | 20       | 1.1     |<br>| 2    | 7        | 30       | 1.3     |<br>| 3    | 21       | 70       | 1.7     |<br>| 4    | 30       | 60       | 1.8     |<br>| 5    | 25       | 65       | ?       |</p><p>第一步：计算损失函数,并求出第一个预测值:</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143637.png"/> </p><p> 第二步：求解划分点 </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143623.png"/></p><p> 得出:年龄21为划分点的方差=0.01+0.0025=0.0125</p><p>第三步：通过调整后目标值,求解得出h1(x)</p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143605.png"/></p><p>  第四步：求解h2(x) </p><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143346.png"/></p><p> 得出结果:</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143327.png"/> 编号5身高 = 1.475 + 0.03 + 0.275 = 1.78</p><h5 id="4-GBDT主要执行思想"><a href="#4-GBDT主要执行思想" class="headerlink" title="4.GBDT主要执行思想"></a>4.GBDT主要执行思想</h5><p>1.使用梯度下降法优化代价函数；</p><p>2.使用一层决策树作为弱学习器，负梯度作为目标值；</p><p>3.利用boosting思想进行集成。</p><h4 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h4><p> <strong>XGBoost= 二阶泰勒展开+boosting+决策树+正则化</strong> </p><p><strong>Boosting</strong>：XGBoost使用Boosting提升思想对多个弱学习器进行迭代式学习</p><p><strong>二阶泰勒展开</strong>：每一轮学习中，XGBoost对损失函数进行二阶泰勒展开，使用一阶和二阶梯度进行优化。</p><p><strong>决策树</strong>：在每一轮学习中，XGBoost使用决策树算法作为弱学习进行优化。</p><p><strong>正则化</strong>：在优化过程中XGBoost为防止过拟合，在损失函数中加入惩罚项，限制决策树的叶子节点个数以及决策树叶子节点的值。</p><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143320.png"/> </p><p>泰勒展开越多，计算结果越精确</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;什么是集成学习&quot;&gt;&lt;a href=&quot;#什么是集成学习&quot; class=&quot;headerlink&quot; title=&quot;什么是集成学习&quot;&gt;&lt;/a&gt;什么是集成学习&lt;/h4&gt;&lt;p&gt; 集成学习通过建立几个模型来解决单一预测问题。它的工作原理是&lt;strong&gt;生成多个分类器/模型&lt;/strong&gt;，各自独立地学习和作出预测。&lt;strong&gt;这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。&lt;/strong&gt; &lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习算法" scheme="https://xiaoliaozi.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="机器学习算法" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="监督学习算法" scheme="https://xiaoliaozi.com/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
      <category term="集成学习" scheme="https://xiaoliaozi.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="欠拟合过拟合" scheme="https://xiaoliaozi.com/tags/%E6%AC%A0%E6%8B%9F%E5%90%88%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
      <category term="bagging集成" scheme="https://xiaoliaozi.com/tags/bagging%E9%9B%86%E6%88%90/"/>
    
      <category term="boosting集成" scheme="https://xiaoliaozi.com/tags/boosting%E9%9B%86%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>特征工程-特征提取</title>
    <link href="https://xiaoliaozi.com/2020/01/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    <id>https://xiaoliaozi.com/2020/01/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/</id>
    <published>2020-01-11T02:40:27.000Z</published>
    <updated>2020-02-22T10:01:30.394Z</updated>
    
    <content type="html"><![CDATA[<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><ul><li><p>定义</p><p><strong>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</strong></p><blockquote><p>注：特征值化是为了计算机更好的去理解数据</p></blockquote><ul><li>特征提取分类:<ul><li>字典特征提取(特征离散化)</li><li>文本特征提取</li><li>图像特征提取（深度学习将介绍）</li></ul></li></ul></li></ul><a id="more"></a><ul><li><p>特征提取API</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">sklearn</span><span class="selector-class">.feature_extraction</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h4><p><strong>作用：对字典数据进行特征值化</strong></p><ul><li>sklearn.feature_extraction.DictVectorizer(sparse=True,…)<ul><li>DictVectorizer.fit_transform(X)<ul><li>X：字典或者包含字典的迭代器返回值</li><li>返回sparse矩阵</li></ul></li><li>DictVectorizer.get_feature_names() 返回类别名称</li></ul></li></ul><p><strong>应用：</strong></p><ul><li>实例化类DictVectorizer</li><li>调用fit_transform方法输入数据并转换（注意返回格式）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dict_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对字典类型的数据进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [&#123;<span class="string">'city'</span>: <span class="string">'北京'</span>,<span class="string">'temperature'</span>:<span class="number">100</span>&#125;, </span><br><span class="line">            &#123;<span class="string">'city'</span>: <span class="string">'上海'</span>,<span class="string">'temperature'</span>:<span class="number">60</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'city'</span>: <span class="string">'深圳'</span>,<span class="string">'temperature'</span>:<span class="number">30</span>&#125;]</span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"返回的结果:\n"</span>, data)</span><br><span class="line">    <span class="comment"># 打印特征名字</span></span><br><span class="line">    print(<span class="string">"特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Nonepython</span><br></pre></td></tr></table></figure><p> 注意观察没有加上sparse=False参数的结果 </p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">返回的结果:</span><br><span class="line">   (<span class="number">0</span>, <span class="number">1</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">3</span>)    <span class="number">100.0</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">0</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">3</span>)    <span class="number">60.0</span></span><br><span class="line">  (<span class="number">2</span>, <span class="number">2</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">2</span>, <span class="number">3</span>)    <span class="number">30.0</span></span><br><span class="line">特征名字：</span><br><span class="line"> [<span class="string">'city=上海'</span>, <span class="string">'city=北京'</span>, <span class="string">'city=深圳'</span>, <span class="string">'temperature'</span>]</span><br></pre></td></tr></table></figure><p> 这个结果并不是我们想要看到的，所以加上参数，得到想要的结果： </p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">返回的结果:</span><br><span class="line"> [[   <span class="number">0.</span>    <span class="number">1.</span>    <span class="number">0.</span>  <span class="number">100.</span>]</span><br><span class="line"> [   <span class="number">1.</span>    <span class="number">0.</span>    <span class="number">0.</span>   <span class="number">60.</span>]</span><br><span class="line"> [   <span class="number">0.</span>    <span class="number">0.</span>    <span class="number">1.</span>   <span class="number">30.</span>]]</span><br><span class="line">特征名字：</span><br><span class="line"> [<span class="string">'city=上海'</span>, <span class="string">'city=北京'</span>, <span class="string">'city=深圳'</span>, <span class="string">'temperature'</span>]</span><br></pre></td></tr></table></figure><p>之前在学习pandas中的离散化的时候，也实现了类似的效果。我们把这个处理数据的技巧叫做”one-hot“编码</p><p> <strong>对于特征当中存在类别信息的我们都会做one-hot编码处理</strong> 。</p><h4 id="文本特征提取"><a href="#文本特征提取" class="headerlink" title="文本特征提取"></a>文本特征提取</h4><p><strong>作用：对文本数据进行特征值化</strong></p><ul><li><strong>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</strong><ul><li>返回词频矩阵</li><li>CountVectorizer.fit_transform(X)<ul><li>X:文本或者包含文本字符串的可迭代对象</li><li>返回值:返回sparse矩阵</li></ul></li><li>CountVectorizer.get_feature_names() 返回值:单词列表</li></ul></li><li><strong>sklearn.feature_extraction.text.TfidfVectorizer</strong></li></ul><p><strong>应用：</strong></p><ul><li>实例化类CountVectorizer</li><li>调用fit_transform方法输入数据并转换 （注意返回格式，利用toarray()进行sparse矩阵转换array数组）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_count_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对文本进行特征抽取，countvetorizer</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"life is short,i like like python"</span>, <span class="string">"life is too long,i dislike python"</span>]</span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False) # 注意,没有sparse这个参数</span></span><br><span class="line">    transfer = CountVectorizer()</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>返回结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line"> [<span class="string">'dislike'</span>, <span class="string">'is'</span>, <span class="string">'life'</span>, <span class="string">'like'</span>, <span class="string">'long'</span>, <span class="string">'python'</span>, <span class="string">'short'</span>, <span class="string">'too'</span>]</span><br></pre></td></tr></table></figure><p>不支持单个中文字，中文未分词，所以我们要对中文进行分词处理 </p><h4 id="jieba分词处理"><a href="#jieba分词处理" class="headerlink" title="jieba分词处理"></a>jieba分词处理</h4><ul><li>jieba.cut()：返回词语组成的生成器</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要安装下jieba库</span></span><br><span class="line">pip3 install jieba</span><br></pre></td></tr></table></figure><p><strong>案例</strong>：</p><ul><li>准备句子，利用jieba.cut进行分词</li><li>实例化CountVectorizer</li><li>将分词结果变成字符串当作fit_transform的输入值</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行分词</span></span><br><span class="line"><span class="string">    "我爱北京天安门"————&gt;"我 爱 北京 天安门"</span></span><br><span class="line"><span class="string">    :param text:</span></span><br><span class="line"><span class="string">    :return: text</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 用结巴对中文字符串进行分词</span></span><br><span class="line">    text = <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_chinese_count_demo2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span>,</span><br><span class="line">            <span class="string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span>,</span><br><span class="line">            <span class="string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span>]</span><br><span class="line">    <span class="comment"># 将原始数据转换成分好词的形式</span></span><br><span class="line">    text_list = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        text_list.append(cut_word(sent))</span><br><span class="line">    print(text_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False)</span></span><br><span class="line">    transfer = CountVectorizer()</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(text_list)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p> 返回结果： </p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Building prefix dict <span class="keyword">from</span> the <span class="keyword">default</span> <span class="built_in">dictionary</span> ...</span><br><span class="line">Dumping model to file cache /var/folders/mz/tzf2l3sx4rgg6qpglfb035_r0000gn/T/jieba.cache</span><br><span class="line">Loading model cost <span class="number">1.032</span> seconds.</span><br><span class="line">[<span class="string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span>, <span class="string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span>, <span class="string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span>]</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">4</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line"> [<span class="string">'一种'</span>, <span class="string">'不会'</span>, <span class="string">'不要'</span>, <span class="string">'之前'</span>, <span class="string">'了解'</span>, <span class="string">'事物'</span>, <span class="string">'今天'</span>, <span class="string">'光是在'</span>, <span class="string">'几百万年'</span>, <span class="string">'发出'</span>, <span class="string">'取决于'</span>, <span class="string">'只用'</span>, <span class="string">'后天'</span>, <span class="string">'含义'</span>, <span class="string">'大部分'</span>, <span class="string">'如何'</span>, <span class="string">'如果'</span>, <span class="string">'宇宙'</span>, <span class="string">'我们'</span>, <span class="string">'所以'</span>, <span class="string">'放弃'</span>, <span class="string">'方式'</span>, <span class="string">'明天'</span>, <span class="string">'星系'</span>, <span class="string">'晚上'</span>, <span class="string">'某样'</span>, <span class="string">'残酷'</span>, <span class="string">'每个'</span>, <span class="string">'看到'</span>, <span class="string">'真正'</span>, <span class="string">'秘密'</span>, <span class="string">'绝对'</span>, <span class="string">'美好'</span>, <span class="string">'联系'</span>, <span class="string">'过去'</span>, <span class="string">'还是'</span>, <span class="string">'这样'</span>]</span><br></pre></td></tr></table></figure><h4 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h4><ul><li>TF-IDF的主要思想是：如果<strong>某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现</strong>，则认为此词或者短语具有很好的类别区分能力，能代表文章的主题，适合用来分类。</li><li><strong>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</strong>提取文章的标签（主题）。</li></ul><h5 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h5><ul><li>词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率</li><li>逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到</strong></li></ul><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222180055.png"/></p><p> 最终得出结果可以理解为重要程度。 </p><p><strong>tfidf越大越能代表文章的主题</strong></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">举例：</span><br><span class="line">假如一篇文章的总词语数是<span class="number">100</span>个，而词语<span class="string">"非常"</span>出现了<span class="number">5</span>次，那么<span class="string">"非常"</span>一词在该文件中的词频就是<span class="number">5</span>/<span class="number">100</span>=<span class="number">0.05</span>。</span><br><span class="line">而计算文件频率（IDF）的方法是以文件集的文件总数，除以出现<span class="string">"非常"</span>一词的文件数。</span><br><span class="line">所以，如果<span class="string">"非常"</span>一词在<span class="number">1</span>,<span class="number">0000</span>份文件出现过，而文件总数是<span class="number">10</span>,<span class="number">000</span>,<span class="number">000</span>份的话，</span><br><span class="line">其逆向文件频率就是lg（<span class="number">10</span>,<span class="number">000</span>,<span class="number">000</span> / <span class="number">1</span>,<span class="number">0000</span>）=<span class="number">3</span>。</span><br><span class="line">最后<span class="string">"非常"</span>对于这篇文档的tf-idf的分数为<span class="number">0.05</span> * <span class="number">3</span>=<span class="number">0.15</span></span><br></pre></td></tr></table></figure><h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行分词</span></span><br><span class="line"><span class="string">    "我爱北京天安门"————&gt;"我 爱 北京 天安门"</span></span><br><span class="line"><span class="string">    :param text:</span></span><br><span class="line"><span class="string">    :return: text</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 用结巴对中文字符串进行分词</span></span><br><span class="line">    text = <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_chinese_tfidf_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span>,</span><br><span class="line">            <span class="string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span>,</span><br><span class="line">            <span class="string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span>]</span><br><span class="line">    <span class="comment"># 将原始数据转换成分好词的形式</span></span><br><span class="line">    text_list = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        text_list.append(cut_word(sent))</span><br><span class="line">    print(text_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False)</span></span><br><span class="line">    <span class="comment"># 剔除'一种', '不会', '不要'这些词没有说明代表意义，减少计算</span></span><br><span class="line">    transfer = TfidfVectorizer(stop_words=[<span class="string">'一种'</span>, <span class="string">'不会'</span>, <span class="string">'不要'</span>])</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(text_list)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Building prefix dict <span class="keyword">from</span> the <span class="keyword">default</span> <span class="built_in">dictionary</span> ...</span><br><span class="line">Loading model <span class="keyword">from</span> cache /var/folders/mz/tzf2l3sx4rgg6qpglfb035_r0000gn/T/jieba.cache</span><br><span class="line">Loading model cost <span class="number">0.856</span> seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">[<span class="string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span>, <span class="string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span>, <span class="string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span>]</span><br><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.43643578</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.43643578</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.43643578</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span></span><br><span class="line">   <span class="number">0.</span>        ]</span><br><span class="line"> [ <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.2410822</span>   <span class="number">0.2410822</span></span><br><span class="line">   <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.2410822</span>   <span class="number">0.55004769</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.48216441</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.2410822</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.2410822</span> ]</span><br><span class="line"> [ <span class="number">0.</span>          <span class="number">0.644003</span>    <span class="number">0.48300225</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.16100075</span>  <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.16100075</span></span><br><span class="line">   <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.12244522</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.3220015</span>   <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>        ]]</span><br><span class="line">返回特征名字：</span><br><span class="line">[<span class="string">'之前'</span>, <span class="string">'了解'</span>, <span class="string">'事物'</span>, <span class="string">'今天'</span>, <span class="string">'光是在'</span>, <span class="string">'几百万年'</span>, <span class="string">'发出'</span>, <span class="string">'取决于'</span>, <span class="string">'只用'</span>, <span class="string">'后天'</span>, <span class="string">'含义'</span>, <span class="string">'大部分'</span>, <span class="string">'如何'</span>, <span class="string">'如果'</span>, <span class="string">'宇宙'</span>, <span class="string">'我们'</span>, <span class="string">'所以'</span>, <span class="string">'放弃'</span>, <span class="string">'方式'</span>, <span class="string">'明天'</span>, <span class="string">'星系'</span>, <span class="string">'晚上'</span>, <span class="string">'某样'</span>, <span class="string">'残酷'</span>, <span class="string">'每个'</span>, <span class="string">'看到'</span>, <span class="string">'真正'</span>, <span class="string">'秘密'</span>, <span class="string">'绝对'</span>, <span class="string">'美好'</span>, <span class="string">'联系'</span>, <span class="string">'过去'</span>, <span class="string">'还是'</span>, <span class="string">'这样'</span>]</span><br></pre></td></tr></table></figure><h5 id="Tf-idf的重要性"><a href="#Tf-idf的重要性" class="headerlink" title="Tf-idf的重要性"></a>Tf-idf的重要性</h5><p> <strong>分类机器学习算法进行文章分类中前期数据处理方式</strong> </p><p>举例：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">文章库中  <span class="number">1000</span>篇文章</span><br><span class="line">的  在 <span class="number">1000</span> 篇文章中都出现过</span><br><span class="line">python  在<span class="number">100</span> 文章中出现过</span><br><span class="line">java       在 <span class="number">100</span> 文章中出现过</span><br><span class="line"></span><br><span class="line">idf(的)  = lg(<span class="number">1000</span>/<span class="number">1000</span>)  = <span class="number">0</span></span><br><span class="line">idf(python) = lg(<span class="number">1000</span>/<span class="number">100</span>) = <span class="number">1</span></span><br><span class="line">idf(java) = lg(<span class="number">1000</span>/<span class="number">100</span>) = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">文章<span class="number">1</span> python  出现了 <span class="number">100</span>次，java也出现了<span class="number">10</span>次， 文章<span class="number">1</span>中一共有一千个词</span><br><span class="line">文章<span class="number">2</span> python  出现了 <span class="number">10</span>次，java也出现了<span class="number">100</span>次， 文章<span class="number">2</span>中一共有一千个词</span><br><span class="line"></span><br><span class="line">tf(python , 文章<span class="number">1</span>) = <span class="number">100</span> /<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line">tf(java, 文章<span class="number">1</span>) = <span class="number">10</span>/<span class="number">1000</span> = <span class="number">0.01</span></span><br><span class="line">tf(python , 文章<span class="number">2</span>) = <span class="number">10</span> /<span class="number">1000</span> = <span class="number">00.1</span></span><br><span class="line">tf(java, 文章<span class="number">2</span>) = <span class="number">100</span>/<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">tfidf(python , 文章<span class="number">1</span>) = <span class="number">0.1</span> * <span class="number">1</span>  = <span class="number">0.1</span></span><br><span class="line">tfidf(java, 文章<span class="number">1</span>) = <span class="number">0.01</span></span><br><span class="line">tfidf(的, 文章<span class="number">1</span>) = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">tfidf(python , 文章<span class="number">2</span>)  = <span class="number">00.1</span></span><br><span class="line">tfidf(java, 文章<span class="number">2</span>)  = <span class="number">0.1</span></span><br><span class="line">tfidf(的, 文章<span class="number">2</span>) = <span class="number">0</span></span><br><span class="line">相对而言，Java代表文章<span class="number">2</span>的主题，python代表文章<span class="number">1</span>的主题</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;特征提取&quot;&gt;&lt;a href=&quot;#特征提取&quot; class=&quot;headerlink&quot; title=&quot;特征提取&quot;&gt;&lt;/a&gt;特征提取&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;定义&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;将任意数据（如文本或图像）转换为可用于机器学习的数字特征&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注：特征值化是为了计算机更好的去理解数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;特征提取分类:&lt;ul&gt;
&lt;li&gt;字典特征提取(特征离散化)&lt;/li&gt;
&lt;li&gt;文本特征提取&lt;/li&gt;
&lt;li&gt;图像特征提取（深度学习将介绍）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="特征工程" scheme="https://xiaoliaozi.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="特征提取" scheme="https://xiaoliaozi.com/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    
      <category term="jieba分词处理" scheme="https://xiaoliaozi.com/tags/jieba%E5%88%86%E8%AF%8D%E5%A4%84%E7%90%86/"/>
    
      <category term="词袋模型" scheme="https://xiaoliaozi.com/tags/%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>决策树算法案例</title>
    <link href="https://xiaoliaozi.com/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B/"/>
    <id>https://xiaoliaozi.com/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B/</id>
    <published>2020-01-10T12:58:33.000Z</published>
    <updated>2020-02-27T02:12:16.558Z</updated>
    
    <content type="html"><![CDATA[<h4 id="决策树算法API"><a href="#决策树算法API" class="headerlink" title="决策树算法API"></a>决策树算法API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">tree</span>.<span class="title">DecisionTreeClassifier</span><span class="params">(criterion=’gini’, max_depth=None,random_state=None)</span></span></span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>criterion</li><li>特征选择标准<ul><li>“gini”或者”entropy”，前者代表基尼系数，后者代表信息增益。一默认”gini”，即CART算法。</li></ul></li><li>min_samples_split</li><li>内部节点再划分所需最小样本数<ul><li>这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。我之前的一个项目例子，有大概10万样本，建立决策树时，我选择了min_samples_split=10。可以作为参考。</li></ul></li><li>min_samples_leaf</li><li>叶子节点最少样本数<ul><li>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1，可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。之前的10万样本项目使用min_samples_leaf的值为5，仅供参考。</li></ul></li><li>max_depth</li><li>决策树最大深度<ul><li>决策树的最大深度，默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间</li></ul></li><li>random_state</li><li>随机数种子</li></ul><h4 id="案例-泰坦尼克号乘客生存预测"><a href="#案例-泰坦尼克号乘客生存预测" class="headerlink" title="案例-泰坦尼克号乘客生存预测"></a>案例-泰坦尼克号乘客生存预测</h4><h5 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h5><p>泰坦尼克号沉没是历史上最臭名昭着的沉船之一。1912年4月15日，在她的处女航中，泰坦尼克号在与冰山相撞后沉没，在2224名乘客和机组人员中造成1502人死亡。这场耸人听闻的悲剧震惊了国际社会，并为船舶制定了更好的安全规定。 造成海难失事的原因之一是乘客和机组人员没有足够的救生艇。尽管幸存下沉有一些运气因素，但有些人比其他人更容易生存，例如妇女，儿童和上流社会。 在这个案例中，我们要求您完成对哪些人可能存活的分析。特别是，我们要求您运用机器学习工具来预测哪些乘客幸免于悲剧。</p><p>案例：<a href="https://www.kaggle.com/c/titanic/overview" target="_blank" rel="noopener">https://www.kaggle.com/c/titanic/overview</a></p><p>我们提取到的数据集中的特征包括票的类别，是否存活，乘坐班次，年龄，登陆home.dest，房间，船和性别等。</p><p>数据：<a href="http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt" target="_blank" rel="noopener">http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt</a></p><p>经过观察数据得到:</p><ul><li><strong>1 乘坐班是指乘客班（1，2，3），是社会经济阶层的代表。</strong></li><li><strong>2 其中age数据存在缺失。</strong></li></ul><h5 id="步骤分析"><a href="#步骤分析" class="headerlink" title="步骤分析"></a>步骤分析</h5><ul><li><p>1.获取数据</p></li><li><p>2.数据基本处理</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.1</span> 确定特征值,目标值</span><br><span class="line"><span class="number">2.2</span> 缺失值处理</span><br><span class="line"><span class="number">2.3</span> 数据集划分</span><br></pre></td></tr></table></figure></li><li><p>3.特征工程(字典特征抽取)</p></li><li><p>4.机器学习(决策树)</p></li><li><p>5.模型评估</p></li></ul><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据</span></span><br><span class="line">taitan = pd.read_csv(<span class="string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span>)</span><br><span class="line">taitan.describe()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据基本处理</span></span><br><span class="line"><span class="comment"># 2.1 确定特征值,目标值</span></span><br><span class="line">x = taitan[[<span class="string">"pclass"</span>, <span class="string">"age"</span>, <span class="string">"sex"</span>]]</span><br><span class="line">y = taitan[<span class="string">"survived"</span>]</span><br><span class="line"><span class="comment"># 2.2 缺失值处理</span></span><br><span class="line"><span class="comment"># inplace:True:会修改原数据，False:不替换修改原数据，生成新的对象</span></span><br><span class="line">x[<span class="string">'age'</span>].fillna(x[<span class="string">'age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 2.3 数据集划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程(字典特征抽取)</span></span><br><span class="line"><span class="comment"># 特征中出现类别符号，需要进行one-hot编码处理(DictVectorizer)</span></span><br><span class="line"><span class="comment"># x.to_dict(orient="records") 需要将数组特征转换成字典数据</span></span><br><span class="line"><span class="comment"># 对于x转换成字典数据x.to_dict(orient="records")</span></span><br><span class="line">transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">x_train = transfer.fit_transform(x_train.to_dict(orient=<span class="string">"records"</span>))</span><br><span class="line">x_test = transfer.fit_transform(x_test.to_dict(orient=<span class="string">"records"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.机器学习(决策树)</span></span><br><span class="line">estimator = DecisionTreeClassifier(criterion=<span class="string">"entropy"</span>, max_depth=<span class="number">5</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 精确率</span></span><br><span class="line">estimator.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line">estimator.predict(x_test)</span><br></pre></td></tr></table></figure><h4 id="决策树可视化"><a href="#决策树可视化" class="headerlink" title="决策树可视化"></a>决策树可视化</h4><h5 id="保存树的结构到dot文件"><a href="#保存树的结构到dot文件" class="headerlink" title="保存树的结构到dot文件"></a>保存树的结构到dot文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn.tree.export_graphviz() 该函数能够导出DOT格式</span></span><br><span class="line"><span class="comment"># tree.export_graphviz(estimator,out_file='tree.dot’,feature_names=[‘’,’’])</span></span><br><span class="line"></span><br><span class="line">export_graphviz(estimator, out_file=<span class="string">"./data/tree.dot"</span>, feature_names=[<span class="string">'age'</span>, <span class="string">'pclass=1st'</span>, <span class="string">'pclass=2nd'</span>, <span class="string">'pclass=3rd'</span>, <span class="string">'女性'</span>, <span class="string">'男性'</span>])</span><br></pre></td></tr></table></figure><h5 id="网站显示结构"><a href="#网站显示结构" class="headerlink" title="网站显示结构"></a>网站显示结构</h5><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">http:</span><span class="comment">//webgraphviz.com/</span></span><br></pre></td></tr></table></figure><h5 id="结果显示"><a href="#结果显示" class="headerlink" title="结果显示"></a>结果显示</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093538.png"/></p><h5 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h5><ul><li>优点：简单的理解和解释，树木可视化。</li><li>缺点：<strong>决策树学习者可以创建不能很好地推广数据的过于复杂的树，容易发生过拟合。</strong></li><li>改进：<ul><li>剪枝cart算法</li><li><strong>随机森林</strong>（集成学习的一种）</li></ul></li></ul><p><strong>注：企业重要决策，由于决策树很好的分析能力，在决策过程应用较多， 可以选择特征</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;决策树算法API&quot;&gt;&lt;a href=&quot;#决策树算法API&quot; class=&quot;headerlink&quot; title=&quot;决策树算法API&quot;&gt;&lt;/a&gt;决策树算法API&lt;/h4&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sklearn&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;tree&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(criterion=’gini’, max_depth=None,random_state=None)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="机器学习算法" scheme="https://xiaoliaozi.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="机器学习算法" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
      <category term="机器学习" scheme="https://xiaoliaozi.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="决策树可视化" scheme="https://xiaoliaozi.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
      <category term="监督学习算法" scheme="https://xiaoliaozi.com/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
</feed>
