<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C++30天学习打卡（三）</title>
    <url>/2020/05/31/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h3 id="C-30天学习打卡（三）"><a href="#C-30天学习打卡（三）" class="headerlink" title="C++30天学习打卡（三）"></a>C++30天学习打卡（三）</h3><h3 id="程序流程结构"><a href="#程序流程结构" class="headerlink" title="程序流程结构"></a>程序流程结构</h3><p>C/C++支持最基本的三种程序运行结构：==顺序结构、选择结构、循环结构==</p>
<ul>
<li>顺序结构：程序按顺序执行，不发生跳转</li>
<li>选择结构：依据条件是否满足，有选择的执行相应功能</li>
<li>循环结构：依据条件是否满足，循环多次执行某段代码</li>
</ul>
<a id="more"></a>
<h4 id="选择结构"><a href="#选择结构" class="headerlink" title="选择结构"></a>选择结构</h4><ul>
<li><h5 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h5><ul>
<li><p><strong>作用：</strong>执行满足条件的语句</p>
</li>
<li><p>if语句的三种形式：单行格式if语句；多行格式if语句；多条件的if语句</p>
</li>
<li><p>注意：==在if判断语句后面，不要加分号==</p>
</li>
<li><p>代码示例：三只小猪称体重</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 三只小猪称体重</span></span><br><span class="line">	<span class="keyword">int</span> A = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> B = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> C = <span class="number">0</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪A的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; A;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪B的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; B;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请输入小猪C的体重："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; C;</span><br><span class="line">	<span class="keyword">if</span> (A &gt;= C) &#123;</span><br><span class="line">		<span class="keyword">if</span> (B &gt;= A) &#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪B的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪A的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (B &gt;= C) &#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪B的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"小猪C的体重最重"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="三目运算符"><a href="#三目运算符" class="headerlink" title="三目运算符"></a>三目运算符</h5><ul>
<li><p>作用：通过三目运算符实现简单的判断，和if语句比较，三目运算符优点是短小整洁，缺点是如果用嵌套，结构不清晰</p>
</li>
<li><p>语法：<code>表达式1 ? 表达式2 ：表达式3</code></p>
</li>
<li><p>解释：==如果表达式1的值为真，执行表达式2，并返回表达式2的结果；如果表达式1的值为假，执行表达式3，并返回表达式3的结果。==</p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line">	<span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> c = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	c = a &gt; b ? a : b;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"c = "</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// C++中的三目运算符返回的是变量，可以继续赋值</span></span><br><span class="line">	(a &gt; b ? a : b) = <span class="number">100</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"b = "</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"c = "</span> &lt;&lt; c &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="switch语句"><a href="#switch语句" class="headerlink" title="switch语句"></a>switch语句</h5><ul>
<li><p>作用：执行多条件分支语句</p>
</li>
<li><p>语法：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span>(表达式)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">case</span> 结果<span class="number">1</span>：执行语句;<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> 结果<span class="number">2</span>：执行语句;<span class="keyword">break</span>;</span><br><span class="line">	...</span><br><span class="line">	<span class="keyword">default</span>:执行语句;<span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 给电影评分</span></span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	9-10-非常好</span></span><br><span class="line"><span class="comment">	7-8-还行</span></span><br><span class="line"><span class="comment">	5-6-一般</span></span><br><span class="line"><span class="comment">	5以下-烂片</span></span><br><span class="line"><span class="comment">	*/</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请给该电影评分："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; score;</span><br><span class="line">	<span class="keyword">switch</span> (score)</span><br><span class="line">	&#123;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">10</span>:</span><br><span class="line">	<span class="keyword">case</span> <span class="number">9</span>:</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影非常好看"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">8</span>:</span><br><span class="line">	<span class="keyword">case</span> <span class="number">7</span>:</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影还行"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">case</span> <span class="number">6</span>:</span><br><span class="line">	<span class="keyword">case</span> <span class="number">5</span>:</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影一般"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	<span class="keyword">default</span>:</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"这部电影是烂片，别看"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>注意：</p>
<blockquote>
<p>1.switch语句中表达式类型只能是整型或者字符型；</p>
<p>2.case里如果没有break，那么程序会一直向下执行；</p>
<p>3.与if语句比，对于多条件判断时，switch的结构清晰，执行效率高，缺点是switch不可以判断区间。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h4 id="循环结构"><a href="#循环结构" class="headerlink" title="循环结构"></a>循环结构</h4><ul>
<li><h5 id="while循环语句"><a href="#while循环语句" class="headerlink" title="while循环语句"></a>while循环语句</h5><ul>
<li><p>作用：满足循环条件，执行循环语句。</p>
</li>
<li><p>语法：==while(循环条件){循环语句}==</p>
</li>
<li><p>示例：==猜数字==，注意：在执行循环语句时候，程序必须提供跳出循环的出口，否则出现死循环。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 猜数字游戏</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">bool</span> flag = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">while</span> (flag)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">// 随机生成数字</span></span><br><span class="line">		<span class="keyword">int</span> a = rand() % <span class="number">101</span>;</span><br><span class="line">		<span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"产生的随机数为："</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 测试用</span></span><br><span class="line">		<span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"请玩家输入猜测的数字："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">			<span class="built_in">cin</span> &gt;&gt; b;</span><br><span class="line">			<span class="keyword">if</span> (b &gt; a) &#123;</span><br><span class="line">				<span class="built_in">cout</span> &lt;&lt; <span class="string">"数字猜大了哦"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (b &lt; a) &#123;</span><br><span class="line">				<span class="built_in">cout</span> &lt;&lt; <span class="string">"猜的数字有点小了哈"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="built_in">cout</span> &lt;&lt; <span class="string">"恭喜玩家猜对了呢"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"退出游戏输入0，继续游戏输入1"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		<span class="built_in">cin</span> &gt;&gt; flag;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"退出游戏了哦"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="do…while循环语句"><a href="#do…while循环语句" class="headerlink" title="do…while循环语句"></a>do…while循环语句</h5><ul>
<li><p>作用：满足循环条件，执行循环语句；</p>
</li>
<li><p>语法：<code>do{ 循环语句 } while(循环条件);</code></p>
</li>
<li><p>注意：与while的区别在于==do…while会先执行一次循环语句==，再判断循环条件；</p>
</li>
<li><p>示例：水仙花数，水仙花数是指一个 3 位数，它的每个位上的数字的 3次幂之和等于它本身。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 水仙花数</span></span><br><span class="line">	<span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> c = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">int</span> start = <span class="number">100</span>;</span><br><span class="line">	<span class="keyword">do</span> &#123;</span><br><span class="line">		<span class="keyword">int</span> a = start / <span class="number">100</span>; <span class="comment">// 百位</span></span><br><span class="line">		b = (start / <span class="number">10</span>)%<span class="number">10</span>; <span class="comment">// 十位</span></span><br><span class="line">		c = start % <span class="number">10</span>; <span class="comment">// 个位</span></span><br><span class="line">		<span class="keyword">if</span> ((a*a*a + b*b*b + c*c*c) == start) &#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; start &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		start++;</span><br><span class="line">	&#125; <span class="keyword">while</span> (start &lt; <span class="number">1000</span>);</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="for循环语句"><a href="#for循环语句" class="headerlink" title="for循环语句"></a>for循环语句</h5><ul>
<li><p>作用： 满足循环条件，执行循环语句</p>
</li>
<li><p>语法：<code>for(起始表达式;条件表达式;末尾循环体) { 循环语句; }</code></p>
</li>
<li><p>注意：</p>
<blockquote>
<p>1.for循环中的表达式，要用分号进行分隔</p>
<p>2.while , do…while, for都是开发中常用的循环语句，for循环结构比较清晰，比较常用</p>
</blockquote>
</li>
<li><p>示例：敲桌子：从1开始数到数字100， 如果数字个位含有7，或者数字十位含有7，或者该数字是7的倍数，我们打印敲桌子，其余数字直接打印输出。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 敲桌子</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">100</span>; i++) &#123;</span><br><span class="line">		<span class="keyword">if</span> (i / <span class="number">10</span> == <span class="number">7</span> || i % <span class="number">10</span> == <span class="number">7</span> || i % <span class="number">7</span> == <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; <span class="string">"敲桌子\t"</span>;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="built_in">cout</span> &lt;&lt; i &lt;&lt;<span class="string">"\t"</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="嵌套循环"><a href="#嵌套循环" class="headerlink" title="嵌套循环"></a>嵌套循环</h5><ul>
<li><p>作用：在循环体中再嵌套一层循环，解决一些实际问题；</p>
</li>
<li><p>示例：九九乘法表</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 九九乘法表</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; <span class="number">10</span>; j++) &#123;</span><br><span class="line">			<span class="keyword">if</span> (j &lt;= i)&#123;</span><br><span class="line">				<span class="built_in">cout</span> &lt;&lt; j &lt;&lt; <span class="string">" * "</span> &lt;&lt; i &lt;&lt; <span class="string">" = "</span> &lt;&lt; i * j &lt;&lt; <span class="string">"\t"</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"\n"</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="跳转语句"><a href="#跳转语句" class="headerlink" title="跳转语句"></a>跳转语句</h4><ul>
<li><h5 id="break语句"><a href="#break语句" class="headerlink" title="break语句"></a>break语句</h5><ul>
<li>作用： 用于跳出==选择结构==或者==循环结构==</li>
<li>使用的时机：<ol>
<li>出现在switch条件语句中，作用是终止case并跳出switch;</li>
<li>出现在循环语句中，作用是跳出当前的循环语句;</li>
<li>出现在嵌套循环中，跳出==最近==的内层循环语句</li>
</ol>
</li>
</ul>
</li>
<li><h5 id="continue语句"><a href="#continue语句" class="headerlink" title="continue语句"></a>continue语句</h5><ul>
<li>作用：在==循环语句==中，跳过本次循环中余下尚未执行的语句，继续执行下一次循环</li>
<li>注意：==continue并没有使整个循环终止，而break会跳出循环。==</li>
</ul>
</li>
<li><h5 id="goto语句"><a href="#goto语句" class="headerlink" title="goto语句"></a>goto语句</h5><ul>
<li><p>作用：可以无条件跳转语句</p>
</li>
<li><p>语法： <code>goto 标记;</code>如果标记的名称存在，执行到goto语句时，会跳转到标记的位置。</p>
</li>
<li><p>示例：==在程序中不建议使用goto语句，以免造成程序流程混乱。==</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"1"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">goto</span> FLAG;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"2"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"3"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"4"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">FLAG:</span><br><span class="line"></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"5"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>C++30天学习打卡</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++30天学习打卡（二）</title>
    <url>/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h3 id="C-30天学习打卡（二）"><a href="#C-30天学习打卡（二）" class="headerlink" title="C++30天学习打卡（二）"></a>C++30天学习打卡（二）</h3><h4 id="1-数据类型"><a href="#1-数据类型" class="headerlink" title="1.数据类型"></a>1.数据类型</h4><blockquote>
<p>C++规定在创建一个变量或者常量时，必须要指定出相应的数据类型，否则无法给变量分配内存。</p>
<p>数据类型存在的意义：给变量分配合适的内存空间。</p>
</blockquote>
<ol>
<li><h5 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h5><ul>
<li><p>作用：整型变量表示的是<strong>整数类型</strong>的数据</p>
</li>
<li><p>分类：C++中能够表示整型的类型有以下几种方式，<strong>区别在于所占内存空间不同</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200531124009.png"/></p>
<a id="more"></a>
</li>
</ul>
</li>
<li><h5 id="sizeof关键字"><a href="#sizeof关键字" class="headerlink" title="sizeof关键字"></a>sizeof关键字</h5><ul>
<li><p>作用：利用sizeof关键字可以==统计数据类型所占内存大小==</p>
</li>
<li><p>语法：<strong>sizeof（数据类型/变量）</strong></p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"short 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(short) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"int 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">int</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"long 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">long</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"long long 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">long</span> <span class="keyword">long</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="实型（浮点型）"><a href="#实型（浮点型）" class="headerlink" title="实型（浮点型）"></a>实型（浮点型）</h5><ul>
<li><p>作用：用于==表示小数==</p>
</li>
<li><p>分类：浮点型变量分为两种，两者的<strong>区别</strong>在于表示的有效数字范围不同。</p>
<ol>
<li>单精度float;</li>
<li>双精度double;</li>
</ol>
<p>| <strong>数据类型</strong> | <strong>占用空间</strong> | <strong>有效数字范围</strong> |<br>| —————— | —————— | ———————— |<br>| float        | 4字节        | 7位有效数字      |<br>| double       | 8字节        | 15～16位有效数字 |</p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 1.单精度</span></span><br><span class="line">	<span class="comment">// 2.双精度</span></span><br><span class="line">	<span class="comment">// 默认情况下，输出一个小数，会显示6位有效数字</span></span><br><span class="line">	<span class="keyword">float</span> fl = <span class="number">3.1415926f</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"fl= "</span> &lt;&lt; fl &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">double</span> dl = <span class="number">3.145926</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"dl = "</span> &lt;&lt; dl &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 统计</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"float 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">float</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"double 类型所占内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">double</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//科学计数法</span></span><br><span class="line">	<span class="keyword">float</span> f2 = <span class="number">3e2</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"f2 = "</span> &lt;&lt; f2 &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">float</span> f3 = <span class="number">3e-2</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"f3 = "</span> &lt;&lt; f3 &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="字符型"><a href="#字符型" class="headerlink" title="字符型"></a>字符型</h5><ul>
<li><p>作用：字符型变量用于显示单个字符</p>
</li>
<li><p>语法：<strong>char ch = ‘a’</strong>;</p>
</li>
<li><p>注意：</p>
<ol>
<li><strong>在显示字符型变量时，用单引号将字符括起来，不要用双引号</strong>；</li>
<li><strong>单引号内只能有一个字符，不可以是字符串</strong>；</li>
<li><strong>C和C++中字符型变量只占用1个字节</strong>；</li>
<li><strong>字符型变量并不是把字符本身放到内存中存储，而是将对应的ASCII编码放入到存储单元</strong>。</li>
</ol>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 1.字符型变量创建方式</span></span><br><span class="line">	<span class="keyword">char</span> ch = <span class="string">'a'</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; ch &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2.字符型变量所占内存大小</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"char 字符型变量所占内存为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">char</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3.字符型变量常见错误 </span></span><br><span class="line">	<span class="comment">// char ch2 = "b"; // 要用单引号</span></span><br><span class="line">	<span class="comment">// char ch3 = 'abcdf' // 只能一个字符</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4.字符型变量对于ASKII码 a-97 A-65</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; (<span class="keyword">int</span>)ch &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="转义字符"><a href="#转义字符" class="headerlink" title="转义字符"></a>转义字符</h5><ul>
<li><p>作用：用于表示一些==不能显示出来的ASCII字符==</p>
</li>
<li><p>罗列：现阶段我们常用的转义字符有：<code>\n  \\  \t</code></p>
<p>| <strong>转义字符</strong> | <strong>含义</strong>                                | <strong>ASCII</strong>码值（十进制） |<br>| —————— | ———————————————————- | ———————————- |<br>| \a           | 警报                                    | 007                     |<br>| \b           | 退格(BS) ，将当前位置移到前一列         | 008                     |<br>| \f           | 换页(FF)，将当前位置移到下页开头        | 012                     |<br>| <strong>\n</strong>       | <strong>换行(LF) ，将当前位置移到下一行开头</strong> | <strong>010</strong>                 |<br>| \r           | 回车(CR) ，将当前位置移到本行开头       | 013                     |<br>| <strong>\t</strong>       | <strong>水平制表(HT)  （跳到下一个TAB位置）</strong> | <strong>009</strong>                 |<br>| \v           | 垂直制表(VT)                            | 011                     |<br>| <strong>\\</strong>     | <strong>代表一个反斜线字符”\”</strong>               | <strong>092</strong>                 |<br>| \’           | 代表一个单引号（撇号）字符              | 039                     |<br>| \”           | 代表一个双引号字符                      | 034                     |<br>| \?           | 代表一个问号                            | 063                     |<br>| \0           | 数字0                                   | 000                     |<br>| \ddd         | 8进制转义字符，d范围0~7                 | 3位8进制                |<br>| \xhh         | 16进制转义字符，h范围0~9，a~f，A~F      | 3位16进制               |</p>
</li>
</ul>
</li>
<li><h5 id="字符串型"><a href="#字符串型" class="headerlink" title="字符串型"></a>字符串型</h5><ul>
<li><p>作用：用于表示一串字符</p>
</li>
<li><p>两种风格：</p>
<ol>
<li>C风格字符串：<code>char 变量名[] = &quot;字符串值&quot;</code></li>
<li>C++风格字符串：<code>string 变量名 = “字符串”</code></li>
</ol>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;  // 新版vs自动包含了一些头文件</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// C++风格字符串 注意事项：双引号</span></span><br><span class="line">	<span class="built_in">string</span> xlz = <span class="string">"小廖子"</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"我的名字是："</span> &lt;&lt; xlz &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="布尔类型-bool"><a href="#布尔类型-bool" class="headerlink" title="布尔类型 bool"></a>布尔类型 bool</h5><ul>
<li><p>作用：布尔数据类型代表真或假的值 </p>
</li>
<li><p>表达方式：bool类型只有两个值：</p>
<ul>
<li>true  —- 真（本质是1）</li>
<li>false —- 假（本质是0）</li>
</ul>
</li>
<li><p>注意：bool类型占==1个字节==大小</p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 创建bool类型</span></span><br><span class="line">	<span class="keyword">bool</span> flag = <span class="literal">true</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; flag &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 1</span></span><br><span class="line">	flag = <span class="literal">false</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; flag &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 0</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 查看bool类型所占内存空间  1</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"bool 类型所占的内存空间为："</span> &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">bool</span>) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="数据的输入"><a href="#数据的输入" class="headerlink" title="数据的输入"></a>数据的输入</h5><ul>
<li><p>作用：用于从键盘获取数据</p>
</li>
<li><p>关键字：<strong>cin</strong></p>
</li>
<li><p>语法：<code>cin &gt;&gt; 变量</code></p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 数据输入</span></span><br><span class="line">	<span class="comment">// 1.整型</span></span><br><span class="line">	<span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请给整型变量a赋值："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; a;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"整型变量a的值为："</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2.浮点型</span></span><br><span class="line">	<span class="keyword">float</span> b = <span class="number">0.01</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"请给浮点型变量b赋值："</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="built_in">cin</span> &gt;&gt; b;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"浮点型变量b的值为："</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">     <span class="comment">// 其它都类似</span></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h4 id="2-运算符"><a href="#2-运算符" class="headerlink" title="2.运算符"></a>2.运算符</h4><p><strong>作用：</strong>用于执行代码的运算</p>
<p>本章我们主要讲解以下几类运算符：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>运算符类型</strong></th>
<th><strong>作用</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>算术运算符</td>
<td>用于处理四则运算</td>
</tr>
<tr>
<td>赋值运算符</td>
<td>用于将表达式的值赋给变量</td>
</tr>
<tr>
<td>比较运算符</td>
<td>用于表达式的比较，并返回一个真值或假值</td>
</tr>
<tr>
<td>逻辑运算符</td>
<td>用于根据表达式的值返回真值或假值</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><h5 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h5><ul>
<li><p>作用：用于处理四则运算 </p>
</li>
<li><p>罗列：注意：<strong>两个整数相除，结果依然是整数，将小数部分去除，10/20结果为0；两个小数可以相除，运算结果可以是小数。</strong></p>
<p>| 运算符<strong> | </strong>术语<strong>   | </strong>示例<strong>    | </strong>结果<em>*  |<br>| ———— | ————— | —————- | ————- |<br>| +        | 正号       | +3          | 3         |<br>| -        | 负号       | -3          | -3        |<br>| +        | 加         | 10 + 5      | 15        |<br>| -        | 减         | 10 - 5      | 5         |<br>| </em>        | 乘         | 10 * 5      | 50        |<br>| /        | 除         | 10 / 5      | 2         |<br>| %        | 取模(取余) | 10 % 3      | 1         |<br>| ++       | 前置递增   | a=2; b=++a; | a=3; b=3; |<br>| ++       | 后置递增   | a=2; b=a++; | a=3; b=2; |<br>| —       | 前置递减   | a=2; b=—a; | a=1; b=1; |<br>| —       | 后置递减   | a=2; b=a—; | a=1; b=2; |</p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 前置递增</span></span><br><span class="line">	<span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line">	++a;   <span class="comment">// 让变量加1</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a =  "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2.后置递增</span></span><br><span class="line">	<span class="keyword">int</span> b = <span class="number">10</span>;</span><br><span class="line">	b++;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"b = "</span> &lt;&lt; b &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 前置递增和后置递增的区别</span></span><br><span class="line">	<span class="comment">// 前置递增 先让变量+1 后进行表达是运算</span></span><br><span class="line">	<span class="keyword">int</span> a2 = <span class="number">10</span>;</span><br><span class="line">	<span class="keyword">int</span> b2 = ++a2 * <span class="number">10</span>; </span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a2 = "</span> &lt;&lt; a2 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 11</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"b2 = "</span> &lt;&lt; b2 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 110</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 后置递增 先进行表达是运算 后让变量+1</span></span><br><span class="line">	<span class="keyword">int</span> a3 = <span class="number">10</span>;</span><br><span class="line">	<span class="keyword">int</span> b3 = a3++ * <span class="number">10</span>; </span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a3 = "</span> &lt;&lt; a3 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 11</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"b3 = "</span> &lt;&lt; b3 &lt;&lt; <span class="built_in">endl</span>; <span class="comment">// 100</span></span><br><span class="line"></span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><h5 id="赋值运算符"><a href="#赋值运算符" class="headerlink" title="赋值运算符"></a>赋值运算符</h5><ul>
<li><p>作用：用于将表达式的值赋给变量</p>
</li>
<li><p>罗列：</p>
<p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong>   | <strong>结果</strong>  |<br>| ————— | ———— | ————— | ————- |<br>| =          | 赋值     | a=2; b=3;  | a=2; b=3; |<br>| +=         | 加等于   | a=0; a+=2; | a=2;      |<br>| -=         | 减等于   | a=5; a-=3; | a=2;      |<br>| <em>=         | 乘等于   | a=2; a</em>=2; | a=4;      |<br>| /=         | 除等于   | a=4; a/=2; | a=2;      |<br>| %=         | 模等于   | a=3; a%2;  | a=1;      |</p>
</li>
</ul>
</li>
<li><h5 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h5><ul>
<li><p>作用：用于表达式的比较，并返回一个真值或假值</p>
</li>
<li><p>罗列：注意：C和C++ 语言的比较运算中， ==“真”用数字“1”来表示， “假”用数字“0”来表示。== </p>
<p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong> | <strong>结果</strong> |<br>| ————— | ———— | ———— | ———— |<br>| ==         | 相等于   | 4 == 3   | 0        |<br>| !=         | 不等于   | 4 != 3   | 1        |<br>| &lt;          | 小于     | 4 &lt; 3    | 0        |<br>| >         | 大于     | 4 &gt; 3    | 1        |<br>| &lt;=         | 小于等于 | 4 &lt;= 3   | 0        |<br>| >=        | 大于等于 | 4 &gt;= 1   | 1        |</p>
</li>
</ul>
</li>
<li><h5 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h5><ul>
<li><p>作用：用于根据表达式的值返回真值或假值</p>
</li>
<li><p>罗列：</p>
<p>| <strong>运算符</strong> | <strong>术语</strong> | <strong>示例</strong> | <strong>结果</strong>                                                 |<br>| ————— | ———— | ———— | ———————————————————————————— |<br>| !          | 非       | !a       | 如果a为假，则!a为真；  如果a为真，则!a为假。             |<br>| &amp;&amp;         | 与       | a &amp;&amp; b   | 如果a和b都为真，则结果为真，否则为假。                   |<br>| ||       | 或       | a || b | 如果a和b有一个为真，则结果为真，二者都为假时，结果为假。 |</p>
</li>
</ul>
</li>
</ol>
<h4 id="3-扩展"><a href="#3-扩展" class="headerlink" title="3.扩展"></a>3.扩展</h4><p><strong>ASCII码表格：</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>ASCII</strong>值</th>
<th><strong>控制字符</strong></th>
<th><strong>ASCII</strong>值</th>
<th><strong>字符</strong></th>
<th><strong>ASCII</strong>值</th>
<th><strong>字符</strong></th>
<th><strong>ASCII</strong>值</th>
<th><strong>字符</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>NUT</td>
<td>32</td>
<td>(space)</td>
<td>64</td>
<td>@</td>
<td>96</td>
<td>、</td>
</tr>
<tr>
<td>1</td>
<td>SOH</td>
<td>33</td>
<td>!</td>
<td>65</td>
<td>A</td>
<td>97</td>
<td>a</td>
</tr>
<tr>
<td>2</td>
<td>STX</td>
<td>34</td>
<td>“</td>
<td>66</td>
<td>B</td>
<td>98</td>
<td>b</td>
</tr>
<tr>
<td>3</td>
<td>ETX</td>
<td>35</td>
<td>#</td>
<td>67</td>
<td>C</td>
<td>99</td>
<td>c</td>
</tr>
<tr>
<td>4</td>
<td>EOT</td>
<td>36</td>
<td>$</td>
<td>68</td>
<td>D</td>
<td>100</td>
<td>d</td>
</tr>
<tr>
<td>5</td>
<td>ENQ</td>
<td>37</td>
<td>%</td>
<td>69</td>
<td>E</td>
<td>101</td>
<td>e</td>
</tr>
<tr>
<td>6</td>
<td>ACK</td>
<td>38</td>
<td>&amp;</td>
<td>70</td>
<td>F</td>
<td>102</td>
<td>f</td>
</tr>
<tr>
<td>7</td>
<td>BEL</td>
<td>39</td>
<td>,</td>
<td>71</td>
<td>G</td>
<td>103</td>
<td>g</td>
</tr>
<tr>
<td>8</td>
<td>BS</td>
<td>40</td>
<td>(</td>
<td>72</td>
<td>H</td>
<td>104</td>
<td>h</td>
</tr>
<tr>
<td>9</td>
<td>HT</td>
<td>41</td>
<td>)</td>
<td>73</td>
<td>I</td>
<td>105</td>
<td>i</td>
</tr>
<tr>
<td>10</td>
<td>LF</td>
<td>42</td>
<td>*</td>
<td>74</td>
<td>J</td>
<td>106</td>
<td>j</td>
</tr>
<tr>
<td>11</td>
<td>VT</td>
<td>43</td>
<td>+</td>
<td>75</td>
<td>K</td>
<td>107</td>
<td>k</td>
</tr>
<tr>
<td>12</td>
<td>FF</td>
<td>44</td>
<td>,</td>
<td>76</td>
<td>L</td>
<td>108</td>
<td>l</td>
</tr>
<tr>
<td>13</td>
<td>CR</td>
<td>45</td>
<td>-</td>
<td>77</td>
<td>M</td>
<td>109</td>
<td>m</td>
</tr>
<tr>
<td>14</td>
<td>SO</td>
<td>46</td>
<td>.</td>
<td>78</td>
<td>N</td>
<td>110</td>
<td>n</td>
</tr>
<tr>
<td>15</td>
<td>SI</td>
<td>47</td>
<td>/</td>
<td>79</td>
<td>O</td>
<td>111</td>
<td>o</td>
</tr>
<tr>
<td>16</td>
<td>DLE</td>
<td>48</td>
<td>0</td>
<td>80</td>
<td>P</td>
<td>112</td>
<td>p</td>
</tr>
<tr>
<td>17</td>
<td>DCI</td>
<td>49</td>
<td>1</td>
<td>81</td>
<td>Q</td>
<td>113</td>
<td>q</td>
</tr>
<tr>
<td>18</td>
<td>DC2</td>
<td>50</td>
<td>2</td>
<td>82</td>
<td>R</td>
<td>114</td>
<td>r</td>
</tr>
<tr>
<td>19</td>
<td>DC3</td>
<td>51</td>
<td>3</td>
<td>83</td>
<td>S</td>
<td>115</td>
<td>s</td>
</tr>
<tr>
<td>20</td>
<td>DC4</td>
<td>52</td>
<td>4</td>
<td>84</td>
<td>T</td>
<td>116</td>
<td>t</td>
</tr>
<tr>
<td>21</td>
<td>NAK</td>
<td>53</td>
<td>5</td>
<td>85</td>
<td>U</td>
<td>117</td>
<td>u</td>
</tr>
<tr>
<td>22</td>
<td>SYN</td>
<td>54</td>
<td>6</td>
<td>86</td>
<td>V</td>
<td>118</td>
<td>v</td>
</tr>
<tr>
<td>23</td>
<td>TB</td>
<td>55</td>
<td>7</td>
<td>87</td>
<td>W</td>
<td>119</td>
<td>w</td>
</tr>
<tr>
<td>24</td>
<td>CAN</td>
<td>56</td>
<td>8</td>
<td>88</td>
<td>X</td>
<td>120</td>
<td>x</td>
</tr>
<tr>
<td>25</td>
<td>EM</td>
<td>57</td>
<td>9</td>
<td>89</td>
<td>Y</td>
<td>121</td>
<td>y</td>
</tr>
<tr>
<td>26</td>
<td>SUB</td>
<td>58</td>
<td>:</td>
<td>90</td>
<td>Z</td>
<td>122</td>
<td>z</td>
</tr>
<tr>
<td>27</td>
<td>ESC</td>
<td>59</td>
<td>;</td>
<td>91</td>
<td>[</td>
<td>123</td>
<td>{</td>
</tr>
<tr>
<td>28</td>
<td>FS</td>
<td>60</td>
<td>&lt;</td>
<td>92</td>
<td>/</td>
<td>124</td>
<td>\</td>
<td></td>
</tr>
<tr>
<td>29</td>
<td>GS</td>
<td>61</td>
<td>=</td>
<td>93</td>
<td>]</td>
<td>125</td>
<td>}</td>
</tr>
<tr>
<td>30</td>
<td>RS</td>
<td>62</td>
<td>&gt;</td>
<td>94</td>
<td>^</td>
<td>126</td>
<td>`</td>
</tr>
<tr>
<td>31</td>
<td>US</td>
<td>63</td>
<td>?</td>
<td>95</td>
<td>_</td>
<td>127</td>
<td>DEL</td>
</tr>
</tbody>
</table>
</div>
<p>ASCII 码大致由以下<strong>两部分组</strong>成：</p>
<ul>
<li>ASCII 非打印控制字符： ASCII 表上的数字 <strong>0-31</strong> 分配给了控制字符，用于控制像打印机等一些外围设备。</li>
<li>ASCII 打印字符：数字 <strong>32-126</strong> 分配给了能在键盘上找到的字符，当查看或打印文档时就会出现。</li>
</ul>
]]></content>
      <categories>
        <category>C++30天学习打卡</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++30天学习打卡（一）</title>
    <url>/2020/05/30/C-30%E5%A4%A9%E5%AD%A6%E4%B9%A0%E6%89%93%E5%8D%A1%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h3 id="C-30天学习打卡（一）"><a href="#C-30天学习打卡（一）" class="headerlink" title="C++30天学习打卡（一）"></a>C++30天学习打卡（一）</h3><h4 id="1-注释"><a href="#1-注释" class="headerlink" title="1.注释"></a>1.注释</h4><blockquote>
<ol>
<li>单行注释：//  描述信息</li>
<li>多行注释：/<em> 注释信息 </em>/</li>
</ol>
</blockquote>
<h4 id="2-变量"><a href="#2-变量" class="headerlink" title="2.变量"></a>2.变量</h4><ol>
<li><p>作用：给一段指定的内存空间起名，方便操作这段内存。</p>
</li>
<li><p>语法：数据类型   变量名 = 初始值；</p>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> a = <span class="number">10</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"a = "</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 注意：C++在创建变量时，必须给变量一个初始值，否则会报错</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<a id="more"></a>
<h4 id="3-常量"><a href="#3-常量" class="headerlink" title="3.常量"></a>3.常量</h4><ol>
<li><p>作用：用于记录不可更改的数据；</p>
</li>
<li><p>定义常量的两种方式：</p>
<blockquote>
<ol>
<li>#define 宏常量：#define  常量名  常量值<ul>
<li>== 通常在文件上方定义==，表示一个常量</li>
</ul>
</li>
<li>const 修饰的变量：const 数据类型  变量名 = 常量值<ul>
<li>==通常在变量定义前加关键字const==，修饰该变量为常量，不可修改</li>
</ul>
</li>
</ol>
</blockquote>
</li>
<li><p>示例：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> day 7</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 常量定义</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"一周共有 "</span> &lt;&lt; day &lt;&lt; <span class="string">" 天"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">int</span> month = <span class="number">12</span>;</span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"一年有几个 "</span> &lt;&lt; month &lt;&lt; <span class="string">" 月"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">	system(<span class="string">"pause"</span>);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="4-关键字"><a href="#4-关键字" class="headerlink" title="4.关键字"></a>4.关键字</h4><ol>
<li><p>作用：关键字是C++中预先保留的单词（标识符）</p>
</li>
<li><p>注意：在定义变量或者常量时候，不要用关键字，否则会产生歧义</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200530204651.png"/></p>
</li>
</ol>
<h4 id="5-标识符命名规则"><a href="#5-标识符命名规则" class="headerlink" title="5.标识符命名规则"></a>5.标识符命名规则</h4><ol>
<li><p>作用：C++规定给标识符（变量、常量）命名时，有一套自己的规则；</p>
</li>
<li><p>注意事项：</p>
<blockquote>
<ul>
<li>标识符不能是关键字</li>
<li>标识符只能由字母、数字、下划线组成</li>
<li>第一个字符必须为字母或下划线</li>
<li>标识符中字母区分大小写</li>
</ul>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>C++30天学习打卡</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Hive</title>
    <url>/2020/02/13/%E5%85%B3%E4%BA%8EHive/</url>
    <content><![CDATA[<h4 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h4><h5 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h5><ul>
<li>Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL)查询功能，底层数据是存储在 HDFS 上。</li>
<li>Hive 本质: 将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，<strong>是一款基于HDFS 的 MapReduce 计算框架</strong></li>
<li>主要用途：用来做离线数据分析，比直接用 MapReduce 开发效率更高。</li>
</ul>
<a id="more"></a>
<h5 id="为什么使用Hive"><a href="#为什么使用Hive" class="headerlink" title="为什么使用Hive"></a>为什么使用Hive</h5><ul>
<li>直接使用 Hadoop MapReduce 处理数据所面临的问题：<ul>
<li>人员学习成本太高</li>
<li>MapReduce 实现复杂查询逻辑开发难度太大</li>
</ul>
</li>
<li>使用 Hive<ul>
<li>操作接口采用类 SQL 语法，提供快速开发的能力</li>
<li>避免了去写 MapReduce，减少开发人员的学习成本</li>
<li>功能扩展很方便</li>
</ul>
</li>
</ul>
<h4 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h4><h5 id="Hive-架构图"><a href="#Hive-架构图" class="headerlink" title="Hive 架构图"></a>Hive 架构图</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200221213219.jpg"/></p>
<h5 id="Hive-组件"><a href="#Hive-组件" class="headerlink" title="Hive 组件"></a>Hive 组件</h5><ul>
<li>用户接口：包括 CLI、JDBC/ODBC、WebGUI。<ul>
<li>CLI(command line interface)为 shell 命令行</li>
<li>JDBC/ODBC 是 Hive 的 JAVA 实现，与传统数据库JDBC 类似</li>
<li>WebGUI 是通过浏览器访问 Hive。</li>
<li>HiveServer2基于Thrift，允许远程客户端使用多种编程语言如Java、Python向Hive提交请求</li>
</ul>
</li>
<li>元数据存储：通常是存储在关系数据库如 mysql/derby 中。<ul>
<li>Hive 将元数据存储在数据库中。</li>
<li>Hive 中的元数据包括<ul>
<li>表的名字</li>
<li>表的列</li>
<li>分区及其属性</li>
<li>表的属性（是否为外部表等）</li>
<li>表的数据所在目录等。</li>
</ul>
</li>
</ul>
</li>
<li>解释器、编译器、优化器、执行器：完成 HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在 HDFS 中，并在随后由 MapReduce 调用执行</li>
</ul>
<h5 id="Hive与Hadoop的关系"><a href="#Hive与Hadoop的关系" class="headerlink" title="Hive与Hadoop的关系"></a>Hive与Hadoop的关系</h5><ul>
<li>Hive 利用 HDFS 存储数据，利用 MapReduce 查询分析数据。</li>
<li>Hive是数据仓库工具，没有集群的概念，</li>
<li>如果想提交Hive作业只需要在hadoop集群 Master节点上装Hive就可以了</li>
</ul>
<h4 id="Hive与传统数据库对比"><a href="#Hive与传统数据库对比" class="headerlink" title="Hive与传统数据库对比"></a>Hive与传统数据库对比</h4><ul>
<li>hive 用于海量数据的离线数据分析 </li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Hive</th>
<th style="text-align:center">关系型数据库</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ANSI SQL</td>
<td style="text-align:center">不完全支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">更新</td>
<td style="text-align:center">INSERT OVERWRITE\INTO TABLE(默认)</td>
<td style="text-align:center">UPDATE\INSERT\DELETE</td>
</tr>
<tr>
<td style="text-align:center">事务</td>
<td style="text-align:center">不支持(默认)</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">模式</td>
<td style="text-align:center">读模式</td>
<td style="text-align:center">写模式</td>
</tr>
<tr>
<td style="text-align:center">查询语言</td>
<td style="text-align:center">HQL</td>
<td style="text-align:center">SQL</td>
</tr>
<tr>
<td style="text-align:center">数据存储</td>
<td style="text-align:center">HDFS</td>
<td style="text-align:center">Raw Device or Local FS</td>
</tr>
<tr>
<td style="text-align:center">执行</td>
<td style="text-align:center">MapReduce</td>
<td style="text-align:center">Executor</td>
</tr>
<tr>
<td style="text-align:center">执行延迟</td>
<td style="text-align:center">高</td>
<td style="text-align:center">低</td>
</tr>
<tr>
<td style="text-align:center">子查询</td>
<td style="text-align:center">只能用在From子句中</td>
<td style="text-align:center">完全支持</td>
</tr>
<tr>
<td style="text-align:center">处理数据规模</td>
<td style="text-align:center">大</td>
<td style="text-align:center">小</td>
</tr>
<tr>
<td style="text-align:center">可扩展性</td>
<td style="text-align:center">高</td>
<td style="text-align:center">低</td>
</tr>
<tr>
<td style="text-align:center">索引</td>
<td style="text-align:center">0.8版本后加入位图索引</td>
<td style="text-align:center">有复杂的索引</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>hive支持的数据类型<ul>
<li>原子数据类型<ul>
<li>TINYINT SMALLINT INT BIGINT BOOLEAN FLOAT DOUBLE STRING BINARY TIMESTAMP DECIMAL CHAR VARCHAR DATE</li>
</ul>
</li>
<li>复杂数据类型<ul>
<li>ARRAY  MAP  STRUCT</li>
</ul>
</li>
</ul>
</li>
<li>hive中表的类型<ul>
<li>托管表 (managed table) (内部表)</li>
<li>外部表</li>
</ul>
</li>
</ul>
<h4 id="Hive-数据模型"><a href="#Hive-数据模型" class="headerlink" title="Hive 数据模型"></a>Hive 数据模型</h4><ul>
<li>Hive 中所有的数据都存储在 HDFS 中，没有专门的数据存储格式</li>
<li>在创建表时指定数据中的分隔符，Hive 就可以映射成功，解析数据。</li>
<li>Hive 中包含以下数据模型：<ul>
<li>db：在 hdfs 中表现为 hive.metastore.warehouse.dir 目录下一个文件夹</li>
<li>table：在 hdfs 中表现所属 db 目录下一个文件夹</li>
<li>external table：数据存放位置可以在 HDFS 任意指定路径</li>
<li>partition：在 hdfs 中表现为 table 目录下的子目录</li>
<li>bucket：在 hdfs 中表现为同一个表目录下根据 hash 散列之后的多个文件</li>
</ul>
</li>
</ul>
<h4 id="Hive安装部署"><a href="#Hive安装部署" class="headerlink" title="Hive安装部署"></a>Hive安装部署</h4><ul>
<li><p>Hive 安装前需要安装好 JDK 和 Hadoop。配置好环境变量。 </p>
</li>
<li><p>下载Hive的安装包 <a href="http://archive.cloudera.com/cdh5/cdh/5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/</a> 并解压 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf hive-1.1.0-cdh5.7.0.tar.gz  -C ~/app/</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入到 解压后的hive目录 找到 conf目录, 修改配置文件 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">vi hive-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在hive-env.sh中指定hadoop的路径</span></span><br><span class="line">HADOOP_HOME=/root/bigdata/hadoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line"></span><br><span class="line">export HIVE_HOME=/root/bigdata/hive</span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据元数据存储的介质不同，分为下面两个版本，其中 derby 属于内嵌模式。实际生产环境中则使用 mysql 来进行元数据的存储。</p>
<ul>
<li><p>内置 derby 版： bin/hive 启动即可使用 缺点：不同路径启动 hive，每一个 hive 拥有一套自己的元数据，无法共享 </p>
</li>
<li><p>mysql 版 </p>
<ul>
<li>上传 mysql驱动到 hive安装目录的lib目录下   mysql-connector-java-5.*.jar </li>
<li>vi conf/hive-site.xml 配置 Mysql 元数据库信息(MySql安装见文档) </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 插入以下代码 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;&lt;!-- 指定mysql用户名 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;password&lt;/value&gt;&lt;!-- 指定mysql密码 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;mysql</span><br><span class="line">        &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;&lt;!-- 指定mysql数据库地址 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;!-- 指定mysql驱动 --&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">        &lt;!-- 到此结束代码 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.script.wrapper&lt;/name&gt;</span><br><span class="line">    &lt;value/&gt;</span><br><span class="line">    &lt;description/&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>hive启动 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动docker</span></span><br><span class="line">service docker start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过docker 启动mysql</span></span><br><span class="line">docker start mysql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 hive的metastore元数据服务</span></span><br><span class="line">hive --service metastore</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动hive</span></span><br><span class="line">hive</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Hive基本操作"><a href="#Hive基本操作" class="headerlink" title="Hive基本操作"></a>Hive基本操作</h4><ul>
<li><p>创建数据库 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>显示所有数据库 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">DATABASES</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建表 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(classNo <span class="keyword">string</span>, stuNo <span class="keyword">string</span>, score <span class="built_in">int</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>row format delimited fields terminated by ‘,’ 指定了字段的分隔符为逗号</li>
<li>所以load数据的时候，load的文本也要为逗号，否则加载后为NULL。</li>
<li>hive只支持单个字符的分隔符，hive默认的分隔符是\001 </li>
</ul>
</li>
<li><p>将数据load到表中 </p>
<ul>
<li>在本地文件系统创建一个如下的文本文件：/home/hadoop/tmp/student.txt </li>
</ul>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line"><span class="attr"># 数据</span></span><br><span class="line"><span class="attr">C01</span>,<span class="symbol">N0101</span>,<span class="number">82</span></span><br><span class="line">C<span class="number">01</span>,<span class="symbol">N0102</span>,<span class="number">59</span></span><br><span class="line">C<span class="number">01</span>,<span class="symbol">N0103</span>,<span class="number">65</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0201</span>,<span class="number">81</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0202</span>,<span class="number">82</span></span><br><span class="line">C<span class="number">02</span>,<span class="symbol">N0203</span>,<span class="number">79</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0301</span>,<span class="number">56</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0302</span>,<span class="number">92</span></span><br><span class="line">C<span class="number">03</span>,<span class="symbol">N0306</span>,<span class="number">72</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/tmp/student.txt'</span>overwrite <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>
<ul>
<li>这个命令将student.txt文件复制到hive的warehouse目录中</li>
<li>这个目录由hive.metastore.warehouse.dir配置项设置，默认值为/user/hive/warehouse。</li>
<li>Overwrite选项将导致Hive事先删除student目录下所有的文件，并将文件内容映射到表中。</li>
<li>Hive不会对student.txt做任何格式处理，因为Hive本身并不强调数据的存储格式。 </li>
</ul>
</li>
<li><p>查询表中的数据 跟SQL类似 </p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">hive&gt;select * from student;</span><br></pre></td></tr></table></figure>
</li>
<li><p>分组查询group by和统计 count </p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">hive&gt;select classNo,count(score) from student where score&gt;=60 group by classNo;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Hive的内部表和外部表"><a href="#Hive的内部表和外部表" class="headerlink" title="Hive的内部表和外部表"></a>Hive的内部表和外部表</h4><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>内部表(managed table)</th>
<th>外部表(external table)</th>
</tr>
</thead>
<tbody>
<tr>
<td>概念</td>
<td>创建表时无external修饰</td>
<td>创建表时被external修饰</td>
</tr>
<tr>
<td>数据管理</td>
<td>由Hive自身管理</td>
<td>由HDFS管理</td>
</tr>
<tr>
<td>数据保存位置</td>
<td>hive.metastore.warehouse.dir （默认：/user/hive/warehouse）</td>
<td>hdfs中任意位置</td>
</tr>
<tr>
<td>删除时影响</td>
<td>直接删除元数据（metadata）及存储数据</td>
<td>仅会删除元数据，HDFS上的文件并不会被删除</td>
</tr>
<tr>
<td>表结构修改时影响</td>
<td>修改会将修改直接同步给元数据</td>
<td>表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）</td>
</tr>
</tbody>
</table>
</div>
<p><strong>小案例</strong></p>
<ul>
<li><p>创建一个外部表student2 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建外部表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> student2 (classNo <span class="keyword">string</span>, stuNo <span class="keyword">string</span>, score <span class="built_in">int</span>) <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span> location <span class="string">'/tmp/student'</span>;</span><br><span class="line"><span class="comment"># 装载数据</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/tmp/student.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> student2;</span><br></pre></td></tr></table></figure>
</li>
<li><p>显示表信息 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">desc formatted table_name;</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除表查看结果 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>
</li>
<li><p>再次创建外部表 student2 </p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不插入数据直接查询查看结果</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> student2;</span><br><span class="line"><span class="comment"># 能查到数据吗？能</span></span><br><span class="line"><span class="comment"># 外部表只删除元数据，不会删除储存数据</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Hive分区表"><a href="#Hive分区表" class="headerlink" title="Hive分区表"></a>Hive分区表</h4><ul>
<li><p>什么是分区表 </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span>随着表的不断增大，对于新纪录的增加，查找，删除等(DML)的维护也更加困难。对于数据库中的超大型表，可以通过把它的数据分成若干个小表，从而简化数据库的管理活动，对于每一个简化后的小表，我们称为一个单个的分区。</span><br><span class="line"><span class="number">2.</span>hive中分区表实际就是对应hdfs文件系统上独立的文件夹，该文件夹内的文件是该分区所有数据文件。</span><br><span class="line"><span class="number">3.</span>分区可以理解为分类，通过分类把不同类型的数据放到不同的目录下。</span><br><span class="line"><span class="number">4.</span>分类的标准就是分区字段，可以一个，也可以多个。</span><br><span class="line"><span class="number">5.</span>分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建分区表</p>
</li>
</ul>
<ul>
<li><p>查看表的分区</p>
</li>
<li><p>添加分区</p>
</li>
<li><p>加载数据到分区</p>
</li>
<li><p>如果重复加载同名文件，不会报错，会自动创建一个*_copy_1.txt </p>
</li>
<li><p>外部分区表即使有分区的目录结构, 也必须要通过hql添加分区, 才能看到相应的数据 </p>
</li>
</ul>
<p><strong>总结</strong></p>
<blockquote>
<p>利用分区表方式减少查询时需要扫描的数据量</p>
<ul>
<li>分区字段不是表中的列, 数据文件中没有对应的列</li>
<li>分区仅仅是一个目录名</li>
<li>查看数据时, hive会自动添加分区列</li>
<li>支持多级分区, 多级子目录</li>
</ul>
</blockquote>
<h4 id="Hive动态分区"><a href="#Hive动态分区" class="headerlink" title="Hive动态分区"></a>Hive动态分区</h4><ul>
<li>在写入数据时自动创建分区(包括目录结构)</li>
<li>创建表 </li>
<li>导入数据</li>
<li>使用动态分区需要设置参数</li>
</ul>
<h4 id="Hive函数"><a href="#Hive函数" class="headerlink" title="Hive函数"></a>Hive函数</h4><h5 id="内置运算符"><a href="#内置运算符" class="headerlink" title="内置运算符"></a>内置运算符</h5><h5 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h5><h5 id="Hive-自定义函数和-Transform"><a href="#Hive-自定义函数和-Transform" class="headerlink" title="Hive 自定义函数和 Transform"></a>Hive 自定义函数和 Transform</h5><h4 id="Hive综合案例"><a href="#Hive综合案例" class="headerlink" title="Hive综合案例"></a>Hive综合案例</h4><h4 id="拓展-ANSI-SQL"><a href="#拓展-ANSI-SQL" class="headerlink" title="拓展-ANSI SQL"></a>拓展-ANSI SQL</h4><p>了解一下即可，一般做ORM的需要深入学习，对象关系映射（Object Relational Mapping，简称ORM）模式是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。 </p>
<ul>
<li><p>ANSI：美国国家标准化组织，是一个核准多种行业标准的组织。</p>
</li>
<li><p>SQL</p>
<ul>
<li>结构化查询语言</li>
<li>是与关系型数据库进行通信的标准语言</li>
<li>最初由IBM公司的E.F.Codd博士论文为原型开发出来的。</li>
</ul>
</li>
<li><p>ANSI SQL：国际标准SQL语法</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>Hive</tag>
        <tag>Hive架构</tag>
        <tag>Hive与Hadoop的关系</tag>
        <tag>Hive与传统数据库对比</tag>
        <tag>Hive基本操作</tag>
        <tag>Hive函数</tag>
      </tags>
  </entry>
  <entry>
    <title>HADOOP概念扩展</title>
    <url>/2020/02/12/HADOOP%E6%A6%82%E5%BF%B5%E6%89%A9%E5%B1%95/</url>
    <content><![CDATA[<h4 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h4><h5 id="狭义的Hadoop-VS-广义的Hadoop"><a href="#狭义的Hadoop-VS-广义的Hadoop" class="headerlink" title="狭义的Hadoop VS 广义的Hadoop"></a>狭义的Hadoop VS 广义的Hadoop</h5><p> 广义的Hadoop：指的是Hadoop生态系统，Hadoop生态系统是一个很庞大的概念，hadoop是其中最重要最基础的一个部分，生态系统中每一子系统只解决某一个特定的问题域（甚至可能更窄），不搞统一型的全能系统，而是小而精的多个小系统。</p>
<a id="more"></a>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203527.png"/> </p>
<ul>
<li>Hive：数据仓库</li>
<li>R：数据分析</li>
<li>Mahout：机器学习库</li>
<li>pig：脚本语言，跟Hive类似</li>
<li>Oozie：工作流引擎，管理作业执行顺序</li>
<li>Zookeeper：用户无感知，主节点挂掉选择从节点作为主的</li>
<li>Flume：日志收集框架</li>
<li>Sqoop：数据交换框架，例如：关系型数据库与HDFS之间的数据交换</li>
<li>Hbase : 海量数据中的查询，相当于分布式文件系统中的数据库</li>
<li><p>Spark: 分布式的计算框架基于内存</p>
<ul>
<li>spark core</li>
<li>spark sql</li>
<li>spark streaming 准实时 不算是一个标准的流式计算</li>
<li>spark ML spark MLlib</li>
</ul>
</li>
<li><p>Kafka: 消息队列</p>
</li>
<li>Storm: 分布式的流式计算框架 python操作storm</li>
<li>Flink: 分布式的流式计算框架</li>
</ul>
<h5 id="Hadoop生态系统的特点"><a href="#Hadoop生态系统的特点" class="headerlink" title="Hadoop生态系统的特点"></a><strong>Hadoop生态系统的特点</strong></h5><ul>
<li>开源、社区活跃</li>
<li>囊括了大数据处理的方方面面</li>
<li>成熟的生态圈</li>
</ul>
<h4 id="HDFS-读写流程-amp-高可用"><a href="#HDFS-读写流程-amp-高可用" class="headerlink" title="HDFS 读写流程&amp; 高可用"></a>HDFS 读写流程&amp; 高可用</h4><h5 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203608.jpg"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203557.jpg"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203543.jpg"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203536.jpg"/> </p>
<ul>
<li>客户端向NameNode发出写文件请求。 </li>
<li>检查是否已存在文件、检查权限。若通过检查，直接先将操作写入EditLog，并返回输出流对象。 （注：WAL，write ahead log，先写Log，再写内存，因为EditLog记录的是最新的HDFS客户端执行所有的写操作。如果后续真实写操作失败了，由于在真实写操作之前，操作就被写入EditLog中了，故EditLog中仍会有记录，我们不用担心后续client读不到相应的数据块，因为在第5步中DataNode收到块后会有一返回确认信息，若没写成功，发送端没收到确认信息，会一直重试，直到成功）</li>
<li>client端按128MB的块切分文件。</li>
<li>client将NameNode返回的分配的可写的DataNode列表和Data数据一同发送给最近的第一个DataNode节点，此后client端和NameNode分配的多个DataNode构成pipeline管道，client端向输出流对象中写数据。client每向第一个DataNode写入一个packet，这个packet便会直接在pipeline里传给第二个、第三个…DataNode。 （注：并不是写好一个块或一整个文件后才向后分发）</li>
<li>每个DataNode写完一个块后，会返回确认信息。 （注：并不是每写完一个packet后就返回确认信息，个人觉得因为packet中的每个chunk都携带校验信息，没必要每写一个就汇报一下，这样效率太慢。正确的做法是写完一个block块后，对校验信息进行汇总分析，就能得出是否有块写错的情况发生）</li>
<li>写完数据，关闭输输出流。</li>
<li>发送完成信号给NameNode。（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）。</li>
</ul>
<h5 id="HDFS如何实现高可用-HA"><a href="#HDFS如何实现高可用-HA" class="headerlink" title="HDFS如何实现高可用(HA)"></a>HDFS如何实现高可用(HA)</h5><ul>
<li><strong>数据存储故障容错</strong> <ul>
<li>磁盘介质在存储过程中受环境或者老化影响，数据可能错乱</li>
<li>对于存储在 DataNode 上的数据块，计算并存储校验和（CheckSum)</li>
<li>读取数据的时候，重新计算读取出来的数据校验和， 校验不正确抛出异常，从其它DataNode上读取备份数据</li>
</ul>
</li>
<li><strong>磁盘故障容错</strong><ul>
<li>DataNode 监测到本机的某块磁盘损坏</li>
<li>将该块磁盘上存储的所有 BlockID 报告给 NameNode</li>
<li>NameNode 检查这些数据块在哪些DataNode上有备份,</li>
<li>通知相应DataNode, 将数据复制到其他服务器上</li>
</ul>
</li>
<li><strong>DataNode故障容错</strong><ul>
<li>通过心跳和NameNode保持通讯</li>
<li>超时未发送心跳， NameNode会认为这个DataNode已经宕机</li>
<li>NameNode查找这个DataNode上有哪些数据块，以及这些数据在其它DataNode服务器上的存储情况</li>
<li>从其它DataNode服务器上复制数据</li>
</ul>
</li>
<li><strong>NameNode故障容错</strong><ul>
<li>主从热备 secondary namenode</li>
<li>zookeeper配合 master节点选举</li>
</ul>
</li>
</ul>
<h4 id="Hadoop发行版的选择"><a href="#Hadoop发行版的选择" class="headerlink" title="Hadoop发行版的选择"></a>Hadoop发行版的选择</h4><h5 id="社区版-Apache-Hadoop"><a href="#社区版-Apache-Hadoop" class="headerlink" title="社区版 Apache Hadoop"></a>社区版 Apache Hadoop</h5><ul>
<li><p>开源，技术最新；</p>
</li>
<li><p>最新的Hadoop版本都是从Apache Hadoop发布的，可以在 xxx.apache.org上进行软件的下载；</p>
</li>
<li><p>当涉及到的大数据工具比较多的时候，比较容易出现兼容性的问题，所以我们以后在选择发行版本的时候，<strong>一般选择CDH的版本</strong>，如果选择社区版可能因为兼容问题，耽误大量时间，并且可能还解决不了问题。</p>
</li>
</ul>
<h5 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h5><ul>
<li>部分内容没有开源，技术会有滞后</li>
<li>Cloudera 在社区版的基础上做了一些修改</li>
<li>在<a href="http://archive.cloudera.com/cdh5/cdh/5/进行下载" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/cdh/5/进行下载</a></li>
<li>hadoop-2.6.0-cdh-5.7.0 和 Flume<strong>*</strong>-cdh5.7.0 cdh版本一致 的各个组件配合是有不会有兼容性问题</li>
<li>一般情况下建议使用CDH版本</li>
</ul>
<h5 id="HDP"><a href="#HDP" class="headerlink" title="HDP"></a>HDP</h5><ul>
<li>商用的版本，用得比较少</li>
</ul>
<h4 id="大数据产品与互联网产品结合"><a href="#大数据产品与互联网产品结合" class="headerlink" title="大数据产品与互联网产品结合"></a>大数据产品与互联网产品结合</h4><p>1、分布式系统执行任务瓶颈: 延迟高 MapReduce 几分钟 Spark几秒钟</p>
<p>2、互联网产品要求</p>
<ul>
<li>毫秒级响应(1秒以内完成)</li>
<li>需要通过大数据实现 统计分析 数据挖掘 关联推荐 用户画像</li>
</ul>
<p>3、大数据平台</p>
<ul>
<li>整合网站应用和大数据系统之间的差异, 将应用产生的数据导入到大数据系统, 经过处理计算后再导出给应用程序使用</li>
</ul>
<p>4、互联网大数据平台架构</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227203551.png"/> </p>
<p>5、数据采集</p>
<ul>
<li>App/Web 产生的数据&amp;日志同步到大数据系统</li>
<li>数据库同步:Sqoop，日志同步:Flume， 打点: Kafka</li>
<li>不同数据源产生的数据质量可能差别很大<ul>
<li>数据库 也许可以直接用</li>
<li>日志 爬虫 大量的清洗,转化处理</li>
</ul>
</li>
</ul>
<p>6、数据处理</p>
<ul>
<li>大数据存储与计算的核心</li>
<li>数据同步后导入HDFS</li>
<li>MapReduce Hive Spark 读取数据进行计算 结果再保存到HDFS</li>
<li>MapReduce Hive Spark 离线计算，HDFS 离线存储<ul>
<li>离线计算通常针对(某一类别)全体数据，比如 历史上所有订单</li>
<li>离线计算特点: 数据规模大, 运行时间长</li>
</ul>
</li>
<li>流式计算<ul>
<li>淘宝双11 每秒产生订单数 监控宣传</li>
<li>Storm(毫秒) SparkStreaming(秒)</li>
</ul>
</li>
</ul>
<p>7、数据输出与展示</p>
<ul>
<li>HDFS需要把数据导出交给应用程序，让用户实时展示 ECharts<ul>
<li>淘宝卖家量子魔方</li>
</ul>
</li>
<li>给运营和决策层提供各种统计报告，数据需要写入数据库<ul>
<li>很多运营管理人员，上班后就会登陆后台数据系统</li>
</ul>
</li>
</ul>
<p>8、任务调度系统</p>
<ul>
<li>将上面三个部分整合起来</li>
</ul>
<h4 id="拓展：大数据应用-数据分析"><a href="#拓展：大数据应用-数据分析" class="headerlink" title="拓展：大数据应用-数据分析"></a>拓展：大数据应用-数据分析</h4><p>1、通过数据分析指标监控企业运营状态，及时调整运营和产品策略,是大数据技术的关键价值之一</p>
<p>2、大数据平台(互联网企业)运行的绝大多数大数据计算都是关于数据分析的</p>
<ul>
<li>统计指标</li>
<li>关联分析,</li>
<li>汇总报告,</li>
</ul>
<p>3、运营数据是公司管理的基础</p>
<ul>
<li>了解公司目前发展的状况</li>
<li>数据驱动运营: 调节指标对公司进行管理</li>
</ul>
<p>4、运营数据的获取需要大数据平台的支持</p>
<ul>
<li>埋点采集数据</li>
<li>数据库，日志 三方采集数据</li>
<li>对数据清洗 转换 存储</li>
<li>利用SQL进行数据统计 汇总 分析</li>
<li>得到需要的运营数据报告</li>
</ul>
<p>5、运营常用数据指标</p>
<ul>
<li><p>新增用户数 UG user growth 用户增长</p>
<ul>
<li>产品增长性的关键指标</li>
<li>新增访问网站(新下载APP)的用户数</li>
</ul>
</li>
<li><p>用户留存率</p>
<ul>
<li>用户留存率 = 留存用户数 / 当期新增用户数</li>
<li>3日留存 5日留存 7日留存</li>
</ul>
</li>
<li><p>活跃用户数</p>
<ul>
<li>打开使用产品的用户</li>
<li>日活</li>
<li>月活</li>
<li>提升活跃是网站运营的重要目标</li>
</ul>
</li>
<li><p>PV Page View</p>
<ul>
<li>打开产品就算活跃</li>
<li>打开以后是否频繁操作就用PV衡量, 每次点击, 页面跳转都记一次PV</li>
</ul>
</li>
<li><p>GMV</p>
<ul>
<li>成交总金额(Gross Merchandise Volume) 电商网站统计营业额, 反应网站应收能力的重要指标</li>
<li>GMV相关的指标: 订单量 客单价</li>
</ul>
</li>
<li><p>转化率</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">转化率 = 有购买行为的用户数 / 总访问用户数</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>Hadoop生态系统</tag>
        <tag>HDFS 读写流程&amp;高可用</tag>
        <tag>Hadoop发行版的选择</tag>
      </tags>
  </entry>
  <entry>
    <title>YARN和MAPREDUCE</title>
    <url>/2020/02/12/YARN%E5%92%8CMAPREDUCE/</url>
    <content><![CDATA[<h4 id="资源调度框架-YARN"><a href="#资源调度框架-YARN" class="headerlink" title="资源调度框架 YARN"></a>资源调度框架 YARN</h4><h5 id="什么是YARN"><a href="#什么是YARN" class="headerlink" title="什么是YARN"></a>什么是YARN</h5><ul>
<li>Yet Another Resource Negotiator, 另一种资源协调者</li>
<li>通用资源管理系统</li>
<li>为上层应用提供统一的资源管理和调度，为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处</li>
</ul>
<a id="more"></a>
<h5 id="YARN产生背景"><a href="#YARN产生背景" class="headerlink" title="YARN产生背景"></a>YARN产生背景</h5><ul>
<li><p>通用资源管理系统</p>
<ul>
<li>Hadoop数据分布式存储（数据分块，冗余存储）</li>
<li>当多个MapReduce任务要用到相同的hdfs数据， 需要进行资源调度管理</li>
<li>Hadoop1.x时并没有YARN，MapReduce 既负责进行计算作业又处理服务器集群资源调度管理</li>
</ul>
</li>
<li><p>服务器集群资源调度管理和MapReduce执行过程耦合在一起带来的问题</p>
<ul>
<li>Hadoop早期, 技术只有Hadoop, 这个问题不明显</li>
<li>随着大数据技术的发展，Spark Storm … 计算框架都要用到服务器集群资源</li>
<li><p>如果没有通用资源管理系统，只能为多个集群分别提供数据</p>
<ul>
<li>资源利用率低 运维成本高</li>
</ul>
</li>
<li><p>Yarn (Yet Another Resource Negotiator) 另一种资源调度器</p>
<ul>
<li>Mesos 大数据资源管理产品</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171624.png"/></p>
</li>
<li><p>不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171624.png"/></p>
</li>
</ul>
<h5 id="YARN的架构和执行流程"><a href="#YARN的架构和执行流程" class="headerlink" title="YARN的架构和执行流程"></a>YARN的架构和执行流程</h5><ul>
<li>ResourceManager: RM 资源管理器 整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度 处理客户端的请求： submit, kill 监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理</li>
<li>NodeManager: NM 节点管理器 整个集群中有多个，负责自己本身节点资源管理和使用 定时向RM汇报本节点的资源使用情况 接收并处理来自RM的各种命令：启动Container 处理来自AM的命令</li>
<li>ApplicationMaster: AM 每个应用程序对应一个：MR、Spark，负责应用程序的管理 为应用程序向RM申请资源（core、memory），分配给内部task 需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面</li>
<li>Container 容器: 封装了CPU、Memory等资源的一个容器,是一个任务运行环境的抽象</li>
<li><p>Client: 提交作业，查询作业的运行进度，杀死作业</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227165923.png"/></p>
</li>
</ul>
<blockquote>
<p> 1.Client提交作业请求</p>
<p>2.ResourceManager 进程和 NodeManager 进程通信，根据集群资源，为用户程序分配第一个Container(容器)，并将 ApplicationMaster 分发到这个容器上面</p>
<p>3.在启动的Container中创建ApplicationMaster</p>
<p>4.ApplicationMaster启动后向ResourceManager注册进程,申请资源</p>
<p>5.ApplicationMaster申请到资源后，向对应的NodeManager申请启动Container，将要执行的程序分发到NodeManager上</p>
<p>6.Container启动后，执行对应的任务</p>
<p>7.Tast执行完毕之后，向ApplicationMaster返回结果</p>
<p>8.ApplicationMaster向ResourceManager 请求kill</p>
</blockquote>
<h5 id="YARN环境搭建"><a href="#YARN环境搭建" class="headerlink" title="YARN环境搭建"></a>YARN环境搭建</h5><p>1）mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>2）yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>3) 启动YARN相关的进程 sbin/start-yarn.sh</p>
<p>4）验证 jps ResourceManager NodeManager <a href="http://192,168.19.137:8088" target="_blank" rel="noopener">http://192,168.19.137:8088</a></p>
<p>5）停止YARN相关的进程 sbin/stop-yarn.sh</p>
<h4 id="分布式处理框架-MapReduce"><a href="#分布式处理框架-MapReduce" class="headerlink" title="分布式处理框架 MapReduce"></a>分布式处理框架 MapReduce</h4><h5 id="什么是MapReduce"><a href="#什么是MapReduce" class="headerlink" title="什么是MapReduce"></a>什么是MapReduce</h5><ul>
<li>定义： 分布式计算框架</li>
<li>作用： 海量数据的离线处理</li>
<li>MapReduce优点: 海量数据离线处理&amp;易开发</li>
<li>MapReduce缺点: 实时流式计算</li>
</ul>
<h5 id="MapReduce编程模型"><a href="#MapReduce编程模型" class="headerlink" title="MapReduce编程模型"></a>MapReduce编程模型</h5><ul>
<li>MapReduce分而治之的思想 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">数钱实例：一堆钞票，各种面值分别是多少</span><br><span class="line">单点策略：一个人数所有的钞票，数出各种面值有多少张</span><br><span class="line">分治策略：</span><br><span class="line">	每个人分得一堆钞票，数出各种面值有多少张</span><br><span class="line">	汇总，每个人负责统计一种面值</span><br><span class="line">解决数据可以切割进行计算的应用</span><br></pre></td></tr></table></figure>
<ul>
<li>MapReduce编程分Map和Reduce阶段 <ul>
<li>将作业拆分成Map阶段和Reduce阶段</li>
<li>Map阶段 Map Tasks 分：把复杂的问题分解为若干”简单的任务”</li>
<li>Reduce阶段: Reduce Tasks 合：reduce</li>
</ul>
</li>
<li><p>MapReduce编程执行步骤 </p>
<ul>
<li>准备MapReduce的输入数据</li>
<li>准备Mapper数据</li>
<li>Shuffle</li>
<li>Reduce处理</li>
<li>结果输出</li>
</ul>
</li>
<li><p>编程模型 </p>
</li>
</ul>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">借鉴函数式编程方式</span><br><span class="line">用户只需要实现两个函数接口：</span><br><span class="line"><span class="constructor">Map(<span class="params">in_key</span>,<span class="params">in_value</span>)</span></span><br><span class="line">---&gt;(out_key,intermediate_value) <span class="built_in">list</span></span><br><span class="line"><span class="constructor">Reduce(<span class="params">out_key</span>,<span class="params">intermediate_value</span>)</span> <span class="built_in">list</span></span><br><span class="line">---&gt;out_value <span class="built_in">list</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Word Count 词频统计案例 </li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171715.png"/> </p>
<h4 id="MapReduce实战"><a href="#MapReduce实战" class="headerlink" title="MapReduce实战"></a>MapReduce实战</h4><h5 id="MRJob编写和运行MapReduce代码"><a href="#MRJob编写和运行MapReduce代码" class="headerlink" title="MRJob编写和运行MapReduce代码"></a>MRJob编写和运行MapReduce代码</h5><p>1.<strong>mrjob 简介</strong></p>
<ul>
<li>使用python开发在Hadoop上运行的程序, mrjob是最简单的方式</li>
<li>mrjob程序可以在本地测试运行也可以部署到Hadoop集群上运行</li>
<li>如果不想成为hadoop专家, 但是需要利用Hadoop写MapReduce代码，mrJob是很好的选择</li>
</ul>
<p>2.<strong>mrjob 安装</strong></p>
<ul>
<li>使用pip安装：pip install mrjob</li>
</ul>
<p>3.<strong>mrjob实现WordCount</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRWordCount</span><span class="params">(MRJob)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#每一行从line中输入</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(self, _, line)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line.split():</span><br><span class="line">            <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># word相同的 会走到同一个reduce</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span><span class="params">(self, word, counts)</span>:</span>python</span><br><span class="line">        <span class="keyword">yield</span> word, sum(counts)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    MRWordCount.run()</span><br></pre></td></tr></table></figure>
<p>4.<strong>运行WordCount代码</strong> </p>
<p>打开命令行, 找到一篇文本文档, 敲如下命令:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python mr_word_count.py my_file.txt</span><br></pre></td></tr></table></figure>
<h5 id="运行MRJOB的不同方式"><a href="#运行MRJOB的不同方式" class="headerlink" title="运行MRJOB的不同方式"></a>运行MRJOB的不同方式</h5><p>1.<strong>内嵌(-r inline)方式</strong></p>
<ul>
<li>特点是调试方便</li>
<li>启动单一进程模拟任务执行状态和结果，默认(-r inline)可以省略</li>
<li>输出文件使用 &gt; output-file 或-o output-file</li>
<li><p>比如下面两种运行方式是等价的</p>
<ul>
<li>python word_count.py -r inline input.txt &gt; output.txt </li>
<li>python word_count.py input.txt &gt; output.txt</li>
</ul>
<p>2.<strong>本地(-r local)方式</strong> </p>
</li>
<li><p>用于本地模拟Hadoop调试</p>
</li>
<li>与内嵌(inline)方式的区别是启动了多进程执行每一个任务</li>
<li><p>如：python word_count.py -r local input.txt &gt; output1.txt</p>
<p>3.<strong>Hadoop(-r hadoop)方式</strong> </p>
</li>
<li><p>用于hadoop环境，支持Hadoop运行调度控制参数</p>
</li>
<li><p>如：指定Hadoop任务调度优先级(VERY_HIGH|HIGH)</p>
<ul>
<li>—jobconf mapreduce.job.priority=VERY_HIGH。</li>
</ul>
</li>
<li><p>如：Map及Reduce任务个数限制</p>
<ul>
<li>—jobconf mapreduce.map.tasks=2 —jobconf mapreduce.reduce.tasks=5</li>
</ul>
</li>
<li><p>python word_count.py -r hadoop hdfs:///test.txt -o hdfs:///output</p>
</li>
</ul>
<h5 id="mrjob-实现-topN统计"><a href="#mrjob-实现-topN统计" class="headerlink" title="mrjob 实现 topN统计"></a>mrjob 实现 topN统计</h5><p> 统计数据中出现次数最多的前n个数据 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob,MRStep</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopNWords</span><span class="params">(MRJob)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(self, _, line)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> line.strip() != <span class="string">""</span>:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> line.strip().split():</span><br><span class="line">                <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#介于mapper和reducer之间，用于临时的将mapper输出的数据进行统计</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combiner</span><span class="params">(self, word, counts)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> word,sum(counts)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer_sum</span><span class="params">(self, word, counts)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="literal">None</span>,(sum(counts),word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#利用heapq将数据进行排序，将最大的2个取出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top_n_reducer</span><span class="params">(self,_,word_cnts)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> cnt,word <span class="keyword">in</span> heapq.nlargest(<span class="number">2</span>,word_cnts):</span><br><span class="line">            <span class="keyword">yield</span> word,cnt</span><br><span class="line"></span><br><span class="line">    <span class="comment">#实现steps方法用于指定自定义的mapper，comnbiner和reducer方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">steps</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#传入两个step 定义了执行的顺序</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            MRStep(mapper=self.mapper,</span><br><span class="line">                   combiner=self.combiner,</span><br><span class="line">                   reducer=self.reducer_sum),</span><br><span class="line">            MRStep(reducer=self.top_n_reducer)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    TopNWords.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h4 id="MapReduce原理"><a href="#MapReduce原理" class="headerlink" title="MapReduce原理"></a>MapReduce原理</h4><h5 id="单机程序计算流程"><a href="#单机程序计算流程" class="headerlink" title="单机程序计算流程"></a>单机程序计算流程</h5><p>输入数据—-&gt;读取数据—-&gt;处理数据—-&gt;写入数据—-&gt;输出数据</p>
<h5 id="Hadoop计算流程"><a href="#Hadoop计算流程" class="headerlink" title="Hadoop计算流程"></a>Hadoop计算流程</h5><p>input data：输入数据</p>
<p>InputFormat：对数据进行切分，格式化处理</p>
<p>map：将前面切分的数据做map处理(将数据进行分类，输出(k,v)键值对数据)</p>
<p>shuffle&amp;sort:将相同的数据放在一起，并对数据进行排序处理</p>
<p>reduce：将map输出的数据进行hash计算，对每个map数据进行统计计算</p>
<p>OutputFormat：格式化输出数据</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171452.png"/></p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171230.png"/></p>
<p> <img src="YARN%E5%92%8CMAPREDUCE/mp5.png" alt="img"></p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227165931.png"/></p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171503.png"/></p>
<p> map：将数据进行处理</p>
<p>buffer in memory：达到80%数据时，将数据锁在内存上，将这部分输出到磁盘上</p>
<p>partitions：在磁盘上有很多”小的数据”，将这些数据进行归并排序。</p>
<p>merge on disk：将所有的”小的数据”进行合并。</p>
<p>reduce：不同的reduce任务，会从map中对应的任务中copy数据</p>
<p> 在reduce中同样要进行merge操作</p>
<h4 id="MapReduce架构"><a href="#MapReduce架构" class="headerlink" title="MapReduce架构"></a>MapReduce架构</h4><h5 id="MapReduce架构-1-X"><a href="#MapReduce架构-1-X" class="headerlink" title="MapReduce架构 1.X"></a>MapReduce架构 1.X</h5><ul>
<li>JobTracker:负责接收客户作业提交，负责任务到作业节点上运行，检查作业的状态</li>
<li><p>TaskTracker：由JobTracker指派任务，定期向JobTracker汇报状态，在每一个工作节点上永远只会有一个TaskTracker</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171707.png"/></p>
</li>
</ul>
<h5 id="MapReduce2-X架构"><a href="#MapReduce2-X架构" class="headerlink" title="MapReduce2.X架构"></a>MapReduce2.X架构</h5><ul>
<li>ResourceManager：负责资源的管理，负责提交任务到NodeManager所在的节点运行，检查节点的状态</li>
<li>NodeManager：由ResourceManager指派任务，定期向ResourceManager汇报状态</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227171651.png"/></p>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>资源调度框架YARN</tag>
        <tag>分布式处理框架MapReduce</tag>
        <tag>MapReduce实战</tag>
        <tag>MapReduce原理</tag>
        <tag>MapReduce架构</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式文件系统HDFS</title>
    <url>/2020/02/11/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS/</url>
    <content><![CDATA[<h4 id="HDFS概念"><a href="#HDFS概念" class="headerlink" title="HDFS概念"></a>HDFS概念</h4><p>Hadoop 附带了一个名为 HDFS(Hadoop分布式文件系统)的分布式文件系统，基于 Hadoop 的应用程序使用 HDFS 。HDFS 是专为存储超大数据文件，运行在集群的商品硬件上。它是容错的，可伸缩的，并且非常易于扩展。</p>
<a id="more"></a>
<h4 id="HDFS的使用"><a href="#HDFS的使用" class="headerlink" title="HDFS的使用"></a>HDFS的使用</h4><p><strong>启动HDFS</strong> </p>
<ul>
<li><p>来到$HADOOP_HOME/sbin目录下</p>
</li>
<li><p>执行start-dfs.sh</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以看到 namenode和 datanode启动的日志信息 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Starting namenodes on [hadoop00]</span><br><span class="line">hadoop00: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-hadoop00.out</span><br><span class="line">localhost: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-hadoop00.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-secondarynamenode-hadoop00.out</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过jps命令查看当前运行的进程 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ jps</span><br><span class="line">4416 DataNode</span><br><span class="line">4770 Jps</span><br><span class="line">4631 SecondaryNameNode</span><br><span class="line">4251 NameNode</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以看到 NameNode DataNode 以及 SecondaryNameNode 说明启动成功 </p>
</li>
</ul>
<p><strong>通过可视化界面查看HDFS的运行情况</strong> </p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155955.png"/> </p>
<h4 id="HDFS-shell操作"><a href="#HDFS-shell操作" class="headerlink" title="HDFS shell操作"></a>HDFS shell操作</h4><h5 id="HDFS-shell常见操作"><a href="#HDFS-shell常见操作" class="headerlink" title="HDFS shell常见操作"></a>HDFS shell常见操作</h5><p><strong>ls</strong></p>
<ul>
<li><p>hadoop fs -ls </p>
</li>
<li><p>如果是文件，则按照如下格式返回文件信息： 文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID </p>
</li>
<li>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下： 目录名  修改日期  修改时间  权限  用户ID 组ID </li>
<li>示例<ul>
<li>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2</li>
<li>hadoop fs -ls hdfs://host:port/user/hadoop/dir1 /nonexistentfile </li>
<li>返回值： 成功返回0，失败返回-1</li>
</ul>
</li>
</ul>
<h5 id="text"><a href="#text" class="headerlink" title="text"></a><strong>text</strong></h5><ul>
<li>使用方法：hadoop fs -text</li>
<li>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream</li>
</ul>
<p><strong>mv</strong></p>
<ul>
<li>使用方法：hadoop fs -mv URI [URI …]</li>
<li>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。 示例：<ul>
<li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li>
<li>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</li>
<li>返回值：成功返回0，失败返回-1</li>
</ul>
</li>
</ul>
<p><strong>put</strong></p>
<ul>
<li>使用方法：hadoop fs -put …</li>
<li>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。<ul>
<li>hadoop fs -put localfile /user/hadoop/hadoopfile</li>
<li>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</li>
<li>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</li>
<li>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile 从标准输入中读取输入。</li>
<li>返回值：成功返回0，失败返回-1</li>
</ul>
</li>
</ul>
<p>参考网址： <a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</a> </p>
<h5 id="HDFS-shell操作练习"><a href="#HDFS-shell操作练习" class="headerlink" title="HDFS shell操作练习"></a>HDFS shell操作练习</h5><ul>
<li>在centos 中创建 test.txt</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">touch test.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>在centos中为test.txt 添加文本内容 </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi test.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>在HDFS中创建 hadoop001/test 文件夹 </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir -p /hadoop001/test</span><br></pre></td></tr></table></figure>
<ul>
<li>把text.txt文件上传到HDFS中 </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -put test.txt /hadoop001/test/</span><br></pre></td></tr></table></figure>
<ul>
<li>查看hdfs中 hadoop001/test/test.txt 文件内容 </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -cat /hadoop001/test/test.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>将hdfs中 hadoop001/test/test.txt文件下载到centos </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -get /hadoop001/test/test.txt test.txt</span><br></pre></td></tr></table></figure>
<ul>
<li>删除HDFS中 hadoop001/test/ </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -rm -r /hadoop001</span><br></pre></td></tr></table></figure>
<h4 id="HDFS设计思路"><a href="#HDFS设计思路" class="headerlink" title="HDFS设计思路"></a>HDFS设计思路</h4><ul>
<li><p>分布式文件系统的设计思路：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155952.png"/></p>
</li>
<li><p>HDFS的设计目标 </p>
<ul>
<li>适合运行在通用硬件(commodity hardware)上的分布式文件系统</li>
<li>高度容错性的系统，适合部署在廉价的机器上</li>
<li>HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用</li>
<li>容易扩展，为用户提供性能不错的文件存储服务</li>
</ul>
</li>
</ul>
<h4 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h4><ul>
<li>1个NameNode/NN(Master) 带 DataNode/DN(Slaves) (Master-Slave结构)</li>
<li>1个文件会被拆分成多个Block</li>
<li>NameNode(NN)<ul>
<li>负责客户端请求的响应</li>
<li>负责元数据（文件的名称、副本系数、Block存放的DN）的管理<ul>
<li>元数据 MetaData 描述数据的数据</li>
</ul>
</li>
<li>监控DataNode健康状况 10分钟没有收到DataNode报告认为Datanode死掉了</li>
</ul>
</li>
<li>DataNode(DN)<ul>
<li>存储用户的文件对应的数据块(Block)</li>
<li>要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况</li>
</ul>
</li>
<li><p>分布式集群NameNode和DataNode部署在不同机器上</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227160002.jpg"/> </p>
</li>
</ul>
<h4 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h4><ul>
<li>优点<ul>
<li>数据冗余 硬件容错</li>
<li>适合存储大文件</li>
<li>处理流式数据</li>
<li>可构建在廉价机器上</li>
</ul>
</li>
<li>缺点<ul>
<li>低延迟的数据访问</li>
<li>小文件存储</li>
</ul>
</li>
</ul>
<h4 id="HDFS环境搭建"><a href="#HDFS环境搭建" class="headerlink" title="HDFS环境搭建"></a>HDFS环境搭建</h4><ul>
<li><p>下载jdk 和 hadoop 放到 ~/software目录下 然后解压到 ~/app目录下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf 压缩包名字 -C ~/app/</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export JAVA_HOME=/root/bigdata/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export HADOOP_HOME=/root/bigdata/hadoop</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">保存退出后</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入到解压后的hadoop目录 修改配置文件</p>
<ul>
<li>配置文件作用<ul>
<li>core-site.xml 指定hdfs的访问方式</li>
<li>hdfs-site.xml 指定namenode 和 datanode 的数据存储位置</li>
<li>mapred-site.xml 配置mapreduce</li>
<li>yarn-site.xml 配置yarn</li>
</ul>
</li>
<li>修改hadoop-env.sh</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd etc/hadoop</span><br><span class="line">vi hadoop-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">找到下面内容添加java home</span></span><br><span class="line">export_JAVA_HOME=/root/bigdata/jdk</span><br></pre></td></tr></table></figure>
<ul>
<li>修改 core-site.xml 在 节点中添加</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/root/bigdata/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop-master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>修改hdfs-site.xml 在 configuration节点中添加</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/bigdata/hadoop/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/bigdata/hadoop/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>修改 mapred-site.xml</li>
<li>默认没有这个 从模板文件复制</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure>
<p> 在mapred-site.xml 的configuration 节点中添加</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>修改yarn-site.xml configuration 节点中添加</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>来到hadoop的bin目录格式化namenode</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./hadoop namenode -format (这个命令只运行一次)</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动hdfs 进入到 sbin</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动启动yarn 在sbin中</p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>HDFS</tag>
        <tag>HDFS概念</tag>
        <tag>HDFS shell操作</tag>
        <tag>HDFS架构</tag>
        <tag>HDFS环境搭建</tag>
        <tag>HDFS优缺点</tag>
      </tags>
  </entry>
  <entry>
    <title>HADOOP概述</title>
    <url>/2020/02/11/HADOOP%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h4 id="Hadoop的概念"><a href="#Hadoop的概念" class="headerlink" title="Hadoop的概念"></a>Hadoop的概念</h4><ul>
<li>Apache™ Hadoop® 是一个开源的，<strong>可靠的</strong>(reliable)，<strong>可扩展</strong>的(scalable)<strong>分布式计算框架</strong> <ul>
<li>允许使用简单的编程模型跨计算机集群分布式处理大型数据集 </li>
<li><strong>可扩展</strong>: 从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储</li>
<li><strong>可靠的</strong>: 不依靠硬件来提供高可用性(high-availability)，而是在应用层检测和处理故障，从而在计算机集群之上提供高可用服务</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h4 id="Hadoop能做什么"><a href="#Hadoop能做什么" class="headerlink" title="Hadoop能做什么?"></a>Hadoop能做什么?</h4><ul>
<li><p>搭建大型数据仓库</p>
</li>
<li><p>PB级数据的存储 处理 分析 统计等业务</p>
<ul>
<li><p>搜索引擎</p>
</li>
<li><p>日志分析</p>
</li>
<li><p>数据挖掘</p>
</li>
<li><p>商业智能(Business Intelligence，简称：BI)</p>
<blockquote>
<p>商业智能通常被理解为将企业中现有的数据(订单、库存、交易账目、客户和供应商等数据)转化为知识，帮助企业做出明智的业务经营决策的工具。从技术层面上讲，是数据仓库、数据挖掘等技术的综合运用。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h4 id="Hadoop核心组件"><a href="#Hadoop核心组件" class="headerlink" title="Hadoop核心组件"></a>Hadoop核心组件</h4><ul>
<li><p>Hadoop是所有搜索引擎的共性问题的廉价解决方案 </p>
<ul>
<li>如何存储持续增长的海量网页: 单节点 V.S. 分布式存储</li>
<li>如何对持续增长的海量网页进行排序: 超算 V.S. 分布式计算</li>
<li>HDFS 解决分布式存储问题</li>
<li>MapReduce 解决分布式计算问题</li>
</ul>
</li>
<li><p>Hadoop Common：协调其他组件的通用工具</p>
</li>
<li><p>HDFS：一个基于网络的分布式文件存储系统</p>
<ul>
<li>Hadoop Distributed File System (HDFS™) </li>
<li>HDFS的特点:扩展性&amp;容错性&amp;海量数量存储</li>
<li>将文件切分成指定大小的数据块, 并在多台机器上保存多个副本</li>
<li>数据切分、多副本、容错等操作对用户是透明的</li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">下面这张图是数据块多份复制存储的示意</span><br><span class="line">图中对于文件 /users/sameerp/data/part<span class="number">-0</span>，其复制备份数设置为<span class="number">2</span>, 存储的BlockID分别为<span class="number">1</span>、<span class="number">3</span>。</span><br><span class="line">Block1的两个备份存储在DataNode0和DataNode2两个服务器上</span><br><span class="line">Block3的两个备份存储在DataNode4和DataNode6两个服务器上</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155845.png"/> </p>
</li>
<li><p>Hadoop MapReduce ： 基于yarn的大数据集并行处理系统 </p>
<ul>
<li>分布式计算框架</li>
<li>MapReduce是GoogleMapReduce的开源实现</li>
<li>MapReduce特点:扩展性&amp;容错性&amp;海量数据离线处理</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155815.png"/> </p>
</li>
<li><p>YARN： 作业调度和集群资源管理的框架 </p>
<ul>
<li>YARN: Yet Another Resource Negotiator</li>
<li>负责整个集群资源的管理和调度</li>
<li>YARN特点:扩展性&amp;容错性&amp;多框架资源统一调度</li>
</ul>
</li>
</ul>
<h4 id="Hadoop优势"><a href="#Hadoop优势" class="headerlink" title="Hadoop优势"></a>Hadoop优势</h4><ul>
<li>高可靠<ul>
<li>数据存储: 数据块多副本</li>
<li>数据计算: 某个节点崩溃, 会自动重新调度作业计算</li>
</ul>
</li>
<li>高扩展性<ul>
<li>存储/计算资源不够时，可以横向的线性扩展机器</li>
<li>一个集群中可以包含数以千计的节点</li>
<li>集群可以使用廉价机器，成本低</li>
</ul>
</li>
<li>Hadoop生态系统成熟</li>
</ul>
<h4 id="拓展-数据仓库"><a href="#拓展-数据仓库" class="headerlink" title="拓展-数据仓库"></a>拓展-数据仓库</h4><h5 id="数据库两大基本类型"><a href="#数据库两大基本类型" class="headerlink" title="数据库两大基本类型"></a>数据库两大基本类型</h5><blockquote>
<p> <strong>操作型数据库</strong> ： 主要用于业务支撑。一个公司往往会使用并维护若干个数据库，这些数据库保存着公司的日常操作数据，比如商品购买、酒店预订、学生成绩录入等； </p>
<p> <strong>分析型数据库</strong> ： 主要用于历史数据分析。这类数据库作为公司的单独数据存储，负责利用历史数据对公司各主题域进行统计分析； </p>
</blockquote>
<h5 id="数据仓库定义"><a href="#数据仓库定义" class="headerlink" title="数据仓库定义"></a>数据仓库定义</h5><p>数据仓库是决策支持系统和联机分析应用数据源的结构化数据环境。数据仓库研究和解决从数据库中获取信息的问题。数据仓库的特征在于面向主题、集成性、稳定性和时变性 </p>
<h5 id="数据仓库特点"><a href="#数据仓库特点" class="headerlink" title="数据仓库特点"></a>数据仓库特点</h5><ol>
<li><strong>面向主题</strong></li>
</ol>
<p>​    面向主题特性是数据仓库和操作型数据库的根本区别。操作型数据库是为了支撑各种业务而建立，而分析型数据库则是为了对从各种繁杂业务中抽象出来的分析主题(如用户、成本、商品等)进行分析而建立；</p>
<ol>
<li><strong>集成性</strong></li>
</ol>
<p>​    集成性是指数据仓库会将不同源数据库中的数据汇总到一起；</p>
<ol>
<li><strong>企业范围</strong></li>
</ol>
<p>​    数据仓库内的数据是面向公司全局的。比如某个主题域为成本，则全公司和成本有关的信息都会被汇集进来；</p>
<ol>
<li><strong>历史性</strong></li>
</ol>
<p>​    较之操作型数据库，数据仓库的时间跨度通常比较长。前者通常保存几个月，后者可能几年甚至几十年；</p>
<ol>
<li><strong>时变性</strong></li>
</ol>
<p>​    时变性是指数据仓库包含来自其时间范围不同时间段的数据快照。有了这些数据快照以后，用户便可将其汇总，生成各历史阶段的数据分析报告；</p>
<h5 id="数据仓库组件"><a href="#数据仓库组件" class="headerlink" title="数据仓库组件"></a>数据仓库组件</h5><p> 数据仓库的核心组件有四个：各源数据库，ETL，数据仓库，前端应用。如下图所示： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155904.jpg"/> </p>
<ol>
<li><p><strong>业务系统</strong></p>
<p> 业务系统包含各种源数据库，这些源数据库既为业务系统提供数据支撑，同时也作为数据仓库的数据源(注：除了业务系统，数据仓库也可从其他外部数据源获取数据)； </p>
</li>
<li><p><strong>ETL</strong></p>
<p> ETL分别代表：提取extraction、转换transformation、加载load。其中提取过程表示操作型数据库搜集指定数据，转换过程表示将数据转化为指定格式并进行数据清洗保证数据质量，加载过程表示将转换过后满足指定格式的数据加载进数据仓库。数据仓库会周期不断地从源数据库提取清洗好了的数据，因此也被称为”目标系统”； </p>
</li>
<li><p><strong>前端应用</strong></p>
<p>  和操作型数据库一样，数据仓库通常提供具有直接访问数据仓库功能的前端应用，这些应用也被称为BI(商务智能)应用； </p>
</li>
</ol>
<h5 id="数据仓库开发流程"><a href="#数据仓库开发流程" class="headerlink" title="数据仓库开发流程"></a>数据仓库开发流程</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155858.jpg"/> </p>
<p> 最后：在大数据时代，数据仓库的重要性更胜以往。Hadoop平台下的Hive，Spark平台下的Spark SQL都是各自生态圈内应用最热门的配套工具，而它们的本质就是开源分布式数据仓库。</p>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>Hadoop的概念</tag>
        <tag>Hadoop核心组件</tag>
        <tag>Hadoop优势</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>基于模型的协同过滤推荐</title>
    <url>/2020/02/11/%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h4 id="Model-Based-协同过滤算法"><a href="#Model-Based-协同过滤算法" class="headerlink" title="Model-Based 协同过滤算法"></a>Model-Based 协同过滤算法</h4><p>随着机器学习技术的逐渐发展与完善，推荐系统也逐渐运用机器学习的思想来进行推荐。将机器学习应用到推荐系统中的方案真是不胜枚举。以下对Model-Based CF算法做一个大致的分类：</p>
<ul>
<li>基于分类算法、回归算法、聚类算法</li>
<li>基于矩阵分解的推荐</li>
<li>基于神经网络算法</li>
<li>基于图模型算法</li>
</ul>
<p>几种应用较多的方案：</p>
<ul>
<li><strong>基于回归模型的协同过滤推荐</strong></li>
<li><strong>基于矩阵分解的协同过滤推荐</strong></li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>基于模型的推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统的冷启动问题</title>
    <url>/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h4 id="推荐系统冷启动概念"><a href="#推荐系统冷启动概念" class="headerlink" title="推荐系统冷启动概念"></a>推荐系统冷启动概念</h4><ul>
<li>⽤户冷启动：如何为新⽤户做个性化推荐</li>
<li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li>
<li>系统冷启动：⽤户冷启动+物品冷启动</li>
<li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li>
</ul>
<a id="more"></a>
<h4 id="处理推荐系统冷启动问题的常用方法"><a href="#处理推荐系统冷启动问题的常用方法" class="headerlink" title="处理推荐系统冷启动问题的常用方法"></a>处理推荐系统冷启动问题的常用方法</h4><h5 id="用户冷启动"><a href="#用户冷启动" class="headerlink" title="用户冷启动"></a>用户冷启动</h5><ul>
<li><p>收集⽤户特征</p>
<ul>
<li>⽤户注册信息：性别、年龄、地域</li>
<li>设备信息：定位、⼿机型号、app列表</li>
<li>社交信息、推⼴素材、安装来源</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155703.png"/></p>
</li>
<li><p>引导用户填写兴趣 </p>
</li>
<li>使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</li>
<li>新老用户推荐策略的差异<ul>
<li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li>
<li>Explore Exploit⼒度</li>
<li>使⽤单独的特征和模型预估</li>
</ul>
</li>
</ul>
<h5 id="物品冷启动"><a href="#物品冷启动" class="headerlink" title="物品冷启动"></a>物品冷启动</h5><ul>
<li>给物品打标签</li>
<li><p>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155708.png"/> </p>
</li>
</ul>
<h5 id="系统冷启动"><a href="#系统冷启动" class="headerlink" title="系统冷启动"></a>系统冷启动</h5><ul>
<li>基于内容的推荐 系统早期</li>
<li>基于内容的推荐逐渐过渡到协同过滤</li>
<li>基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果</li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统冷启动</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统评估</title>
    <url>/2020/02/10/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>了解推荐系统的常用评估指标</li>
<li>了解推荐系统的评估方法</li>
</ul>
<a id="more"></a>
<h4 id="推荐系统的评估指标"><a href="#推荐系统的评估指标" class="headerlink" title="推荐系统的评估指标"></a>推荐系统的评估指标</h4><ul>
<li><p>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155643.png"/> </p>
</li>
<li><p>评估数据来源显示反馈和隐式反馈 </p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>显式反馈</th>
<th>隐式反馈</th>
</tr>
</thead>
<tbody>
<tr>
<td>例子</td>
<td>电影/书籍评分 是否喜欢这个推荐</td>
<td>播放/点击 评论 下载 购买</td>
</tr>
<tr>
<td>准确性</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>数量</td>
<td>少</td>
<td>多</td>
</tr>
<tr>
<td>获取成本</td>
<td>高</td>
<td>低</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>常用评估指标 </p>
<blockquote>
<p>• 准确性 • 信任度 • 满意度 • 实时性 • 覆盖率 • 鲁棒性<br>• 多样性 • 可扩展性 • 新颖性 • 商业⽬标 • 惊喜度 • ⽤户留存 </p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">- </span>准确性 (理论角度) Netflix 美国录像带租赁</span><br><span class="line"><span class="bullet">  - </span>评分预测</span><br><span class="line"><span class="bullet">    - </span>RMSE MAE</span><br><span class="line"><span class="bullet">  - </span>topN推荐</span><br><span class="line"><span class="bullet">    - </span>召回率 精准率</span><br><span class="line"><span class="bullet">- </span>准确性 (业务角度)</span><br><span class="line"><span class="bullet">- </span>覆盖度</span><br><span class="line"><span class="bullet">  - </span>信息熵 对于推荐越大越好</span><br><span class="line"><span class="bullet">  - </span>覆盖率</span><br><span class="line"><span class="bullet">- </span>多样性&amp;新颖性&amp;惊喜性</span><br><span class="line"><span class="bullet">  - </span>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</span><br><span class="line"><span class="bullet">  - </span>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</span><br><span class="line"><span class="bullet">  - </span>惊喜性：历史不相似（惊）但很满意（喜）</span><br><span class="line"><span class="bullet">  - </span>往往需要牺牲准确性</span><br><span class="line"><span class="bullet">  - </span>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</span><br><span class="line"><span class="bullet">  - </span>系统过度强调实时性</span><br><span class="line"><span class="bullet">- </span>Exploitation &amp; Exploration 探索与利用问题</span><br><span class="line"><span class="bullet">  - </span>Exploitation(开发 利用)：选择现在可能最佳的⽅案</span><br><span class="line"><span class="bullet">  - </span>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</span><br><span class="line"><span class="bullet">  - </span>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化 长期的⽬标</span><br><span class="line"><span class="bullet">- </span>EE问题实践</span><br><span class="line"><span class="bullet">  - </span>兴趣扩展: 相似话题, 搭配推荐</span><br><span class="line"><span class="bullet">  - </span>人群算法: userCF 用户聚类</span><br><span class="line"><span class="bullet">  - </span>平衡个性化推荐和热门推荐比例</span><br><span class="line"><span class="bullet">  - </span>随机丢弃用户行为历史</span><br><span class="line"><span class="bullet">  - </span>随机扰动模型参数</span><br><span class="line"><span class="bullet">- </span>EE可能带来的问题</span><br><span class="line"><span class="bullet">  - </span>探索伤害用户体验, 可能导致用户流失</span><br><span class="line"><span class="bullet">  - </span>探索带来的长期收益(留存率)评估周期长, KPI压力大</span><br><span class="line"><span class="bullet">  - </span>如何平衡实时兴趣和长期兴趣</span><br><span class="line"><span class="bullet">  - </span>如何平衡短期产品体验和长期系统生态</span><br><span class="line"><span class="bullet">  - </span>如何平衡大众口味和小众需求</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="推荐系统评估方法"><a href="#推荐系统评估方法" class="headerlink" title="推荐系统评估方法"></a>推荐系统评估方法</h4><p>评估方法</p>
<ul>
<li>问卷调查: 成本高</li>
<li>离线评估:<ul>
<li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li>
<li>只能评估少数指标</li>
<li>速度快, 不损害用户体验</li>
</ul>
</li>
<li>在线评估: 灰度发布 &amp; A/B测试 50% 全量上线</li>
<li>实践: 离线评估和在线评估结合，定期做问卷调查</li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统的评估指标</tag>
        <tag>推荐系统评估方法</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-基于协同过滤的电影推荐</title>
    <url>/2020/02/09/%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<h4 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h4><ul>
<li>应用基于用户的协同过滤实现电影评分预测</li>
<li>应用基于物品的协同过滤实现电影评分预测</li>
</ul>
<a id="more"></a>
<h4 id="User-Based-CF-预测电影评分"><a href="#User-Based-CF-预测电影评分" class="headerlink" title="User-Based CF 预测电影评分"></a>User-Based CF 预测电影评分</h4><ul>
<li><p>据集下载</p>
<ul>
<li>下载地址：<a href="https://grouplens.org/datasets/movielens/latest/" target="_blank" rel="noopener">MovieLens Latest Datasets Small</a></li>
<li>建议下载<a href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" target="_blank" rel="noopener">ml-latest-small.zip</a>，数据量小，便于我们单机使用和运行</li>
</ul>
</li>
<li><p>加载ratings.csv，转换为用户-电影评分矩阵并计算用户之间相似度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">DATA_PATH = <span class="string">"./datasets/ml-latest-small/ratings.csv"</span></span><br><span class="line"></span><br><span class="line">dtype = &#123;<span class="string">"userId"</span>: np.int32, <span class="string">"movieId"</span>: np.int32, <span class="string">"rating"</span>: np.float32&#125;</span><br><span class="line"><span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵</span></span><br><span class="line">ratings_matrix = ratings.pivot_table(index=[<span class="string">"userId"</span>], columns=[<span class="string">"movieId"</span>],values=<span class="string">"rating"</span>)</span><br><span class="line"><span class="comment">#计算用户之间相似度</span></span><br><span class="line">user_similar = ratings_matrix.T.corr()</span><br></pre></td></tr></table></figure>
</li>
<li><p>预测用户对物品的评分 （以用户1对电影1评分为例） </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155449.png"/></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">similar_users = user_similar[<span class="number">1</span>].drop([<span class="number">1</span>]).dropna()</span><br><span class="line"><span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line"><span class="comment"># 2. 从用户1的近邻相似用户中筛选出对物品1有评分记录的近邻用户</span></span><br><span class="line">ids = set(ratings_matrix[<span class="number">1</span>].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">finally_similar_users = similar_users.ix[list(<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line"><span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">    <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">    sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">    <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">    sim_user_rating_for_item = sim_user_rated_movies[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算分子的值</span></span><br><span class="line">    numerator += similarity * sim_user_rating_for_item</span><br><span class="line">    <span class="comment"># 计算分母的值</span></span><br><span class="line">    denominator += similarity</span><br><span class="line"><span class="comment"># 4 计算预测的评分值</span></span><br><span class="line">predict_rating = numerator/denominator</span><br><span class="line">print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (<span class="number">1</span>, <span class="number">1</span>, predict_rating))</span><br></pre></td></tr></table></figure>
</li>
<li><p>封装成方法 预测任意用户对任意电影的评分 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(uid, iid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测给定用户对给定物品的评分值</span></span><br><span class="line"><span class="string">    :param uid: 用户ID</span></span><br><span class="line"><span class="string">    :param iid: 物品ID</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两相似度矩阵</span></span><br><span class="line"><span class="string">    :return: 预测的评分值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    print(<span class="string">"开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."</span>%(uid, iid))</span><br><span class="line">    <span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">    similar_users = user_similar[uid].drop([uid]).dropna()</span><br><span class="line">    <span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">    similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line">    <span class="keyword">if</span> similar_users.empty <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"用户&lt;%d&gt;没有相似的用户"</span> % uid)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户</span></span><br><span class="line">    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">    finally_similar_users = similar_users.ix[list(ids)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">    numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">    denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">    <span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">        <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">        <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">        sim_user_rating_for_item = sim_user_rated_movies[iid]</span><br><span class="line">        <span class="comment"># 计算分子的值</span></span><br><span class="line">        numerator += similarity * sim_user_rating_for_item</span><br><span class="line">        <span class="comment"># 计算分母的值</span></span><br><span class="line">        denominator += similarity</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">    predict_rating = numerator/denominator</span><br><span class="line">    print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br><span class="line">    <span class="keyword">return</span> round(predict_rating, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>为某一用户预测所有电影评分 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(uid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测全部评分</span></span><br><span class="line"><span class="string">    :param uid: 用户id</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品打分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两间的相似度</span></span><br><span class="line"><span class="string">    :return: 生成器，逐个返回预测评分</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 准备要预测的物品的id列表</span></span><br><span class="line">    item_ids = ratings_matrix.columns</span><br><span class="line">    <span class="comment"># 逐个预测</span></span><br><span class="line">    <span class="keyword">for</span> iid <span class="keyword">in</span> item_ids:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rating = predict(uid, iid, ratings_matrix, user_similar)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> uid, iid, rating</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predict_all(<span class="number">1</span>, ratings_matrix, user_similar):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>根据评分为指定用户推荐topN个电影 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k_rs_result</span><span class="params">(k)</span>:</span></span><br><span class="line">    results = predict_all(<span class="number">1</span>, ratings_matrix, user_similar)</span><br><span class="line">    <span class="keyword">return</span> sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="literal">True</span>)[:k]</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    result = top_k_rs_result(<span class="number">20</span>)</span><br><span class="line">    pprint(result)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Item-Based-CF-预测电影评分"><a href="#Item-Based-CF-预测电影评分" class="headerlink" title="Item-Based CF 预测电影评分"></a>Item-Based CF 预测电影评分</h4><ul>
<li><p>加载ratings.csv，转换为用户-电影评分矩阵并计算用户之间相似度 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">DATA_PATH = <span class="string">"./datasets/ml-latest-small/ratings.csv"</span></span><br><span class="line"></span><br><span class="line">dtype = &#123;<span class="string">"userId"</span>: np.int32, <span class="string">"movieId"</span>: np.int32, <span class="string">"rating"</span>: np.float32&#125;</span><br><span class="line"><span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"><span class="comment"># 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵</span></span><br><span class="line">ratings_matrix = ratings.pivot_table(index=[<span class="string">"userId"</span>], columns=[<span class="string">"movieId"</span>],values=<span class="string">"rating"</span>)</span><br><span class="line"><span class="comment">#计算用户之间相似度</span></span><br><span class="line">item_similar = ratings_matrix.corr()</span><br></pre></td></tr></table></figure>
</li>
<li><p>预测用户对物品的评分 （以用户1对电影1评分为例） </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155455.png"/></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 找出iid物品的相似物品</span></span><br><span class="line">  similar_items = item_similar[<span class="number">1</span>].drop([<span class="number">1</span>]).dropna()</span><br><span class="line">  <span class="comment"># 相似物品筛选规则：正相关的物品</span></span><br><span class="line">  similar_items = similar_items.where(similar_items&gt;<span class="number">0</span>).dropna()</span><br><span class="line">  <span class="comment"># 2. 从iid物品的近邻相似物品中筛选出uid用户评分过的物品</span></span><br><span class="line">  ids = set(ratings_matrix.ix[<span class="number">1</span>].dropna().index)&amp;set(similar_items.index)</span><br><span class="line">  finally_similar_items = similar_items.ix[list(ids)]</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3. 结合iid物品与其相似物品的相似度和uid用户对其相似物品的评分，预测uid对iid的评分</span></span><br><span class="line">  numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">  denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">  <span class="keyword">for</span> sim_iid, similarity <span class="keyword">in</span> finally_similar_items.iteritems():</span><br><span class="line">      <span class="comment"># 近邻物品的评分数据</span></span><br><span class="line">      sim_item_rated_movies = ratings_matrix[sim_iid].dropna()</span><br><span class="line">      <span class="comment"># 1用户对相似物品物品的评分</span></span><br><span class="line">      sim_item_rating_from_user = sim_item_rated_movies[<span class="number">1</span>]</span><br><span class="line">      <span class="comment"># 计算分子的值</span></span><br><span class="line">      numerator += similarity * sim_item_rating_from_user</span><br><span class="line">      <span class="comment"># 计算分母的值</span></span><br><span class="line">      denominator += similarity</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">  predict_rating = sum_up/sum_down</span><br><span class="line">  print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br></pre></td></tr></table></figure>
</li>
<li><p>封装成方法 预测任意用户对任意电影的评分 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(uid, iid, ratings_matrix, user_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测给定用户对给定物品的评分值</span></span><br><span class="line"><span class="string">    :param uid: 用户ID</span></span><br><span class="line"><span class="string">    :param iid: 物品ID</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    :param user_similar: 用户两两相似度矩阵</span></span><br><span class="line"><span class="string">    :return: 预测的评分值</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    print(<span class="string">"开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."</span>%(uid, iid))</span><br><span class="line">    <span class="comment"># 1. 找出uid用户的相似用户</span></span><br><span class="line">    similar_users = user_similar[uid].drop([uid]).dropna()</span><br><span class="line">    <span class="comment"># 相似用户筛选规则：正相关的用户</span></span><br><span class="line">    similar_users = similar_users.where(similar_users&gt;<span class="number">0</span>).dropna()</span><br><span class="line">    <span class="keyword">if</span> similar_users.empty <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">"用户&lt;%d&gt;没有相似的用户"</span> % uid)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户</span></span><br><span class="line">    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)</span><br><span class="line">    finally_similar_users = similar_users.ix[list(ids)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分</span></span><br><span class="line">    numerator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分子部分的值</span></span><br><span class="line">    denominator = <span class="number">0</span>    <span class="comment"># 评分预测公式的分母部分的值</span></span><br><span class="line">    <span class="keyword">for</span> sim_uid, similarity <span class="keyword">in</span> finally_similar_users.iteritems():</span><br><span class="line">        <span class="comment"># 近邻用户的评分数据</span></span><br><span class="line">        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()</span><br><span class="line">        <span class="comment"># 近邻用户对iid物品的评分</span></span><br><span class="line">        sim_user_rating_for_item = sim_user_rated_movies[iid]</span><br><span class="line">        <span class="comment"># 计算分子的值</span></span><br><span class="line">        numerator += similarity * sim_user_rating_for_item</span><br><span class="line">        <span class="comment"># 计算分母的值</span></span><br><span class="line">        denominator += similarity</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测的评分值并返回</span></span><br><span class="line">    predict_rating = numerator/denominator</span><br><span class="line">    print(<span class="string">"预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f"</span> % (uid, iid, predict_rating))</span><br><span class="line">    <span class="keyword">return</span> round(predict_rating, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>为某一用户预测所有电影评分 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_all</span><span class="params">(uid, ratings_matrix, item_similar)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    预测全部评分</span></span><br><span class="line"><span class="string">    :param uid: 用户id</span></span><br><span class="line"><span class="string">    :param ratings_matrix: 用户-物品打分矩阵</span></span><br><span class="line"><span class="string">    :param item_similar: 物品两两间的相似度</span></span><br><span class="line"><span class="string">    :return: 生成器，逐个返回预测评分</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 准备要预测的物品的id列表</span></span><br><span class="line">    item_ids = ratings_matrix.columns</span><br><span class="line">    <span class="comment"># 逐个预测</span></span><br><span class="line">    <span class="keyword">for</span> iid <span class="keyword">in</span> item_ids:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rating = predict(uid, iid, ratings_matrix, item_similar)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> uid, iid, rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> predict_all(<span class="number">1</span>, ratings_matrix, item_similar):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>根据评分为指定用户推荐topN个电影 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k_rs_result</span><span class="params">(k)</span>:</span></span><br><span class="line">    results = predict_all(<span class="number">1</span>, ratings_matrix, item_similar)</span><br><span class="line">    <span class="keyword">return</span> sorted(results, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="literal">True</span>)[:k]</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    result = top_k_rs_result(<span class="number">20</span>)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>基于用户的协同过滤</tag>
        <tag>基于物品的协同过滤</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程-特征降维</title>
    <url>/2020/02/03/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<h4 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h4><ul>
<li>了解降维的定义</li>
<li>知道通过低方差过滤实现降维过程</li>
<li>知道相关系数实现降维的过程</li>
<li>知道主成分分析法实现过程</li>
</ul>
<a id="more"></a>
<h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><p> <strong>降维</strong>是指在某些限定条件下，<strong>降低随机变量(特征)个数</strong>，得到<strong>一组“不相关”主变量</strong>的过程 </p>
<ul>
<li><p>降低随机变量的个数 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154011.png"/></p>
</li>
<li><p>相关特征(correlated feature)</p>
<ul>
<li>相对湿度与降雨量之间的相关</li>
<li>等等</li>
</ul>
</li>
</ul>
<blockquote>
<p>正是因为在进行训练的时候，我们都是使用特征进行学习。如果特征本身存在问题或者特征之间相关性较强，对于算法学习预测会影响较大 </p>
</blockquote>
<h5 id="降维的两种方式"><a href="#降维的两种方式" class="headerlink" title="降维的两种方式"></a>降维的两种方式</h5><ul>
<li>特征选择</li>
<li>主成分分析（可以理解一种特征提取的方式）</li>
</ul>
<h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><h5 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h5><p> 数据中包含<strong>冗余或无关变量（或称特征、属性、指标等）</strong>，旨在从<strong>原有特征中找出主要特征</strong>。 </p>
<h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ul>
<li>Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联<ul>
<li><strong>方差选择法：低方差特征过滤</strong></li>
<li><strong>相关系数</strong></li>
</ul>
</li>
<li>Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）<ul>
<li><strong>决策树:信息熵、信息增益</strong></li>
<li><strong>正则化：L1、L2</strong></li>
<li><strong>深度学习：卷积等</strong></li>
</ul>
</li>
</ul>
<h5 id="低方差特征过滤"><a href="#低方差特征过滤" class="headerlink" title="低方差特征过滤"></a>低方差特征过滤</h5><p>1.<strong>定义</strong></p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line">删除低方差的一些特征，前面讲过方差的意义。再结合方差的大小来考虑这个方式的角度。</span><br><span class="line"><span class="bullet">- </span>特征方差小：某个特征大多样本的值比较相近</span><br><span class="line"><span class="bullet">- </span>特征方差大：某个特征很多样本的值都有差别</span><br></pre></td></tr></table></figure>
<p>2.<strong>API</strong></p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.feature_selection.<span class="constructor">VarianceThreshold(<span class="params">threshold</span> = 0.0)</span></span><br><span class="line">	删除所有低方差特征</span><br><span class="line">	<span class="module-access"><span class="module"><span class="identifier">Variance</span>.</span></span>fit<span class="constructor">_transform(X)</span></span><br><span class="line">		X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">		返回值：训练集差异低于threshold的特征将被删除。默认值是保留所有非零方差特征，即删除所有样本中具有相同值的特征。</span><br></pre></td></tr></table></figure>
<p>3.<strong>案例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">“”“</span><br><span class="line">我们对某些股票的指标特征之间进行一个筛选，除去<span class="string">'index,'</span>date<span class="string">','</span><span class="keyword">return</span><span class="string">'列不考虑（这些类型不匹配，也不是所需要指标）</span></span><br><span class="line"><span class="string">”“”</span></span><br><span class="line"><span class="string">import pandas as pd</span></span><br><span class="line"><span class="string">from sklearn.feature_selection import VarianceThreshold</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">def var_thr():</span></span><br><span class="line"><span class="string">    """低方差过滤"""</span></span><br><span class="line"><span class="string">    data = pd.read_csv("./data/factor_returns.csv")</span></span><br><span class="line"><span class="string">    # print(data)</span></span><br><span class="line"><span class="string">    print(data.shape)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # 实例化一个对象</span></span><br><span class="line"><span class="string">    tranfer = VarianceThreshold(threshold=1)</span></span><br><span class="line"><span class="string">    # 转换</span></span><br><span class="line"><span class="string">    tranfer_data = tranfer.fit_transform(data.iloc[:, 1:10])</span></span><br><span class="line"><span class="string">    # print(tranfer_data)</span></span><br><span class="line"><span class="string">    print(tranfer_data.shape)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">if __name__ == '</span>__main__<span class="string">':</span></span><br><span class="line"><span class="string">    var_thr()</span></span><br></pre></td></tr></table></figure>
<p>4.<strong>相关系数</strong></p>
<p>主要实现方式：</p>
<ul>
<li>皮尔逊相关系数</li>
<li>斯皮尔曼相关系数</li>
</ul>
<p>1.<strong>皮尔逊相关系数</strong>(Pearson Correlation Coefficient)</p>
<p><strong>作用</strong>： 反映变量之间相关关系密切程度的统计指标 </p>
<p><strong>公式</strong>： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154029.png"/> </p>
<p> <strong>举例</strong>:</p>
<p>  比如说我们计算年广告费投入与月均销售额 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154004.png"/></p>
<p> 那么之间的相关系数怎么计算</p>
<p> <img src="%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B01.png" alt="img"> </p>
<p> 最终计算： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154000.png"/> </p>
<p>= 0.9942</p>
<p><strong>所以我们最终得出结论是广告投入费与月平均销售额之间有高度的正相关关系。</strong></p>
<p><strong>特点</strong>：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">相关系数的值介于–<span class="number">1</span>与+<span class="number">1</span>之间，即–<span class="number">1</span>≤ r ≤+<span class="number">1</span>。其性质如下：</span><br><span class="line">当r&gt;<span class="number">0</span>时，表示两变量正相关，r&lt;<span class="number">0</span>时，两变量为负相关</span><br><span class="line">当|r|=<span class="number">1</span>时，表示两变量为完全相关，当r=<span class="number">0</span>时，表示两变量间无相关关系</span><br><span class="line">当<span class="number">0</span>&lt;|r|&lt;<span class="number">1</span>时，表示两变量存在一定程度的相关。且|r|越接近<span class="number">1</span>，两变量间线性关系越密切；|r|越接近于<span class="number">0</span>，表示两变量的线性相关越弱</span><br><span class="line">一般可按三级划分：|r|&lt;<span class="number">0.4</span>为低度相关；<span class="number">0.4</span>≤|r|&lt;<span class="number">0.7</span>为显著性相关；<span class="number">0.7</span>≤|r|&lt;<span class="number">1</span>为高度线性相关</span><br></pre></td></tr></table></figure>
<p><strong>API</strong>：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">	x : (N,) <span class="built_in">array</span>_like</span><br><span class="line">	y : (N,) <span class="built_in">array</span>_like Returns: (Pearson’s correlation coefficient, p-value)</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pea_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""皮尔逊相关系数"""</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    x1 = [<span class="number">12.5</span>, <span class="number">15.3</span>, <span class="number">23.2</span>, <span class="number">26.4</span>, <span class="number">33.5</span>, <span class="number">34.4</span>, <span class="number">39.4</span>, <span class="number">45.2</span>, <span class="number">55.4</span>, <span class="number">60.9</span>]</span><br><span class="line">    x2 = [<span class="number">21.2</span>, <span class="number">23.9</span>, <span class="number">32.9</span>, <span class="number">34.1</span>, <span class="number">42.5</span>, <span class="number">43.2</span>, <span class="number">49.0</span>, <span class="number">52.8</span>, <span class="number">59.4</span>, <span class="number">63.5</span>]</span><br><span class="line">    <span class="comment"># 判断</span></span><br><span class="line">    ret = pearsonr(x1, x2)</span><br><span class="line">    print(<span class="string">"皮尔逊相关系数:\n"</span>, ret)</span><br><span class="line">     </span><br><span class="line">pea_demo()</span><br><span class="line"><span class="comment"># (0.9941983762371883, 4.9220899554573455e-09)</span></span><br></pre></td></tr></table></figure>
<p>2.<strong>斯皮尔曼相关系数</strong>(Rank IC)</p>
<p><strong>作用</strong>： 反映变量之间相关关系密切程度的统计指标 </p>
<p><strong>公式</strong>：  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154022.png"/> </p>
<p>n为等级个数，d为二列成对变量的等级差数 </p>
<p><strong>特点</strong>：</p>
<figure class="highlight tp"><table><tr><td class="code"><pre><span class="line">斯皮尔曼相关系数表明 <span class="keyword">X</span> (自变量) 和 <span class="keyword">Y</span> (因变量)的相关方向。 如果当<span class="keyword">X</span>增加时， <span class="keyword">Y</span> 趋向于增加, 斯皮尔曼相关系数则为正</span><br><span class="line">与之前的皮尔逊相关系数大小性质一样，取值 [<span class="number">-1</span>, <span class="number">1</span>]之间</span><br><span class="line">注意：斯皮尔曼相关系数比皮尔逊相关系数应用更加广泛</span><br></pre></td></tr></table></figure>
<p><strong>API</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spear_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""斯皮尔曼相关系数"""</span></span><br><span class="line">    <span class="comment"># 1.准备数据</span></span><br><span class="line">    x1 = [<span class="number">12.5</span>, <span class="number">15.3</span>, <span class="number">23.2</span>, <span class="number">26.4</span>, <span class="number">33.5</span>, <span class="number">34.4</span>, <span class="number">39.4</span>, <span class="number">45.2</span>, <span class="number">55.4</span>, <span class="number">60.9</span>]</span><br><span class="line">    x2 = [<span class="number">21.2</span>, <span class="number">23.9</span>, <span class="number">32.9</span>, <span class="number">34.1</span>, <span class="number">42.5</span>, <span class="number">43.2</span>, <span class="number">49.0</span>, <span class="number">52.8</span>, <span class="number">59.4</span>, <span class="number">63.5</span>]</span><br><span class="line">    <span class="comment"># 判断</span></span><br><span class="line">    ret = spearmanr(x1, x2)</span><br><span class="line">    print(<span class="string">"斯皮尔曼相关系数：\n"</span>, ret)</span><br><span class="line">    </span><br><span class="line">spear_demo()</span><br></pre></td></tr></table></figure>
<h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><h5 id="什么是主成分分析"><a href="#什么是主成分分析" class="headerlink" title="什么是主成分分析"></a>什么是主成分分析</h5><ul>
<li>定义：<strong>高维数据转化为低维数据的过程</strong>，在此过程中<strong>可能会舍弃原有数据、创造新的变量</strong></li>
<li>作用：<strong>是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。</strong></li>
<li>应用：回归分析或者聚类分析当中</li>
<li><strong>图示</strong>： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154036.png"/> </li>
</ul>
<h5 id="API"><a href="#API" class="headerlink" title="API"></a>API</h5><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.decomposition.<span class="constructor">PCA(<span class="params">n_components</span>=None)</span></span><br><span class="line">- 将数据分解为较低维数空间</span><br><span class="line">- n_components:</span><br><span class="line">  - 小数：表示保留百分之多少的信息</span><br><span class="line">  - 整数：减少到多少特征</span><br><span class="line">- <span class="module-access"><span class="module"><span class="identifier">PCA</span>.</span></span>fit<span class="constructor">_transform(X)</span> X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">- 返回值：转换后指定维度的<span class="built_in">array</span></span><br></pre></td></tr></table></figure>
<h5 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pca_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对数据进行PCA降维</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>], [<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化PCA, 小数——保留多少信息</span></span><br><span class="line">    transfer = PCA(n_components=<span class="number">0.9</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data1 = transfer.fit_transform(data)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"保留90%的信息，降维结果为：\n"</span>, data1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化PCA, 整数——指定降维到的维数</span></span><br><span class="line">    transfer2 = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data2 = transfer2.fit_transform(data)</span><br><span class="line">    print(<span class="string">"降维到3维的结果：\n"</span>, data2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pca_demo()</span><br><span class="line">    </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">保留90%的信息，降维结果为：</span></span><br><span class="line"><span class="string"> [[ -3.13587302e-16   3.82970843e+00]</span></span><br><span class="line"><span class="string"> [ -5.74456265e+00  -1.91485422e+00]</span></span><br><span class="line"><span class="string"> [  5.74456265e+00  -1.91485422e+00]]</span></span><br><span class="line"><span class="string">降维到3维的结果：</span></span><br><span class="line"><span class="string"> [[ -3.13587302e-16   3.82970843e+00   4.59544715e-16]</span></span><br><span class="line"><span class="string"> [ -5.74456265e+00  -1.91485422e+00   4.59544715e-16]</span></span><br><span class="line"><span class="string"> [  5.74456265e+00  -1.91485422e+00   4.59544715e-16]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">降维的定义：就是改变特征值，选择哪列保留，哪列删除，目标是得到一组”不相关“的主变量</span><br><span class="line">降维的两种方式：<span class="number">1.</span>特征选择，<span class="number">2.</span>主成分分析（可以理解一种特征提取的方式）</span><br><span class="line">特征选择</span><br><span class="line">定义：提出数据中的冗余变量</span><br><span class="line">方法：</span><br><span class="line">	Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联</span><br><span class="line">		方差选择法：低方差特征过滤</span><br><span class="line">		相关系数</span><br><span class="line">	Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）</span><br><span class="line">		决策树:信息熵、信息增益</span><br><span class="line">		正则化：L1、L2</span><br><span class="line">低方差特征过滤:把方差比较小的某一列进行剔除</span><br><span class="line">api:sklearn.feature_selection.VarianceThreshold(threshold = <span class="number">0.0</span>)</span><br><span class="line">	删除所有低方差特征</span><br><span class="line">	注意，参数threshold一定要进行值的指定</span><br><span class="line">相关系数</span><br><span class="line">主要实现方式：</span><br><span class="line">	皮尔逊相关系数</span><br><span class="line">		通过具体值的大小进行计算</span><br><span class="line">		相对复杂</span><br><span class="line">		api:<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">		返回值，越接近|<span class="number">1</span>|，相关性越强；越接近<span class="number">0</span>，相关性越弱</span><br><span class="line">	斯皮尔曼相关系数</span><br><span class="line">		通过等级差进行计算</span><br><span class="line">		比上一个简单</span><br><span class="line">		api:<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> spearmanr</span><br><span class="line">		返回值，越接近|<span class="number">1</span>|，相关性越强；越接近<span class="number">0</span>，相关性越弱</span><br><span class="line">主成分分析pca</span><br><span class="line">定义：高维数据转换为低维数据，然后产生了新的变量</span><br><span class="line">api:sklearn.decomposition.PCA(n_components=None)</span><br><span class="line">n_components</span><br><span class="line">整数 -- 表示降低到几维</span><br><span class="line">小数 -- 保留百分之多少的信息</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>特征降维</tag>
        <tag>特征选择</tag>
        <tag>主成分分析</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类算法</title>
    <url>/2020/02/01/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h4 id="聚类算法简介"><a href="#聚类算法简介" class="headerlink" title="聚类算法简介"></a>聚类算法简介</h4><p> <strong>使用不同的聚类准则，产生的聚类结果不同</strong>。 </p>
<a id="more"></a>
<ol>
<li><h5 id="聚类算法在现实中的应用"><a href="#聚类算法在现实中的应用" class="headerlink" title="聚类算法在现实中的应用"></a>聚类算法在现实中的应用</h5><ul>
<li>用户画像，广告推荐，Data Segmentation，搜索引擎的流量推荐，恶意流量识别</li>
<li>基于位置信息的商业推送，新闻聚类，筛选排序</li>
<li>图像分割，降维，识别；离群点检测；信用卡异常消费；发掘相同功能的基因片段</li>
</ul>
</li>
<li><h5 id="聚类算法的概念"><a href="#聚类算法的概念" class="headerlink" title="聚类算法的概念"></a>聚类算法的概念</h5><p>一种典型的<strong>无监督</strong>学习算法，主要用于将相似的样本自动归到一个类别中。在聚类算法中根据样本之间的相似性，将样本划分到不同的类别中，对于不同的相似度计算方法，会得到不同的聚类结果，常用的相似度计算方法有欧式距离法。</p>
</li>
<li><h5 id="聚类算法与分类算法最大的区别"><a href="#聚类算法与分类算法最大的区别" class="headerlink" title="聚类算法与分类算法最大的区别"></a>聚类算法与分类算法最大的区别</h5><p> 聚类算法是无监督的学习算法，而分类算法属于监督的学习算法。 </p>
</li>
</ol>
<h4 id="聚类算法API"><a href="#聚类算法API" class="headerlink" title="聚类算法API"></a>聚类算法API</h4><ol>
<li><h5 id="API介绍"><a href="#API介绍" class="headerlink" title="API介绍"></a>API介绍</h5><figure class="highlight gml"><table><tr><td class="code"><pre><span class="line">sklearn.cluster.KMeans(n_clusters=<span class="number">8</span>)</span><br><span class="line">参数:</span><br><span class="line">	n_clusters:开始的聚类中心数量</span><br><span class="line">		整型，缺省值=<span class="number">8</span>，生成的聚类数，即产生的质心（centroids）数。</span><br><span class="line">方法:</span><br><span class="line">	estimator.fit(<span class="symbol">x</span>)</span><br><span class="line">	estimator.predict(<span class="symbol">x</span>)</span><br><span class="line">	estimator.fit_predict(<span class="symbol">x</span>)</span><br><span class="line">		计算聚类中心并预测每个样本属于哪个类别,相当于先调用fit(<span class="symbol">x</span>),然后再调用predict(<span class="symbol">x</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><h5 id="小案例"><a href="#小案例" class="headerlink" title="小案例"></a>小案例</h5><p> 随机创建不同二维数据集作为训练集，并结合k-means算法将其聚类，你可以尝试分别聚类不同数量的簇，并观察聚类效果： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112324.png"/> </p>
<p> 聚类参数n_cluster传值不同，得到的聚类结果不同 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227141148.png"/> </p>
<p>1.<strong>流程分析</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112232.png"/> </p>
<p>2.<strong>代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> calinski_harabaz_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建数据集</span></span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，</span></span><br><span class="line"><span class="comment"># 簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2, 0.2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>, centers=[[<span class="number">-1</span>, <span class="number">-1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line">                  cluster_std=[<span class="number">0.4</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span><br><span class="line">                  random_state=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集可视化</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">'o'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.使用k-means进行聚类,并使用CH方法评估</span></span><br><span class="line">y_pred = KMeans(n_clusters=<span class="number">2</span>, random_state=<span class="number">9</span>).fit_predict(X)</span><br><span class="line"><span class="comment"># 分别尝试n_cluses=2\3\4,然后查看聚类效果</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_pred)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用Calinski-Harabasz Index评估的聚类分数</span></span><br><span class="line">print(calinski_harabaz_score(X, y_pred))</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="聚类算法实现流程"><a href="#聚类算法实现流程" class="headerlink" title="聚类算法实现流程"></a>聚类算法实现流程</h4><blockquote>
<p><strong>k-means其实包含两层内容：</strong></p>
<ul>
<li>K : 初始中心点个数（计划聚类数）</li>
<li>means：求中心点到其他数据点距离的平均值</li>
</ul>
</blockquote>
<h5 id="1-k-means聚类步骤"><a href="#1-k-means聚类步骤" class="headerlink" title="1. k-means聚类步骤"></a>1. k-means聚类步骤</h5><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>、随机设置K个特征空间内的点作为初始的聚类中心</span><br><span class="line"><span class="number">2</span>、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别</span><br><span class="line"><span class="number">3</span>、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）</span><br><span class="line"><span class="number">4</span>、如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程</span><br></pre></td></tr></table></figure>
<p> 通过下图解释实现流程： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111050.png"/></p>
<p>  k聚类动态效果图 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227141741.png"/></p>
<h5 id="2-案例练习"><a href="#2-案例练习" class="headerlink" title="2.案例练习"></a>2.案例练习</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112202.png"/></p>
<p>  1.随机设置K个特征空间内的点作为初始的聚类中心（本案例中设置p1和p2） </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112154.png"/></p>
<p>  2.对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112148.png"/></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112139.png"/></p>
<p>  3.接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值） </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112132.png"/></p>
<p> 4.如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程【经过判断，需要重复上述步骤，开始新一轮迭代】 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112123.png"/></p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112119.png"/> </p>
<p>  5.当每次迭代结果不变时，认为算法收敛，聚类完成，<strong>K-Means一定会停下，不可能陷入一直选质心的过程。</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112105.png"/></p>
<h4 id="聚类算法模型评估"><a href="#聚类算法模型评估" class="headerlink" title="聚类算法模型评估"></a>聚类算法模型评估</h4><h5 id="1-误差平方和-SSE-The-sum-of-squares-due-to-error"><a href="#1-误差平方和-SSE-The-sum-of-squares-due-to-error" class="headerlink" title="1.误差平方和(SSE \The sum of squares due to error)"></a>1.误差平方和(SSE \The sum of squares due to error)</h5><p> 举例:(下图中数据-0.2, 0.4, -0.8, 1.3, -0.7, 均为真实值和预测值的差) </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110835.png"/></p>
<p>  在k-means中的应用: </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110825.png"/></p>
<p>  <img src="%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/sse3.png" alt="image-20190219173610490"> </p>
<p> 公式各部分内容: </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110811.png"/></p>
<p> 上图中: k=2</p>
<ul>
<li><p><strong>SSE图最终的结果，对图松散度的衡量.</strong>(eg: **SSE(左图))</p>
</li>
<li><p>SSE随着聚类迭代，其值会越来越小，直到最后趋于稳定</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110737.png"/> </p>
</li>
<li><p>如果质心的初始值选择不好，SSE只会达到一个不怎么好的局部最优解. </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227101738.png"/> </p>
</li>
</ul>
<h5 id="2-“肘”方法-Elbow-method-—-K值确定"><a href="#2-“肘”方法-Elbow-method-—-K值确定" class="headerlink" title="2.“肘”方法 (Elbow method) — K值确定"></a>2.“肘”方法 (Elbow method) — K值确定</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112225.png"/></p>
<p> （1）对于n个点的数据集，迭代计算k from 1 to n，每次聚类完成后计算每个点到其所属的簇中心的距离的平方和；</p>
<p>（2）平方和是会逐渐变小的，直到k==n时平方和为0，因为每个点都是它所在的簇中心本身。</p>
<p>（3）在这个平方和变化过程中，会出现一个拐点也即“肘”点，<strong>下降率突然变缓时即认为是最佳的k值</strong>。</p>
<p>在决定什么时候停止训练时，肘形判据同样有效，数据通常有更多的噪音，在<strong>增加分类无法带来更多回报时，我们停止增加类别</strong>。</p>
<h5 id="3-轮廓系数法（Silhouette-Coefficient）"><a href="#3-轮廓系数法（Silhouette-Coefficient）" class="headerlink" title="3.轮廓系数法（Silhouette Coefficient）"></a>3.轮廓系数法（Silhouette Coefficient）</h5><p> 结合了聚类的凝聚度（Cohesion）和分离度（Separation），用于评估聚类的效果： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111035.png"/></p>
<p> <strong>目的：</strong> 内部距离最小化，外部距离最大化</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110928.png"/> </p>
<p>计算样本$i$到同簇其他样本的平均距离$a_i$，$a_i$ 越小样本i的簇内不相似度越小，说明样本$i$越应该被聚类到该簇。</p>
<p>计算样本i到最近簇$C<em>j$ 的所有样本的平均距离$b</em>(ij)$，称样本$i$与最近簇$C_j$ 的不相似度，定义为样本i的簇间不相似度：</p>
<p>$b<em>i =min{b</em>(i1), b<em>(i2), …, b</em>(ik)}$，$b_i$越大，说明样本$i$越不属于其他簇。</p>
<p>求出所有样本的轮廓系数后再求平均值就得到了<strong>平均轮廓系数</strong>。</p>
<p>平均轮廓系数的取值范围为[-1,1]，系数越大，聚类效果越好。</p>
<p>簇内样本的距离越近，簇间样本距离越远</p>
<p><strong>案例：</strong></p>
<p>下图是500个样本含有2个feature的数据分布情况，我们对它进行SC系数效果衡量：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110915.png"/> </p>
<p><strong>n_clusters = 2 The average silhouette_score is : 0.7049787496083262</strong></p>
<p>n_clusters = 3 The average silhouette_score is : 0.5882004012129721</p>
<p><strong>n_clusters = 4 The average silhouette_score is : 0.6505186632729437</strong></p>
<p>n_clusters = 5 The average silhouette_score is : 0.56376469026194</p>
<p>n_clusters = 6 The average silhouette_score is : 0.4504666294372765</p>
<p>n_clusters 分别为 2，3，4，5，6时，SC系数如下，是介于[-1,1]之间的度量指标：</p>
<p><strong>每次聚类后，每个样本都会得到一个轮廓系数，当它为1时，说明这个点与周围簇距离较远，结果非常好，当它为0，说明这个点可能处在两个簇的边界上，当值为负时，暗含该点可能被误分了。</strong></p>
<p>从平均SC系数结果来看，K取3，5，6是不好的，那么2和4呢？</p>
<p>k=2的情况：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110855.png"/></p>
<p>  k=4的情况： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227142806.png"/></p>
<p> n_clusters = 2时，第0簇的宽度远宽于第1簇；</p>
<p>n_clusters = 4时，所聚的簇宽度相差不大，因此选择K=4，作为最终聚类个数。</p>
<h5 id="4-CH系数（Calinski-Harabasz-Index）"><a href="#4-CH系数（Calinski-Harabasz-Index）" class="headerlink" title="4.CH系数（Calinski-Harabasz Index）"></a>4.CH系数（Calinski-Harabasz Index）</h5><p><strong>Calinski-Harabasz：</strong>类别内部数据的协方差越小越好，类别之间的协方差越大越好（换句话说：类别内部数据的距离平方和越小越好，类别之间的距离平方和越大越好），</p>
<p>这样的Calinski-Harabasz分数s会高，分数s高则聚类效果越好。</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112338.png"/> </p>
<p>tr为<strong>矩阵的迹</strong>, Bk为类别之间的协方差矩阵，Wk为类别内部数据的协方差矩阵;</p>
<p>m为训练集样本数，k为类别数。</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112330.png"/></p>
<p> 使用矩阵的迹进行求解的理解：</p>
<p>矩阵的对角线可以表示一个物体的相似性</p>
<p>在机器学习里，主要为了获取数据的特征值，那么就是说，在任何一个矩阵计算出来之后，都可以简单化，只要获取矩阵的迹，就可以表示这一块数据的最重要的特征了，这样就可以把很多无关紧要的数据删除掉，达到简化数据，提高处理速度。</p>
<p>CH需要达到的目的：<strong>用尽量少的类别聚类尽量多的样本，同时获得较好的聚类效果。</strong></p>
<h4 id="聚类算法算法优化"><a href="#聚类算法算法优化" class="headerlink" title="聚类算法算法优化"></a>聚类算法算法优化</h4><p><strong>k-means算法小结</strong></p>
<p><strong>优点：</strong></p>
<p> 1.原理简单（靠近中心点），实现容易</p>
<p> 2.聚类效果中上（依赖K的选择）</p>
<p> 3.空间复杂度o(N)，时间复杂度o(I<em>K</em>N)</p>
<blockquote>
<p>N为样本点个数，K为中心点个数，I为迭代次数</p>
</blockquote>
<p><strong>缺点：</strong></p>
<p> 1.对离群点，噪声敏感 （中心点易偏移）</p>
<p> 2.很难发现大小差别很大的簇及进行增量计算</p>
<p> 3.结果不一定是全局最优，只能保证局部最优（与K的个数及初值选取有关）</p>
<h5 id="1-Canopy算法配合初始聚类"><a href="#1-Canopy算法配合初始聚类" class="headerlink" title="1.Canopy算法配合初始聚类"></a>1.Canopy算法配合初始聚类</h5><p>Canopy算法配合初始聚类实现流程：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112345.png"/></p>
<p> 优点：</p>
<ol>
<li><p>Kmeans对噪声抗干扰较弱，通过Canopy对比，将较小的NumPoint的Cluster直接去掉有利于抗干扰。</p>
</li>
<li><p>Canopy选择出来的每个Canopy的centerPoint作为K会更精确。</p>
</li>
<li><p>只是针对每个Canopy的内做Kmeans聚类，减少相似计算的数量。</p>
</li>
</ol>
<p>缺点：</p>
<p> 算法中 T1、T2的确定问题 ，依旧可能落入局部最优解</p>
<h5 id="2-K-means"><a href="#2-K-means" class="headerlink" title="2.K-means++"></a>2.K-means++</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111237.png"/> </p>
<p>  其中： <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111057.png"/></p>
<p>  为方便后面表示，把其记为A </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111217.png"/></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111212.png"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111104.png"/></p>
<p> kmeans++目的，让选择的质心尽可能的分散</p>
<p>如下图中，如果第一个质心选择在圆心，那么最优可能选择到的下一个点在P(A)这个区域（根据颜色进行划分）</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111230.png"/></p>
<h5 id="3-二分k-means"><a href="#3-二分k-means" class="headerlink" title="3.二分k-means"></a>3.二分k-means</h5><p>实现流程:</p>
<ol>
<li><p>所有点作为一个簇</p>
</li>
<li><p>将该簇一分为二</p>
</li>
<li><p>选择能最大限度降低聚类代价函数（也就是误差平方和）的簇划分为两个簇。</p>
</li>
<li><p>以此进行下去，直到簇的数目等于用户给定的数目k为止。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112217.png"/> </p>
</li>
</ol>
<p><strong>隐含的一个原则</strong></p>
<p>因为聚类的误差平方和能够衡量聚类性能，该值越小表示数据点越接近于他们的质心，聚类效果就越好。所以需要对误差平方和最大的簇进行再一次划分，因为误差平方和越大，表示该簇聚类效果越不好，越有可能是多个簇被当成了一个簇，所以我们首先需要对这个簇进行划分。</p>
<p>二分K均值算法可以加速K-means算法的执行速度，因为它的相似度计算少了并且不受初始化问题的影响，因为这里不存在随机点的选取，且每一步都保证了误差最小</p>
<h5 id="4-k-medoids（k-中心聚类算法）"><a href="#4-k-medoids（k-中心聚类算法）" class="headerlink" title="4.k-medoids（k-中心聚类算法）"></a>4.k-medoids（k-中心聚类算法）</h5><p>K-medoids和K-means是有区别的，<strong>不一样的地方在于中心点的选取</strong></p>
<ul>
<li>K-means中，将中心点取为当前cluster中所有数据点的平均值，对异常点很敏感!</li>
<li><p>K-medoids中，将从当前cluster 中选取到其他所有（当前cluster中的）点的距离之和最小的点作为中心点。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227111042.png"/></p>
<p>算法流程：</p>
</li>
</ul>
<p>　　 ( 1 )总体n个样本点中任意选取k个点作为medoids</p>
<p>　　 ( 2 )按照与medoids最近的原则，将剩余的n-k个点分配到当前最佳的medoids代表的类中</p>
<p>　　 ( 3 )对于第i个类中除对应medoids点外的所有其他点，按顺序计算当其为新的medoids时，代价函数的值，遍历所有可能，选取代价函数最小时对应的点作为新的medoids</p>
<p>　　 ( 4 )重复2-3的过程，直到所有的medoids点不再发生变化或已达到设定的最大迭代次数</p>
<p>　　 ( 5 )产出最终确定的k个类</p>
<p><strong>k-medoids对噪声鲁棒性好。</strong></p>
<p>例：当一个cluster样本点只有少数几个，如（1,1）（1,2）（2,1）（1000,1000）。其中（1000,1000）是噪声。如果按照k-means质心大致会处在（1,1）（1000,1000）中间，这显然不是我们想要的。这时k-medoids就可以避免这种情况，他会在（1,1）（1,2）（2,1）（1000,1000）中选出一个样本点使cluster的绝对误差最小，计算可知一定会在前三个点中选取。</p>
<p>k-medoids只能对小样本起作用，样本大，速度就太慢了，当样本多的时候，少数几个噪音对k-means的质心影响也没有想象中的那么重，所以k-means的应用明显比k-medoids多。</p>
<h5 id="5-Kernel-k-means"><a href="#5-Kernel-k-means" class="headerlink" title="5.Kernel k-means"></a>5.Kernel k-means</h5><p> kernel k-means实际上，就是将每个样本进行一个投射到高维空间的处理，然后再将处理后的数据使用普通的k-means算法思想进行聚类。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227112209.png"/></p>
<h5 id="6-ISODATA"><a href="#6-ISODATA" class="headerlink" title="6.ISODATA"></a>6.ISODATA</h5><p>类别数目随着聚类过程而变化；</p>
<p>对类别数会进行合并，分裂，</p>
<p>“合并”：（当聚类结果某一类中样本数太少，或两个类间的距离太近时）</p>
<p>“分裂”：（当聚类结果中某一类的类内方差太大，将该类进行分裂）</p>
<h5 id="7-Mini-Batch-K-Means"><a href="#7-Mini-Batch-K-Means" class="headerlink" title="7.Mini Batch K-Means"></a>7.Mini Batch K-Means</h5><p>适合大数据的聚类算法</p>
<p>大数据量是什么量级？通常当样本量大于1万做聚类时，就需要考虑选用Mini Batch K-Means算法。</p>
<p>Mini Batch KMeans使用了Mini Batch（分批处理）的方法对数据点之间的距离进行计算。</p>
<p>Mini Batch计算过程中不必使用所有的数据样本，而是从不同类别的样本中抽取一部分样本来代表各自类型进行计算。由于计算样本量少，所以会相应的减少运行时间，但另一方面抽样也必然会带来准确度的下降。</p>
<p>该算法的迭代步骤有两步：</p>
<p>(1)从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</p>
<p>(2)更新质心</p>
<p> 与Kmeans相比，数据的更新在每一个小的样本集上。对于每一个小批量，通过计算平均值得到更新质心，并把小批量里的数据分配给该质心，随着迭代次数的增加，这些质心的变化是逐渐减小的，直到质心稳定或者达到指定的迭代次数，停止计算。</p>
<p><strong>总结</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>优化方法</strong></th>
<th><strong>思路</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Canopy+kmeans</td>
<td>Canopy粗聚类配合kmeans</td>
</tr>
<tr>
<td>kmeans++</td>
<td>距离越远越容易成为新的质心</td>
</tr>
<tr>
<td>二分k-means</td>
<td>拆除SSE最大的簇</td>
</tr>
<tr>
<td>k-medoids</td>
<td>和kmeans选取中心点的方式不同</td>
</tr>
<tr>
<td>kernel kmeans</td>
<td>映射到高维空间</td>
</tr>
<tr>
<td>ISODATA</td>
<td>动态聚类，可以更改K值大小</td>
</tr>
<tr>
<td>Mini-batch K-Means</td>
<td>大数据集分批聚类</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例-探究用户对物品类别的喜好细分"><a href="#案例-探究用户对物品类别的喜好细分" class="headerlink" title="案例-探究用户对物品类别的喜好细分"></a>案例-探究用户对物品类别的喜好细分</h4><h5 id="1-数据介绍"><a href="#1-数据介绍" class="headerlink" title="1.数据介绍"></a>1.数据介绍</h5><figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">数据如下：</span><br><span class="line"><span class="keyword">order_products__prior.csv：订单与商品信息</span></span><br><span class="line"><span class="keyword">字段：order_id, </span>product_id, <span class="keyword">add_to_cart_order, </span>reordered</span><br><span class="line">products.csv：商品信息</span><br><span class="line">字段：product_id, product_name, aisle_id, department_id</span><br><span class="line"><span class="keyword">orders.csv：用户的订单信息</span></span><br><span class="line"><span class="keyword">字段：order_id,user_id,eval_set,order_number,….</span></span><br><span class="line"><span class="keyword">aisles.csv：商品所属具体物品类别</span></span><br><span class="line"><span class="keyword">字段： </span>aisle_id, aisle</span><br></pre></td></tr></table></figure>
<h5 id="2-需求分析"><a href="#2-需求分析" class="headerlink" title="2.需求分析"></a>2.需求分析</h5><ol>
<li><p>获取数据</p>
</li>
<li><p>数据基本处理</p>
<p>2.1  合并表格</p>
<p>2.2 交叉表合并</p>
<p>2.3 数据截取</p>
</li>
<li><p>特征工程 — pca</p>
</li>
<li><p>机器学习（k-means）</p>
</li>
<li><p>模型评估</p>
<p>sklearn.metrics.silhouette_score(X, labels)</p>
<p>计算所有样本的平均轮廓系数</p>
<p>X：特征值</p>
<p>labels：被聚类标记的目标值</p>
</li>
</ol>
<h5 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3.代码实现"></a>3.代码实现</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据</span></span><br><span class="line">order_product = pd.read_csv(<span class="string">"./data/instacart/order_products__prior.csv"</span>)</span><br><span class="line">products = pd.read_csv(<span class="string">"./data/instacart/products.csv"</span>)</span><br><span class="line">orders = pd.read_csv(<span class="string">"./data/instacart/orders.csv"</span>)</span><br><span class="line">aisles = pd.read_csv(<span class="string">"./data/instacart/aisles.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据基本处理</span></span><br><span class="line"><span class="comment"># 2.1 合并表格</span></span><br><span class="line">table1 = pd.merge(order_product, products, on=[<span class="string">"product_id"</span>, <span class="string">"product_id"</span>])</span><br><span class="line">table2 = pd.merge(table1, orders, on=[<span class="string">"order_id"</span>, <span class="string">"order_id"</span>])</span><br><span class="line">table = pd.merge(table2, aisles, on=[<span class="string">"aisle_id"</span>, <span class="string">"aisle_id"</span>])</span><br><span class="line"><span class="comment"># 2.2 交叉表合并</span></span><br><span class="line">table = pd.crosstab(table[<span class="string">"user_id"</span>], table[<span class="string">"aisle"</span>])</span><br><span class="line"><span class="comment"># 2.3 数据截取</span></span><br><span class="line">table = table[:<span class="number">1000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程 — pca</span></span><br><span class="line">transfer = PCA(n_components=<span class="number">0.9</span>)</span><br><span class="line">data = transfer.fit_transform(table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.机器学习（k-means）</span></span><br><span class="line">estimator = KMeans(n_clusters=<span class="number">8</span>, random_state=<span class="number">22</span>)</span><br><span class="line">estimator.fit_predict(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line">silhouette_score(data, y_predict)</span><br></pre></td></tr></table></figure>
<h4 id="拓展-算法选择指导"><a href="#拓展-算法选择指导" class="headerlink" title="拓展-算法选择指导"></a>拓展-算法选择指导</h4><p><strong>关于在计算的过程中，如何选择合适的算法进行计算，可以参考scikit learn官方给的指导意见：</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227110840.png"/> </p>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器</tag>
        <tag>学习机器学习算法</tag>
        <tag>聚类算法</tag>
        <tag>无监督学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法</title>
    <url>/2020/01/15/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h4 id="推荐模型构建流程"><a href="#推荐模型构建流程" class="headerlink" title="推荐模型构建流程"></a>推荐模型构建流程</h4><blockquote>
<p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(选择算法训练模型)-&gt;Prediction Output(预测输出) </p>
</blockquote>
<a id="more"></a>
<ul>
<li><p>数据清洗/数据处理 </p>
<ul>
<li><p>数据来源</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">- 显性数据</span><br><span class="line">  - Rating 打分</span><br><span class="line">  - Comments 评论/评价</span><br><span class="line">- 隐形数据</span><br><span class="line">  -  Order history 历史订单</span><br><span class="line">  -  Cart events 加购物车</span><br><span class="line">  - <span class="built_in"> Page </span>views 页面浏览</span><br><span class="line">  -  Click-thru 点击</span><br><span class="line">  -  Search log 搜索记录</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据量/数据能否满足要求</p>
</li>
</ul>
</li>
<li><p>特征工程 </p>
<ul>
<li><p>从数据中筛选特征</p>
<ul>
<li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li>
<li>使用用户行为数据描述商品</li>
</ul>
</li>
<li><p>用数据表示特征</p>
<ul>
<li>将所有用户行为合并在一起 ，形成一个user-item 矩阵</li>
</ul>
</li>
</ul>
</li>
<li><p>选择合适的算法 </p>
<ul>
<li><p><strong>协同过滤</strong></p>
</li>
<li><p>基于内容</p>
</li>
</ul>
</li>
<li><p>产生推荐结果</p>
<ul>
<li>对推荐结果进行评估（评估方法后面章节介绍），评估通过后上线</li>
</ul>
</li>
</ul>
<h4 id="最经典的推荐算法：协同过滤推荐算法"><a href="#最经典的推荐算法：协同过滤推荐算法" class="headerlink" title="最经典的推荐算法：协同过滤推荐算法"></a>最经典的推荐算法：协同过滤推荐算法</h4><p>协同过滤推荐算法（Collaborative Filtering）</p>
<p>算法思想： <strong>物以类聚，人以群分</strong> </p>
<p> 基本的协同过滤推荐算法基于以下假设： </p>
<ul>
<li>“跟你喜好<strong>相似的人</strong>喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）</li>
<li><p>“跟你喜欢的东西<strong>相似的东西</strong>你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）</p>
<p>实现协同过滤推荐步骤： </p>
</li>
</ul>
<p>1.<strong>找出最相似的人或物品：TOP-N相似的人或物品</strong></p>
<p>通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品</p>
<p>2.<strong>根据相似的人或物品产生推荐结果</strong></p>
<p>利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品</p>
<p>简单例子：</p>
<p>  User-Based CF <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154653.png"/></p>
<p> Item-Based CF   <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154700.png"/> </p>
<h4 id="相似度计算-Similarity-Calculation"><a href="#相似度计算-Similarity-Calculation" class="headerlink" title="相似度计算(Similarity Calculation)"></a>相似度计算(Similarity Calculation)</h4><h5 id="相似度的计算方法"><a href="#相似度的计算方法" class="headerlink" title="相似度的计算方法"></a>相似度的计算方法</h5><p>1.<strong>欧氏距离</strong>， 是一个欧式空间下度量距离的方法. 两个物体， 都在同一个空间下表示为两个点,，假如叫做p，q， 分别都是n个坐标，那么欧式距离就是衡量这两个点之间的距离.。欧氏距离不适用于布尔向量之间。</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155047.png"/></p>
<p>  欧氏距离的值是一个非负数, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154824.png"/></p>
<p>2.<strong>余弦相似度</strong> </p>
<ul>
<li>度量的是两个向量之间的夹角，用夹角的余弦值来度量相似的情况</li>
<li>两个向量的夹角为0是，余弦值为1，当夹角为90度是余弦值为0，为180度是余弦值为-1</li>
<li>余弦相似度在度量文本相似度, 用户相似度 物品相似度的时候较为常用</li>
<li><p>余弦相似度的特点， 与向量长度无关，余弦相似度计算要对向量长度归一化， 两个向量只要方向一致，无论程度强弱，都可以视为’相似’</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155116.png"/></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154815.png"/></p>
</li>
</ul>
<h5 id="皮尔逊相关系数Pearson"><a href="#皮尔逊相关系数Pearson" class="headerlink" title="皮尔逊相关系数Pearson"></a>皮尔逊相关系数Pearson</h5><ul>
<li>实际上也是余弦相似度，不过先对向量做了中心化，向量a，b各自减去向量的均值后, 再计算余弦相似度</li>
<li>皮尔逊相似度计算结果在-1，1之间 -1表示负相关， 1表示正相关</li>
<li>度量两个变量是不是同增同减</li>
<li><p>皮尔逊相关系数度量的是两个变量的变化趋势是否一致，<strong>不适合计算布尔值向量之间的相关度</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154731.png"/> </p>
</li>
</ul>
<h5 id="杰卡德相似度-Jaccard"><a href="#杰卡德相似度-Jaccard" class="headerlink" title="杰卡德相似度 Jaccard"></a>杰卡德相似度 Jaccard</h5><ul>
<li>两个集合的交集元素个数在并集中所占的比例，非常适用于布尔向量表示</li>
<li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li>
<li><p>分母是两个布尔向量做或运算， 再求元素和</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154906.png"/> </p>
</li>
</ul>
<h5 id="如何选择余弦相似度"><a href="#如何选择余弦相似度" class="headerlink" title="如何选择余弦相似度"></a>如何选择余弦相似度</h5><ul>
<li>余弦相似度/皮尔逊相关系数适合用户评分数据(实数值)；</li>
<li>杰卡德相似度适用于隐式反馈数据(0，1布尔值 是否收藏，是否点击，是否加购物车)</li>
</ul>
<h4 id="协同过滤推荐算法代码案例"><a href="#协同过滤推荐算法代码案例" class="headerlink" title="协同过滤推荐算法代码案例"></a>协同过滤推荐算法代码案例</h4><p>1.构建数据集 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 构建数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>],</span><br><span class="line">    [<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="string">"buy"</span>,<span class="literal">None</span>,<span class="string">"buy"</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>2.计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line">print(df)</span><br></pre></td></tr></table></figure>
<p>3 .有了数据集，接下来我们就可以进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。这里我们选择使用杰卡德相似系数[0,1] </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> jaccard_similarity_score</span><br><span class="line"><span class="comment"># 直接计算某两项的杰卡德相似系数</span></span><br><span class="line"><span class="comment"># 计算Item A 和Item B的相似度</span></span><br><span class="line">print(jaccard_similarity_score(df[<span class="string">"Item A"</span>], df[<span class="string">"Item B"</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line">print(user_similar)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">print(item_similar)</span><br></pre></td></tr></table></figure>
<p> 有了两两的相似度，接下来就可以筛选TOP-N相似结果，并进行推荐了 </p>
<p>4.User-Based CF </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算用户间相似度  1-杰卡德距离=杰卡德相似度</span></span><br><span class="line">user_similar = <span class="number">1</span> - pairwise_distances(df, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">user_similar = pd.DataFrame(user_similar, columns=users, index=users)</span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line">print(user_similar)</span><br><span class="line"></span><br><span class="line">topN_users = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> user_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = user_similar.loc[i].drop([i])</span><br><span class="line">    <span class="comment">#sort_values 排序 按照相似度降序排列</span></span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 从排序之后的结果中切片 取出前两条（相似度最高的两个）</span></span><br><span class="line">    top2 = list(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_users[i] = top2</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Top2相似用户："</span>)</span><br><span class="line">pprint(topN_users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备空白dict用来保存推荐结果</span></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment">#遍历所有的最相似用户</span></span><br><span class="line"><span class="keyword">for</span> user, sim_users <span class="keyword">in</span> topN_users.items():</span><br><span class="line">    rs_result = set()    <span class="comment"># 存储推荐结果</span></span><br><span class="line">    <span class="keyword">for</span> sim_user <span class="keyword">in</span> sim_users:</span><br><span class="line">        <span class="comment"># 构建初始的推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(set(df.ix[sim_user].replace(<span class="number">0</span>,np.nan).dropna().index))</span><br><span class="line">    <span class="comment"># 过滤掉已经购买过的物品</span></span><br><span class="line">    rs_result -= set(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line">print(<span class="string">"最终推荐结果："</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure>
<p>5.Item-Based CF </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算所有的数据两两的杰卡德相似系数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="comment"># 计算物品间相似度</span></span><br><span class="line">item_similar = <span class="number">1</span> - pairwise_distances(df.T, metric=<span class="string">"jaccard"</span>)</span><br><span class="line">item_similar = pd.DataFrame(item_similar, columns=items, index=items)</span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">print(item_similar)</span><br><span class="line"></span><br><span class="line">topN_items = &#123;&#125;</span><br><span class="line"><span class="comment"># 遍历每一行数据</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> item_similar.index:</span><br><span class="line">    <span class="comment"># 取出每一列数据，并删除自身，然后排序数据</span></span><br><span class="line">    _df = item_similar.loc[i].drop([i])</span><br><span class="line">    _df_sorted = _df.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    top2 = list(_df_sorted.index[:<span class="number">2</span>])</span><br><span class="line">    topN_items[i] = top2</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Top2相似物品："</span>)</span><br><span class="line">pprint(topN_items)</span><br><span class="line"></span><br><span class="line">rs_results = &#123;&#125;</span><br><span class="line"><span class="comment"># 构建推荐结果</span></span><br><span class="line"><span class="keyword">for</span> user <span class="keyword">in</span> df.index:    <span class="comment"># 遍历所有用户</span></span><br><span class="line">    rs_result = set()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index:   <span class="comment"># 取出每个用户当前已购物品列表</span></span><br><span class="line">        <span class="comment"># 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果</span></span><br><span class="line">        rs_result = rs_result.union(topN_items[item])</span><br><span class="line">    <span class="comment"># 过滤掉用户已购的物品</span></span><br><span class="line">    rs_result -= set(df.ix[user].replace(<span class="number">0</span>,np.nan).dropna().index)</span><br><span class="line">    <span class="comment"># 添加到结果中</span></span><br><span class="line">    rs_results[user] = rs_result</span><br><span class="line"></span><br><span class="line">print(<span class="string">"最终推荐结果："</span>)</span><br><span class="line">pprint(rs_results)</span><br></pre></td></tr></table></figure>
<h4 id="关于协同过滤推荐算法使用的数据集"><a href="#关于协同过滤推荐算法使用的数据集" class="headerlink" title="关于协同过滤推荐算法使用的数据集"></a>关于协同过滤推荐算法使用的数据集</h4><p>在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测。</p>
<p>因此在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据。</p>
<h5 id="关于用户-物品评分矩阵"><a href="#关于用户-物品评分矩阵" class="headerlink" title="关于用户-物品评分矩阵"></a>关于用户-物品评分矩阵</h5><p> 用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案 </p>
<ul>
<li><p><strong>稠密评分矩阵</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154715.png"/> </p>
</li>
<li><p><strong>稀疏评分矩阵</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154645.png"/> </p>
</li>
</ul>
<h4 id="使用协同过滤推荐算法对用户进行评分预测"><a href="#使用协同过滤推荐算法对用户进行评分预测" class="headerlink" title="使用协同过滤推荐算法对用户进行评分预测"></a>使用协同过滤推荐算法对用户进行评分预测</h4><ul>
<li><p>数据集 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154709.png"/></p>
<p> <strong>目的：预测用户1对物品E的评分</strong> </p>
</li>
<li><p>构建数据集：注意这里构建评分数据时，对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">users = [<span class="string">"User1"</span>, <span class="string">"User2"</span>, <span class="string">"User3"</span>, <span class="string">"User4"</span>, <span class="string">"User5"</span>]</span><br><span class="line">items = [<span class="string">"Item A"</span>, <span class="string">"Item B"</span>, <span class="string">"Item C"</span>, <span class="string">"Item D"</span>, <span class="string">"Item E"</span>]</span><br><span class="line"><span class="comment"># 用户购买记录数据集</span></span><br><span class="line">datasets = [</span><br><span class="line">    [<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="literal">None</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">    [<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">5</span>],</span><br><span class="line">    [<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">2</span>,<span class="number">1</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</li>
<li><p>计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关</p>
<blockquote>
<p>pandas中corr方法可直接用于计算皮尔逊相关系数 </p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.DataFrame(datasets,</span><br><span class="line">                  columns=items,</span><br><span class="line">                  index=users)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"用户之间的两两相似度："</span>)</span><br><span class="line"><span class="comment"># 直接计算皮尔逊相关系数</span></span><br><span class="line"><span class="comment"># 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置</span></span><br><span class="line">user_similar = df.T.corr()</span><br><span class="line">print(user_similar.round(<span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"物品之间的两两相似度："</span>)</span><br><span class="line">item_similar = df.corr()</span><br><span class="line">print(item_similar.round(<span class="number">4</span>))</span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行结果：</span></span><br><span class="line"><span class="string">用户之间的两两相似度：</span></span><br><span class="line">        <span class="string">User1</span>   <span class="string">User2</span>   <span class="string">User3</span>   <span class="string">User4</span>   <span class="string">User5</span></span><br><span class="line"><span class="string">User1</span>  <span class="number">1.0000</span>  <span class="number">0.8528</span>  <span class="number">0.7071</span>  <span class="number">0.0000</span> <span class="number">-0.7921</span></span><br><span class="line"><span class="string">User2</span>  <span class="number">0.8528</span>  <span class="number">1.0000</span>  <span class="number">0.4677</span>  <span class="number">0.4900</span> <span class="number">-0.9001</span></span><br><span class="line"><span class="string">User3</span>  <span class="number">0.7071</span>  <span class="number">0.4677</span>  <span class="number">1.0000</span> <span class="number">-0.1612</span> <span class="number">-0.4666</span></span><br><span class="line"><span class="string">User4</span>  <span class="number">0.0000</span>  <span class="number">0.4900</span> <span class="number">-0.1612</span>  <span class="number">1.0000</span> <span class="number">-0.6415</span></span><br><span class="line"><span class="string">User5</span> <span class="number">-0.7921</span> <span class="number">-0.9001</span> <span class="number">-0.4666</span> <span class="number">-0.6415</span>  <span class="number">1.0000</span></span><br><span class="line"><span class="string">物品之间的两两相似度：</span></span><br><span class="line">        <span class="string">Item</span> <span class="string">A</span>  <span class="string">Item</span> <span class="string">B</span>  <span class="string">Item</span> <span class="string">C</span>  <span class="string">Item</span> <span class="string">D</span>  <span class="string">Item</span> <span class="string">E</span></span><br><span class="line"><span class="string">Item</span> <span class="string">A</span>  <span class="number">1.0000</span> <span class="number">-0.4767</span> <span class="number">-0.1231</span>  <span class="number">0.5322</span>  <span class="number">0.9695</span></span><br><span class="line"><span class="string">Item</span> <span class="string">B</span> <span class="number">-0.4767</span>  <span class="number">1.0000</span>  <span class="number">0.6455</span> <span class="number">-0.3101</span> <span class="number">-0.4781</span></span><br><span class="line"><span class="string">Item</span> <span class="string">C</span> <span class="number">-0.1231</span>  <span class="number">0.6455</span>  <span class="number">1.0000</span> <span class="number">-0.7206</span> <span class="number">-0.4276</span></span><br><span class="line"><span class="string">Item</span> <span class="string">D</span>  <span class="number">0.5322</span> <span class="number">-0.3101</span> <span class="number">-0.7206</span>  <span class="number">1.0000</span>  <span class="number">0.5817</span></span><br><span class="line"><span class="string">Item</span> <span class="string">E</span>  <span class="number">0.9695</span> <span class="number">-0.4781</span> <span class="number">-0.4276</span>  <span class="number">0.5817</span>  <span class="number">1.0000</span></span><br></pre></td></tr></table></figure>
<p>可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。</p>
<p><strong>注意：</strong>我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。</p>
</li>
<li><p><strong>评分预测：</strong> </p>
<p><strong>User-Based CF 评分预测：使用用户间的相似度进行预测</strong> </p>
<p>关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，该方案考虑了用户本身的评分评分以及近邻用户的加权平均相似度打分来进行预测： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155128.png"/></p>
<p>我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：$pred(u_1,i_5)=(0.85∗3+0.71∗5)/(0.85+0.71)=3.91$最终预测出用户1对物品5的评分为3.91</p>
<p><strong>Item-Based CF 评分预测：使用物品间的相似度进行预测</strong> </p>
<p>这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img2/20200227155120.png"/></p>
<p>户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，计算如下： $pred(u1,i5)=(0.97∗5+0.58∗4)/(0.97+0.58)=4.63$ 对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但具体哪一种更佳，必须经过合理的效果评估，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。 </p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>推荐模型构建流程</tag>
        <tag>推荐算法</tag>
        <tag>协同过滤推荐算法</tag>
        <tag>相似度计算</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统</title>
    <url>/2020/01/15/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h4 id="推荐系统概念"><a href="#推荐系统概念" class="headerlink" title="推荐系统概念"></a>推荐系统概念</h4><h5 id="什么是推荐系统"><a href="#什么是推荐系统" class="headerlink" title="什么是推荐系统"></a>什么是推荐系统</h5><p>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载，系统通过一定的规则对物品进行排序，并将排在前面的物品展示给用户，这样的系统就是推荐系统 。</p>
<h5 id="信息过载-amp-用户需求不明确"><a href="#信息过载-amp-用户需求不明确" class="headerlink" title="信息过载 &amp; 用户需求不明确"></a>信息过载 &amp; 用户需求不明确</h5><ul>
<li>分类⽬录（1990s）：覆盖少量热门⽹站。典型应用：Hao123 Yahoo</li>
<li>搜索引擎（2000s）：通过搜索词明确需求。典型应用：Google Baidu</li>
<li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤ 户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能 够满⾜他们兴趣和需求的信息。</li>
</ul>
<a id="more"></a>
<h5 id="推荐系统与搜索引擎"><a href="#推荐系统与搜索引擎" class="headerlink" title="推荐系统与搜索引擎"></a>推荐系统与搜索引擎</h5><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>搜索</th>
<th>推荐</th>
</tr>
</thead>
<tbody>
<tr>
<td>行为方式</td>
<td>主动</td>
<td>被动</td>
</tr>
<tr>
<td>意图</td>
<td>明确</td>
<td>模糊</td>
</tr>
<tr>
<td>个性化</td>
<td>弱</td>
<td>强</td>
</tr>
<tr>
<td>流量分布</td>
<td>马太效应</td>
<td>长尾效应</td>
</tr>
<tr>
<td>目标</td>
<td>快速满足</td>
<td>持续服务</td>
</tr>
<tr>
<td>评估指标</td>
<td>简明</td>
<td>复杂</td>
</tr>
</tbody>
</table>
</div>
<h4 id="推荐系统的工作原理"><a href="#推荐系统的工作原理" class="headerlink" title="推荐系统的工作原理"></a>推荐系统的工作原理</h4><ul>
<li><strong>社会化推荐</strong> 例如：向朋友咨询，社会化推荐，让好友给自己推荐物品</li>
<li><strong>基于内容的推荐</strong> 例如：打开搜索引擎，输入自己喜欢的演员的名字，然后看看返回结果中还有什么电影是自己没看过的</li>
<li><strong>基于流行度的推荐</strong> 例如：查看票房排行榜</li>
<li><strong>基于协同过滤的推荐</strong> 例如：找到和自己历史兴趣相似的用户，看看他们最近在看什么电影</li>
</ul>
<h4 id="推荐系统的作用"><a href="#推荐系统的作用" class="headerlink" title="推荐系统的作用"></a>推荐系统的作用</h4><ul>
<li>高效连接用户和物品</li>
<li>提高用户停留时间和用户活跃程度</li>
<li>有效的帮助产品实现其商业价值</li>
</ul>
<h4 id="推荐系统的应用场景"><a href="#推荐系统的应用场景" class="headerlink" title="推荐系统的应用场景"></a>推荐系统的应用场景</h4><ul>
<li>头条</li>
<li>淘宝京东</li>
<li>抖音</li>
</ul>
<h4 id="推荐系统和Web项目的区别"><a href="#推荐系统和Web项目的区别" class="headerlink" title="推荐系统和Web项目的区别"></a>推荐系统和Web项目的区别</h4><ul>
<li>通过信息过滤实现目标提升 V.S. 稳定的信息流通系统<ul>
<li>web项目: 处理复杂业务逻辑，处理高并发，为用户构建一个稳定的信息流通服务</li>
<li>推荐系统: 追求指标增长， 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li>
</ul>
</li>
<li>确定 V.S. 不确定思维<ul>
<li>web项目: 对结果有确定预期</li>
<li>推荐系统: 结果是概率问题</li>
</ul>
</li>
</ul>
<h4 id="推荐系统要素"><a href="#推荐系统要素" class="headerlink" title="推荐系统要素"></a>推荐系统要素</h4><ul>
<li>UI 和 UE(前端界面)</li>
<li>数据 (Lambda架构)</li>
<li>业务知识</li>
<li>算法</li>
</ul>
<h4 id="推荐系统架构"><a href="#推荐系统架构" class="headerlink" title="推荐系统架构"></a>推荐系统架构</h4><h5 id="推荐系统整体架构"><a href="#推荐系统整体架构" class="headerlink" title="推荐系统整体架构"></a>推荐系统整体架构</h5><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154506.png"/></p>
<h5 id="大数据Lambda架构"><a href="#大数据Lambda架构" class="headerlink" title="大数据Lambda架构"></a>大数据Lambda架构</h5><ul>
<li>Lambda架构是由实时大数据处理框架Storm的作者Nathan Marz提出的一个实时大数据处理框架。</li>
<li>Lambda架构的将离线计算和实时计算整合，设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。</li>
<li>分层架构<ul>
<li>批处理层（离线计算）<ul>
<li>数据不可变, 可进行任何计算, 可水平扩展</li>
<li>高延迟 几分钟~几小时(计算量和数据量不同)</li>
<li>日志收集： Flume</li>
<li>分布式存储： Hadoop</li>
<li>分布式计算： Hadoop、Spark</li>
<li>视图存储数据库<ul>
<li>nosql(HBase/Cassandra)</li>
<li>Redis/memcache</li>
<li>MySQL</li>
</ul>
</li>
</ul>
</li>
<li>实时处理层<ul>
<li>流式处理, 持续计算</li>
<li>存储和分析某个窗口期内的数据（一段时间的热销排行，实时热搜等）</li>
<li>实时数据收集 flume-日志收集 &amp; kafka-消息队列（数据的实时收集）</li>
<li>实时数据分析 spark streaming/storm/flink</li>
</ul>
</li>
<li>服务层<ul>
<li>支持随机读</li>
<li>需要在非常短的时间内返回结果</li>
<li>读取批处理层和实时处理层结果并对其归并</li>
</ul>
</li>
</ul>
</li>
<li><p>Lambda架构图</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154322.png"/></p>
</li>
</ul>
<h5 id="推荐算法架构"><a href="#推荐算法架构" class="headerlink" title="推荐算法架构"></a>推荐算法架构</h5><ul>
<li>召回阶段 (海选)<ul>
<li>召回决定了最终推荐结果的天花板</li>
<li>常用算法:<ul>
<li>协同过滤</li>
<li>基于内容</li>
</ul>
</li>
</ul>
</li>
<li>排序阶段 （精选）<ul>
<li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li>
<li>CTR预估 (点击率预估 使用LR算法) 估计用户是否会点击某个商品 需要用户的点击数据</li>
</ul>
</li>
<li>过滤<ul>
<li>法律规则</li>
<li>没有库存问题</li>
<li>反复曝光都没看</li>
</ul>
</li>
<li><p>规则调整</p>
<ul>
<li>商业合作</li>
<li>政策问题</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154421.jpeg"/></p>
</li>
</ul>
<h5 id="推荐系统的整体架构"><a href="#推荐系统的整体架构" class="headerlink" title="推荐系统的整体架构"></a>推荐系统的整体架构</h5><p> 推荐系统业务架构</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154452.png"/></p>
<p>  推荐系统技术架构</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227154427.png"/> </p>
]]></content>
      <categories>
        <category>大数据推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统简介</tag>
        <tag>推荐系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title>五大常用算法</title>
    <url>/2020/01/13/%E4%BA%94%E5%A4%A7%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>据说有人归纳了计算机的五大常用算法，它们是贪婪算法，动态规划算法，分治算法，回溯算法以及分支限界算法。这五个算法是有很多应用场景的，最优化问题大多可以利用这些算法解决。算法的本质就是解决问题。当数据量比较小时，其实根本就不需要什么算法，写一些for循环完全就可以很快速的搞定了，但是当数据量比较大，场景比较复杂的时候，算法就尤为重要了，本文先归纳这几个算法及应用场景，随后在细细品味。</p>
<a id="more"></a>
<h4 id="穷举法"><a href="#穷举法" class="headerlink" title="穷举法"></a>穷举法</h4><h5 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h5><p>穷举法也叫枚举法， 在进行归纳推理时，如果逐个考察了某类事件的所有可能情况，因而得出一般结论，那么这结论是可靠的，这种归纳方法叫做枚举法。枚举法是利用计算机运算速度快、精确度高的特点，对要解决问题的所有可能情况，一个不漏地进行检验，从中找出符合要求的答案，因此枚举法是通过牺牲时间来换取答案的全面性 。穷举法属于暴力破解法， 暴力破解法，就是把所有条件，相关情况统统考虑进去，让计算机进行检索，指导得出与之所有条件符合的结果 。</p>
<h5 id="2-基本思想"><a href="#2-基本思想" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol>
<li>确定枚举对象、枚举范围和判定条件</li>
<li>枚举可能的解，验证是否是问题的解</li>
</ol>
<h5 id="3-应用实例"><a href="#3-应用实例" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>百钱买鸡问题</li>
<li>鸡兔同笼问题</li>
<li>搬砖块问题</li>
<li>猜数字</li>
<li>韩信点兵 </li>
</ol>
<h4 id="贪婪算法"><a href="#贪婪算法" class="headerlink" title="贪婪算法"></a>贪婪算法</h4><h5 id="1-定义-1"><a href="#1-定义-1" class="headerlink" title="1.定义"></a>1.定义</h5><p>贪婪算法(贪心算法)是指在对问题进行求解时，在每一步选择中都采取最好或者最优(即最有利)的选择，从而希望能够导致结果是最好或者最优的算法。贪婪算法所得到的结果往往不是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果。</p>
<h5 id="2-基本思想-1"><a href="#2-基本思想-1" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol>
<li><p>建立数学模型来描述问题</p>
</li>
<li><p>把求解的问题分成若干个子问题</p>
</li>
<li><p>对每一子问题求解，得到子问题的局部最优解</p>
</li>
<li><p>把子问题对应的局部最优解合成原来整个问题的一个近似最优解</p>
</li>
</ol>
<h5 id="3-应用实例-1"><a href="#3-应用实例-1" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>钱币找零问题 </li>
<li>区间调度问题</li>
<li>背包问题 </li>
<li>均分纸牌 </li>
<li>最大整数</li>
</ol>
<h4 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h4><h5 id="1-定义-2"><a href="#1-定义-2" class="headerlink" title="1.定义"></a>1.定义</h5><p> 动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种多阶段最优化决策解决问题的过程就称为动态规划。 </p>
<h5 id="2-基本思想-2"><a href="#2-基本思想-2" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol>
<li>将待求解的问题分解为若干个子问题（阶段）</li>
<li>按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息</li>
<li>在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解</li>
<li>依次解决各子问题，最后一个子问题就是初始问题的解。 </li>
</ol>
<h5 id="3-应用实例-2"><a href="#3-应用实例-2" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>数字三角形问题</li>
<li>找零钱问题</li>
<li>走方格问题</li>
<li>最长公共序列数</li>
</ol>
<h4 id="分治算法"><a href="#分治算法" class="headerlink" title="分治算法"></a>分治算法</h4><h5 id="1-定义-3"><a href="#1-定义-3" class="headerlink" title="1.定义"></a>1.定义</h5><p> 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。即一种分目标完成程序算法，简单问题可用二分法完成。 </p>
<h5 id="2-基本思想-3"><a href="#2-基本思想-3" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><ol>
<li>先把问题分解成几个子问题</li>
<li>求出这几个子问题的解法</li>
<li>再找到合适的方法，把它们组合成求整个问题的解法。</li>
<li>如果这些子问题还较大，难以解决，可以再把它们分成几个更小的子问题</li>
<li>以此类推，直至可以直接求出解为止</li>
</ol>
<h5 id="3-应用实例-3"><a href="#3-应用实例-3" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>找出伪币</li>
<li>二分搜索</li>
<li>汉诺塔</li>
<li>归并排序</li>
<li>快速排序</li>
<li>大整数乘法</li>
</ol>
<h4 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h4><h5 id="1-定义-4"><a href="#1-定义-4" class="headerlink" title="1.定义"></a>1.定义</h5><p> 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 </p>
<h5 id="2-基本思想-4"><a href="#2-基本思想-4" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><p> 从一条路往前走，能进则进，不能进则退回来，换一条路再试 </p>
<h5 id="3-应用实例-4"><a href="#3-应用实例-4" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>八皇后问题</li>
<li>图的着色问题 </li>
<li>装载问题 </li>
<li>批处理作业调度问题 </li>
<li>背包问题 </li>
<li>最大团问题 </li>
</ol>
<h4 id="分支限界算法"><a href="#分支限界算法" class="headerlink" title="分支限界算法"></a>分支限界算法</h4><h5 id="1-定义-5"><a href="#1-定义-5" class="headerlink" title="1.定义"></a>1.定义</h5><p>分支限界算法是按照广度优先的方式对解空间树（状态空间树）进行搜索，从而求得最优解的算法。</p>
<h5 id="2-基本思想-5"><a href="#2-基本思想-5" class="headerlink" title="2.基本思想"></a>2.基本思想</h5><p>在搜索的过程中，采用<strong>限界函数</strong>（bound function）估算所有子节点的目标函数的可能取值，从而选择使目标函数取极值（极大值或者极小值）的节点作为扩展结点（如果限界值没有超过目前的最优解，则剪枝）进行下一步搜索（重复 BFS -&gt; 计算所有子节点限界 -&gt; 选择最优子节点作为扩展结点的过程），从而不断调整搜索的方向，尽快找到问题的最优解。分支限界的思想类似于：图的广度优先搜索，树的层序遍历。</p>
<h5 id="3-应用实例-5"><a href="#3-应用实例-5" class="headerlink" title="3.应用实例"></a>3.应用实例</h5><ol>
<li>单源最短路径问题</li>
<li>装载问题</li>
<li>布线问题</li>
<li>0-1背包问题</li>
<li>最大团问题</li>
<li>旅行售货员问题</li>
</ol>
<h4 id="总结说明"><a href="#总结说明" class="headerlink" title="总结说明"></a>总结说明</h4><p>对于一个应用实例可能会有多种算法解决，算法是一种解决问题的思想，任意一个算法绝对不是一两篇文章可以讲清楚的。当然也不是通过一两道题目可以完全学会。学习算法的关键是<strong>用算法的思想去想问题，去解决实际问题</strong>，多刷题是养成算法思维解决问题的基础。</p>
<h4 id="学习算法方法"><a href="#学习算法方法" class="headerlink" title="学习算法方法"></a>学习算法方法</h4><h5 id="1-书籍"><a href="#1-书籍" class="headerlink" title="1.书籍"></a>1.书籍</h5><ol>
<li>数据结构</li>
<li>数据结构与算法分析 </li>
<li>算法导论</li>
</ol>
<h5 id="2-刷题"><a href="#2-刷题" class="headerlink" title="2.刷题"></a>2.刷题</h5><ol>
<li>牛客</li>
<li>LeeCode</li>
</ol>
<h5 id="3-在线视频课程"><a href="#3-在线视频课程" class="headerlink" title="3.在线视频课程"></a>3.在线视频课程</h5><ol>
<li>慕课</li>
<li>网易云课程（强烈推荐）</li>
</ol>
<h5 id="4-可视化工具"><a href="#4-可视化工具" class="headerlink" title="4.可视化工具"></a>4.可视化工具</h5><ul>
<li><a href="https://visualgo.net/" target="_blank" rel="noopener">visualgo 网址 </a> </li>
</ul>
<p>最重要的是耐心，自律，有毅力，坚持。</p>
<p>作为才入门的程序员，我已经沉浸在知识海洋中无法自拔，深深感受到了自己的渺小。</p>
]]></content>
      <categories>
        <category>计算机常用算法</category>
      </categories>
      <tags>
        <tag>计算机常用算法</tag>
        <tag>算法思想</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习</title>
    <url>/2020/01/13/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h4 id="什么是集成学习"><a href="#什么是集成学习" class="headerlink" title="什么是集成学习"></a>什么是集成学习</h4><p> 集成学习通过建立几个模型来解决单一预测问题。它的工作原理是<strong>生成多个分类器/模型</strong>，各自独立地学习和作出预测。<strong>这些预测最后结合成组合预测，因此优于任何一个单分类的做出预测。</strong> </p>
<a id="more"></a>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143703.png"/></p>
<h4 id="机器学习的两个核心任务"><a href="#机器学习的两个核心任务" class="headerlink" title="机器学习的两个核心任务"></a>机器学习的两个核心任务</h4><ul>
<li>任务一：<strong>如何优化训练数据</strong> —&gt; 主要用于<strong>解决欠拟合问题</strong></li>
<li>任务二：<strong>如何提升泛化性能</strong> —&gt; 主要用于<strong>解决过拟合问题</strong></li>
</ul>
<h4 id="集成学习中boosting和Bagging"><a href="#集成学习中boosting和Bagging" class="headerlink" title="集成学习中boosting和Bagging"></a>集成学习中boosting和Bagging</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143653.png"/> </p>
<p><strong>只要单分类器的表现不太差，集成学习的结果总是要好于单分类器的</strong></p>
<h4 id="Bagging集成原理"><a href="#Bagging集成原理" class="headerlink" title="Bagging集成原理"></a>Bagging集成原理</h4><p> 目标：把下面的圈和方块进行分类 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227153011.png"/> </p>
<p>实现过程：</p>
<p>1.采样不同数据集</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152903.png"/></p>
<p> 2.训练分类器 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152657.png"/> </p>
<ol>
<li><p>平权投票，获取最终结果 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152648.png"/></p>
<p>4.主要实现过程小结 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152622.png"/> </p>
</li>
</ol>
<h4 id="随机森林构造过程"><a href="#随机森林构造过程" class="headerlink" title="随机森林构造过程"></a>随机森林构造过程</h4><p>在机器学习中，<strong>随机森林是一个包含多个决策树的分类器</strong>，并且其输出的类别是由个别树输出的类别的众数而定。</p>
<p><strong>随机森林</strong> <strong>= Bagging +</strong> <strong>决策树</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143311.png"/></p>
<h4 id="随机森林api介绍"><a href="#随机森林api介绍" class="headerlink" title="随机森林api介绍"></a>随机森林api介绍</h4><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestClassifier(<span class="attribute">n_estimators</span>=10, <span class="attribute">criterion</span>=’gini’, <span class="attribute">max_depth</span>=None, <span class="attribute">bootstrap</span>=<span class="literal">True</span>, <span class="attribute">random_state</span>=None, <span class="attribute">min_samples_split</span>=2)</span><br><span class="line">	n_estimators：integer，optional（default = 10）森林里的树木数量120,200,300,500,800,1200</span><br><span class="line">	Criterion：string，可选（default =“gini”）分割特征的测量方法</span><br><span class="line">	max_depth：integer或None，可选（默认=无）树的最大深度 5,8,15,25,30</span><br><span class="line">	<span class="attribute">max_features</span>=<span class="string">"auto”,每个决策树的最大特征数量</span></span><br><span class="line"><span class="string">		If "</span>auto", then <span class="attribute">max_features</span>=sqrt(n_features).</span><br><span class="line">		<span class="keyword">If</span> <span class="string">"sqrt"</span>, then <span class="attribute">max_features</span>=sqrt(n_features)(same as <span class="string">"auto"</span>).</span><br><span class="line">		<span class="keyword">If</span> <span class="string">"log2"</span>, then <span class="attribute">max_features</span>=log2(n_features).</span><br><span class="line">		<span class="keyword">If</span> None, then <span class="attribute">max_features</span>=n_features.</span><br><span class="line">	bootstrap：boolean，optional（default = <span class="literal">True</span>）是否在构建树时使用放回抽样</span><br><span class="line">	min_samples_split:节点划分最少样本数</span><br><span class="line">	min_samples_leaf:叶子节点的最小样本数</span><br><span class="line">超参数：n_estimator, max_depth, min_samples_split,min_samples_leaf</span><br></pre></td></tr></table></figure>
<h4 id="随机森林预测案例"><a href="#随机森林预测案例" class="headerlink" title="随机森林预测案例"></a>随机森林预测案例</h4><ul>
<li>实例化随机森林</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 随机森林去进行预测</span></span><br><span class="line">rf = RandomForestClassifier()</span><br></pre></td></tr></table></figure>
<ul>
<li>定义超参数的选择列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">param = &#123;<span class="string">"n_estimators"</span>: [<span class="number">120</span>,<span class="number">200</span>,<span class="number">300</span>,<span class="number">500</span>,<span class="number">800</span>,<span class="number">1200</span>], <span class="string">"max_depth"</span>: [<span class="number">5</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">30</span>]&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>使用GridSearchCV进行网格搜索</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 超参数调优</span></span><br><span class="line">gc = GridSearchCV(rf, param_grid=param, cv=<span class="number">2</span>)</span><br><span class="line">gc.fit(x_train, y_train)</span><br><span class="line">print(<span class="string">"随机森林预测的准确率为："</span>, gc.score(x_test, y_test))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意</p>
<ul>
<li>随机森林的建立过程</li>
<li>树的深度、树的个数等需要进行超参数调优</li>
</ul>
</blockquote>
<h4 id="bagging集成优点"><a href="#bagging集成优点" class="headerlink" title="bagging集成优点"></a>bagging集成优点</h4><p><strong>Bagging + 决策树/线性回归/逻辑回归/深度学习… = bagging集成学习方法</strong></p>
<p>经过上面方式组成的集成学习方法:</p>
<ol>
<li><strong>均可在原有算法上提高约2%左右的泛化正确率</strong></li>
<li><strong>简单, 方便, 通用</strong></li>
</ol>
<h4 id="boosting集成原理"><a href="#boosting集成原理" class="headerlink" title="boosting集成原理"></a>boosting集成原理</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152607.png"/> </p>
<p><strong>随着学习的积累从弱到强</strong></p>
<p><strong>简而言之：每新加入一个弱学习器，整体能力就会得到提升</strong></p>
<p>代表算法：Adaboost，GBDT，XGBoost</p>
<h4 id="boosting实现过程"><a href="#boosting实现过程" class="headerlink" title="boosting实现过程"></a>boosting实现过程</h4><p>1.<strong>训练第一个学习器</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152557.png"/></p>
<p> 2.<strong>调整数据分布</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143933.png"/></p>
<p> 3.<strong>训练第二个学习器</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227152614.png"/></p>
<p> 4.<strong>再次调整数据分布</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143839.png"/></p>
<p> 5.<strong>依次训练学习器，调整数据分布</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143802.png"/></p>
<p> 6.<strong>整体过程实现</strong></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143754.png"/> </p>
<blockquote>
<p>关键点：<br>如何确认投票权重？<br>如何调整数据分布？</p>
</blockquote>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143743.png"/></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143717.png"/>  </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143710.png"/> </p>
<h4 id="bagging与boosting比较"><a href="#bagging与boosting比较" class="headerlink" title="bagging与boosting比较"></a>bagging与boosting比较</h4><blockquote>
<p>区别一：数据方面</p>
<p>​    Bagging：对数据进行采样训练；</p>
<p>​    Boosting：根据前一轮学习结果调整数据的重要性。</p>
<p>区别二：投票方面</p>
<p>​    Bagging：所有学习器平权投票；</p>
<p>​    Boosting：对学习器进行加权投票。</p>
<p>区别三：学习顺序</p>
<p>​    Bagging的学习是并行的，每个学习器没有依赖关系；</p>
<p>​    Boosting学习是串行，学习有先后顺序。</p>
<p>区别四：主要作用</p>
<p>​    Bagging主要用于提高泛化性能（解决过拟合，也可以说降低方差）</p>
<p>​    Boosting主要用于提高训练精度 （解决欠拟合，也可以说降低偏差）</p>
</blockquote>
<h4 id="boostingAPI介绍"><a href="#boostingAPI介绍" class="headerlink" title="boostingAPI介绍"></a>boostingAPI介绍</h4><figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">from sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">api链接<span class="symbol">:https</span><span class="symbol">://scikit-learn</span>.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html<span class="comment">#sklearn.ensemble.AdaBoostClassifier</span></span><br></pre></td></tr></table></figure>
<h4 id="梯度提升决策树-GBDT"><a href="#梯度提升决策树-GBDT" class="headerlink" title="梯度提升决策树 GBDT"></a>梯度提升决策树 GBDT</h4><h5 id="1-GBDT定义"><a href="#1-GBDT定义" class="headerlink" title="1.GBDT定义"></a>1.GBDT定义</h5><p>梯度提升决策树(GBDT Gradient Boosting Decision Tree) <strong>是一种迭代的决策树算法</strong>，<strong>该算法由多棵决策树组成，所有树的结论累加起来做最终答案。</strong>它在被提出之初就被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。</p>
<p><strong>GBDT = 梯度下降 + Boosting + 决策树</strong></p>
<h5 id="2-GBDT执行流程"><a href="#2-GBDT执行流程" class="headerlink" title="2.GBDT执行流程"></a>2.GBDT执行流程</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143646.png"/></p>
<p>如果上式中的$h_i(x)=$决策树模型,则上式就变为:</p>
<p><strong>GBDT = 梯度下降 + Boosting + 决策树</strong></p>
<h5 id="3-GBDT案例"><a href="#3-GBDT案例" class="headerlink" title="3.GBDT案例"></a>3.GBDT案例</h5><p>预测编号5的身高：<br>| 编号 | 年龄(岁) | 体重(KG) | 身高(M) |<br>| —— | ———— | ———— | ———- |<br>| 1    | 5        | 20       | 1.1     |<br>| 2    | 7        | 30       | 1.3     |<br>| 3    | 21       | 70       | 1.7     |<br>| 4    | 30       | 60       | 1.8     |<br>| 5    | 25       | 65       | ?       |</p>
<p>第一步：计算损失函数,并求出第一个预测值:</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143637.png"/> </p>
<p> 第二步：求解划分点 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143623.png"/></p>
<p> 得出:年龄21为划分点的方差=0.01+0.0025=0.0125</p>
<p>第三步：通过调整后目标值,求解得出h1(x)</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143605.png"/></p>
<p>  第四步：求解h2(x) </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143346.png"/></p>
<p> 得出结果:</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143327.png"/> 编号5身高 = 1.475 + 0.03 + 0.275 = 1.78</p>
<h5 id="4-GBDT主要执行思想"><a href="#4-GBDT主要执行思想" class="headerlink" title="4.GBDT主要执行思想"></a>4.GBDT主要执行思想</h5><p>1.使用梯度下降法优化代价函数；</p>
<p>2.使用一层决策树作为弱学习器，负梯度作为目标值；</p>
<p>3.利用boosting思想进行集成。</p>
<h4 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h4><p> <strong>XGBoost= 二阶泰勒展开+boosting+决策树+正则化</strong> </p>
<p><strong>Boosting</strong>：XGBoost使用Boosting提升思想对多个弱学习器进行迭代式学习</p>
<p><strong>二阶泰勒展开</strong>：每一轮学习中，XGBoost对损失函数进行二阶泰勒展开，使用一阶和二阶梯度进行优化。</p>
<p><strong>决策树</strong>：在每一轮学习中，XGBoost使用决策树算法作为弱学习进行优化。</p>
<p><strong>正则化</strong>：在优化过程中XGBoost为防止过拟合，在损失函数中加入惩罚项，限制决策树的叶子节点个数以及决策树叶子节点的值。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img1/20200227143320.png"/> </p>
<p>泰勒展开越多，计算结果越精确</p>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>监督学习算法</tag>
        <tag>集成学习</tag>
        <tag>欠拟合过拟合</tag>
        <tag>bagging集成</tag>
        <tag>boosting集成</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程-特征提取</title>
    <url>/2020/01/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/</url>
    <content><![CDATA[<h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><ul>
<li><p>定义</p>
<p><strong>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</strong></p>
<blockquote>
<p>注：特征值化是为了计算机更好的去理解数据</p>
</blockquote>
<ul>
<li>特征提取分类:<ul>
<li>字典特征提取(特征离散化)</li>
<li>文本特征提取</li>
<li>图像特征提取（深度学习将介绍）</li>
</ul>
</li>
</ul>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>特征提取API</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">sklearn</span><span class="selector-class">.feature_extraction</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h4><p><strong>作用：对字典数据进行特征值化</strong></p>
<ul>
<li>sklearn.feature_extraction.DictVectorizer(sparse=True,…)<ul>
<li>DictVectorizer.fit_transform(X)<ul>
<li>X：字典或者包含字典的迭代器返回值</li>
<li>返回sparse矩阵</li>
</ul>
</li>
<li>DictVectorizer.get_feature_names() 返回类别名称</li>
</ul>
</li>
</ul>
<p><strong>应用：</strong></p>
<ul>
<li>实例化类DictVectorizer</li>
<li>调用fit_transform方法输入数据并转换（注意返回格式）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dict_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对字典类型的数据进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [&#123;<span class="string">'city'</span>: <span class="string">'北京'</span>,<span class="string">'temperature'</span>:<span class="number">100</span>&#125;, </span><br><span class="line">            &#123;<span class="string">'city'</span>: <span class="string">'上海'</span>,<span class="string">'temperature'</span>:<span class="number">60</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'city'</span>: <span class="string">'深圳'</span>,<span class="string">'temperature'</span>:<span class="number">30</span>&#125;]</span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"返回的结果:\n"</span>, data)</span><br><span class="line">    <span class="comment"># 打印特征名字</span></span><br><span class="line">    print(<span class="string">"特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Nonepython</span><br></pre></td></tr></table></figure>
<p> 注意观察没有加上sparse=False参数的结果 </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">返回的结果:</span><br><span class="line">   (<span class="number">0</span>, <span class="number">1</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">0</span>, <span class="number">3</span>)    <span class="number">100.0</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">0</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">1</span>, <span class="number">3</span>)    <span class="number">60.0</span></span><br><span class="line">  (<span class="number">2</span>, <span class="number">2</span>)    <span class="number">1.0</span></span><br><span class="line">  (<span class="number">2</span>, <span class="number">3</span>)    <span class="number">30.0</span></span><br><span class="line">特征名字：</span><br><span class="line"> [<span class="string">'city=上海'</span>, <span class="string">'city=北京'</span>, <span class="string">'city=深圳'</span>, <span class="string">'temperature'</span>]</span><br></pre></td></tr></table></figure>
<p> 这个结果并不是我们想要看到的，所以加上参数，得到想要的结果： </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">返回的结果:</span><br><span class="line"> [[   <span class="number">0.</span>    <span class="number">1.</span>    <span class="number">0.</span>  <span class="number">100.</span>]</span><br><span class="line"> [   <span class="number">1.</span>    <span class="number">0.</span>    <span class="number">0.</span>   <span class="number">60.</span>]</span><br><span class="line"> [   <span class="number">0.</span>    <span class="number">0.</span>    <span class="number">1.</span>   <span class="number">30.</span>]]</span><br><span class="line">特征名字：</span><br><span class="line"> [<span class="string">'city=上海'</span>, <span class="string">'city=北京'</span>, <span class="string">'city=深圳'</span>, <span class="string">'temperature'</span>]</span><br></pre></td></tr></table></figure>
<p>之前在学习pandas中的离散化的时候，也实现了类似的效果。我们把这个处理数据的技巧叫做”one-hot“编码</p>
<p> <strong>对于特征当中存在类别信息的我们都会做one-hot编码处理</strong> 。</p>
<h4 id="文本特征提取"><a href="#文本特征提取" class="headerlink" title="文本特征提取"></a>文本特征提取</h4><p><strong>作用：对文本数据进行特征值化</strong></p>
<ul>
<li><strong>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</strong><ul>
<li>返回词频矩阵</li>
<li>CountVectorizer.fit_transform(X)<ul>
<li>X:文本或者包含文本字符串的可迭代对象</li>
<li>返回值:返回sparse矩阵</li>
</ul>
</li>
<li>CountVectorizer.get_feature_names() 返回值:单词列表</li>
</ul>
</li>
<li><strong>sklearn.feature_extraction.text.TfidfVectorizer</strong></li>
</ul>
<p><strong>应用：</strong></p>
<ul>
<li>实例化类CountVectorizer</li>
<li>调用fit_transform方法输入数据并转换 （注意返回格式，利用toarray()进行sparse矩阵转换array数组）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_count_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对文本进行特征抽取，countvetorizer</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"life is short,i like like python"</span>, <span class="string">"life is too long,i dislike python"</span>]</span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False) # 注意,没有sparse这个参数</span></span><br><span class="line">    transfer = CountVectorizer()</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p>返回结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[<span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line"> [<span class="string">'dislike'</span>, <span class="string">'is'</span>, <span class="string">'life'</span>, <span class="string">'like'</span>, <span class="string">'long'</span>, <span class="string">'python'</span>, <span class="string">'short'</span>, <span class="string">'too'</span>]</span><br></pre></td></tr></table></figure>
<p>不支持单个中文字，中文未分词，所以我们要对中文进行分词处理 </p>
<h4 id="jieba分词处理"><a href="#jieba分词处理" class="headerlink" title="jieba分词处理"></a>jieba分词处理</h4><ul>
<li>jieba.cut()：返回词语组成的生成器</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 需要安装下jieba库</span></span><br><span class="line">pip3 install jieba</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong>：</p>
<ul>
<li>准备句子，利用jieba.cut进行分词</li>
<li>实例化CountVectorizer</li>
<li>将分词结果变成字符串当作fit_transform的输入值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行分词</span></span><br><span class="line"><span class="string">    "我爱北京天安门"————&gt;"我 爱 北京 天安门"</span></span><br><span class="line"><span class="string">    :param text:</span></span><br><span class="line"><span class="string">    :return: text</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 用结巴对中文字符串进行分词</span></span><br><span class="line">    text = <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_chinese_count_demo2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span>,</span><br><span class="line">            <span class="string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span>,</span><br><span class="line">            <span class="string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span>]</span><br><span class="line">    <span class="comment"># 将原始数据转换成分好词的形式</span></span><br><span class="line">    text_list = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        text_list.append(cut_word(sent))</span><br><span class="line">    print(text_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False)</span></span><br><span class="line">    transfer = CountVectorizer()</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(text_list)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p> 返回结果： </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Building prefix dict <span class="keyword">from</span> the <span class="keyword">default</span> <span class="built_in">dictionary</span> ...</span><br><span class="line">Dumping model to file cache /var/folders/mz/tzf2l3sx4rgg6qpglfb035_r0000gn/T/jieba.cache</span><br><span class="line">Loading model cost <span class="number">1.032</span> seconds.</span><br><span class="line">[<span class="string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span>, <span class="string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span>, <span class="string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span>]</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">4</span> <span class="number">3</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]]</span><br><span class="line">返回特征名字：</span><br><span class="line"> [<span class="string">'一种'</span>, <span class="string">'不会'</span>, <span class="string">'不要'</span>, <span class="string">'之前'</span>, <span class="string">'了解'</span>, <span class="string">'事物'</span>, <span class="string">'今天'</span>, <span class="string">'光是在'</span>, <span class="string">'几百万年'</span>, <span class="string">'发出'</span>, <span class="string">'取决于'</span>, <span class="string">'只用'</span>, <span class="string">'后天'</span>, <span class="string">'含义'</span>, <span class="string">'大部分'</span>, <span class="string">'如何'</span>, <span class="string">'如果'</span>, <span class="string">'宇宙'</span>, <span class="string">'我们'</span>, <span class="string">'所以'</span>, <span class="string">'放弃'</span>, <span class="string">'方式'</span>, <span class="string">'明天'</span>, <span class="string">'星系'</span>, <span class="string">'晚上'</span>, <span class="string">'某样'</span>, <span class="string">'残酷'</span>, <span class="string">'每个'</span>, <span class="string">'看到'</span>, <span class="string">'真正'</span>, <span class="string">'秘密'</span>, <span class="string">'绝对'</span>, <span class="string">'美好'</span>, <span class="string">'联系'</span>, <span class="string">'过去'</span>, <span class="string">'还是'</span>, <span class="string">'这样'</span>]</span><br></pre></td></tr></table></figure>
<h4 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h4><ul>
<li>TF-IDF的主要思想是：如果<strong>某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现</strong>，则认为此词或者短语具有很好的类别区分能力，能代表文章的主题，适合用来分类。</li>
<li><strong>TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。</strong>提取文章的标签（主题）。</li>
</ul>
<h5 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h5><ul>
<li>词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率</li>
<li>逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以<strong>由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222180055.png"/></p>
<p> 最终得出结果可以理解为重要程度。 </p>
<p><strong>tfidf越大越能代表文章的主题</strong></p>
<figure class="highlight lsl"><table><tr><td class="code"><pre><span class="line">举例：</span><br><span class="line">假如一篇文章的总词语数是<span class="number">100</span>个，而词语<span class="string">"非常"</span>出现了<span class="number">5</span>次，那么<span class="string">"非常"</span>一词在该文件中的词频就是<span class="number">5</span>/<span class="number">100</span>=<span class="number">0.05</span>。</span><br><span class="line">而计算文件频率（IDF）的方法是以文件集的文件总数，除以出现<span class="string">"非常"</span>一词的文件数。</span><br><span class="line">所以，如果<span class="string">"非常"</span>一词在<span class="number">1</span>,<span class="number">0000</span>份文件出现过，而文件总数是<span class="number">10</span>,<span class="number">000</span>,<span class="number">000</span>份的话，</span><br><span class="line">其逆向文件频率就是lg（<span class="number">10</span>,<span class="number">000</span>,<span class="number">000</span> / <span class="number">1</span>,<span class="number">0000</span>）=<span class="number">3</span>。</span><br><span class="line">最后<span class="string">"非常"</span>对于这篇文档的tf-idf的分数为<span class="number">0.05</span> * <span class="number">3</span>=<span class="number">0.15</span></span><br></pre></td></tr></table></figure>
<h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行分词</span></span><br><span class="line"><span class="string">    "我爱北京天安门"————&gt;"我 爱 北京 天安门"</span></span><br><span class="line"><span class="string">    :param text:</span></span><br><span class="line"><span class="string">    :return: text</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 用结巴对中文字符串进行分词</span></span><br><span class="line">    text = <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_chinese_tfidf_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对中文进行特征抽取</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span>,</span><br><span class="line">            <span class="string">"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span>,</span><br><span class="line">            <span class="string">"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span>]</span><br><span class="line">    <span class="comment"># 将原始数据转换成分好词的形式</span></span><br><span class="line">    text_list = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        text_list.append(cut_word(sent))</span><br><span class="line">    print(text_list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1、实例化一个转换器类</span></span><br><span class="line">    <span class="comment"># transfer = CountVectorizer(sparse=False)</span></span><br><span class="line">    <span class="comment"># 剔除'一种', '不会', '不要'这些词没有说明代表意义，减少计算</span></span><br><span class="line">    transfer = TfidfVectorizer(stop_words=[<span class="string">'一种'</span>, <span class="string">'不会'</span>, <span class="string">'不要'</span>])</span><br><span class="line">    <span class="comment"># 2、调用fit_transform</span></span><br><span class="line">    data = transfer.fit_transform(text_list)</span><br><span class="line">    print(<span class="string">"文本特征抽取的结果：\n"</span>, data.toarray())</span><br><span class="line">    print(<span class="string">"返回特征名字：\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Building prefix dict <span class="keyword">from</span> the <span class="keyword">default</span> <span class="built_in">dictionary</span> ...</span><br><span class="line">Loading model <span class="keyword">from</span> cache /var/folders/mz/tzf2l3sx4rgg6qpglfb035_r0000gn/T/jieba.cache</span><br><span class="line">Loading model cost <span class="number">0.856</span> seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">[<span class="string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span>, <span class="string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span>, <span class="string">'如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span>]</span><br><span class="line">文本特征抽取的结果：</span><br><span class="line"> [[ <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.43643578</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.43643578</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.43643578</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.21821789</span>  <span class="number">0.21821789</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.21821789</span></span><br><span class="line">   <span class="number">0.</span>        ]</span><br><span class="line"> [ <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.2410822</span>   <span class="number">0.2410822</span></span><br><span class="line">   <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.2410822</span>   <span class="number">0.55004769</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.2410822</span>   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.48216441</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.2410822</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.2410822</span> ]</span><br><span class="line"> [ <span class="number">0.</span>          <span class="number">0.644003</span>    <span class="number">0.48300225</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.16100075</span>  <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.16100075</span></span><br><span class="line">   <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.12244522</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span></span><br><span class="line">   <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.3220015</span>   <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span>          <span class="number">0.16100075</span>  <span class="number">0.</span>          <span class="number">0.</span></span><br><span class="line">   <span class="number">0.</span>        ]]</span><br><span class="line">返回特征名字：</span><br><span class="line">[<span class="string">'之前'</span>, <span class="string">'了解'</span>, <span class="string">'事物'</span>, <span class="string">'今天'</span>, <span class="string">'光是在'</span>, <span class="string">'几百万年'</span>, <span class="string">'发出'</span>, <span class="string">'取决于'</span>, <span class="string">'只用'</span>, <span class="string">'后天'</span>, <span class="string">'含义'</span>, <span class="string">'大部分'</span>, <span class="string">'如何'</span>, <span class="string">'如果'</span>, <span class="string">'宇宙'</span>, <span class="string">'我们'</span>, <span class="string">'所以'</span>, <span class="string">'放弃'</span>, <span class="string">'方式'</span>, <span class="string">'明天'</span>, <span class="string">'星系'</span>, <span class="string">'晚上'</span>, <span class="string">'某样'</span>, <span class="string">'残酷'</span>, <span class="string">'每个'</span>, <span class="string">'看到'</span>, <span class="string">'真正'</span>, <span class="string">'秘密'</span>, <span class="string">'绝对'</span>, <span class="string">'美好'</span>, <span class="string">'联系'</span>, <span class="string">'过去'</span>, <span class="string">'还是'</span>, <span class="string">'这样'</span>]</span><br></pre></td></tr></table></figure>
<h5 id="Tf-idf的重要性"><a href="#Tf-idf的重要性" class="headerlink" title="Tf-idf的重要性"></a>Tf-idf的重要性</h5><p> <strong>分类机器学习算法进行文章分类中前期数据处理方式</strong> </p>
<p>举例：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">文章库中  <span class="number">1000</span>篇文章</span><br><span class="line">的  在 <span class="number">1000</span> 篇文章中都出现过</span><br><span class="line">python  在<span class="number">100</span> 文章中出现过</span><br><span class="line">java       在 <span class="number">100</span> 文章中出现过</span><br><span class="line"></span><br><span class="line">idf(的)  = lg(<span class="number">1000</span>/<span class="number">1000</span>)  = <span class="number">0</span></span><br><span class="line">idf(python) = lg(<span class="number">1000</span>/<span class="number">100</span>) = <span class="number">1</span></span><br><span class="line">idf(java) = lg(<span class="number">1000</span>/<span class="number">100</span>) = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">文章<span class="number">1</span> python  出现了 <span class="number">100</span>次，java也出现了<span class="number">10</span>次， 文章<span class="number">1</span>中一共有一千个词</span><br><span class="line">文章<span class="number">2</span> python  出现了 <span class="number">10</span>次，java也出现了<span class="number">100</span>次， 文章<span class="number">2</span>中一共有一千个词</span><br><span class="line"></span><br><span class="line">tf(python , 文章<span class="number">1</span>) = <span class="number">100</span> /<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line">tf(java, 文章<span class="number">1</span>) = <span class="number">10</span>/<span class="number">1000</span> = <span class="number">0.01</span></span><br><span class="line">tf(python , 文章<span class="number">2</span>) = <span class="number">10</span> /<span class="number">1000</span> = <span class="number">00.1</span></span><br><span class="line">tf(java, 文章<span class="number">2</span>) = <span class="number">100</span>/<span class="number">1000</span> = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">tfidf(python , 文章<span class="number">1</span>) = <span class="number">0.1</span> * <span class="number">1</span>  = <span class="number">0.1</span></span><br><span class="line">tfidf(java, 文章<span class="number">1</span>) = <span class="number">0.01</span></span><br><span class="line">tfidf(的, 文章<span class="number">1</span>) = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">tfidf(python , 文章<span class="number">2</span>)  = <span class="number">00.1</span></span><br><span class="line">tfidf(java, 文章<span class="number">2</span>)  = <span class="number">0.1</span></span><br><span class="line">tfidf(的, 文章<span class="number">2</span>) = <span class="number">0</span></span><br><span class="line">相对而言，Java代表文章<span class="number">2</span>的主题，python代表文章<span class="number">1</span>的主题</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>特征工程</tag>
        <tag>特征提取</tag>
        <tag>jieba分词处理</tag>
        <tag>词袋模型</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树算法案例</title>
    <url>/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<h4 id="决策树算法API"><a href="#决策树算法API" class="headerlink" title="决策树算法API"></a>决策树算法API</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">tree</span>.<span class="title">DecisionTreeClassifier</span><span class="params">(criterion=’gini’, max_depth=None,random_state=None)</span></span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<ul>
<li>criterion</li>
<li>特征选择标准<ul>
<li>“gini”或者”entropy”，前者代表基尼系数，后者代表信息增益。一默认”gini”，即CART算法。</li>
</ul>
</li>
<li>min_samples_split</li>
<li>内部节点再划分所需最小样本数<ul>
<li>这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。我之前的一个项目例子，有大概10万样本，建立决策树时，我选择了min_samples_split=10。可以作为参考。</li>
</ul>
</li>
<li>min_samples_leaf</li>
<li>叶子节点最少样本数<ul>
<li>这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1，可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。之前的10万样本项目使用min_samples_leaf的值为5，仅供参考。</li>
</ul>
</li>
<li>max_depth</li>
<li>决策树最大深度<ul>
<li>决策树的最大深度，默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间</li>
</ul>
</li>
<li>random_state</li>
<li>随机数种子</li>
</ul>
<h4 id="案例-泰坦尼克号乘客生存预测"><a href="#案例-泰坦尼克号乘客生存预测" class="headerlink" title="案例-泰坦尼克号乘客生存预测"></a>案例-泰坦尼克号乘客生存预测</h4><h5 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h5><p>泰坦尼克号沉没是历史上最臭名昭着的沉船之一。1912年4月15日，在她的处女航中，泰坦尼克号在与冰山相撞后沉没，在2224名乘客和机组人员中造成1502人死亡。这场耸人听闻的悲剧震惊了国际社会，并为船舶制定了更好的安全规定。 造成海难失事的原因之一是乘客和机组人员没有足够的救生艇。尽管幸存下沉有一些运气因素，但有些人比其他人更容易生存，例如妇女，儿童和上流社会。 在这个案例中，我们要求您完成对哪些人可能存活的分析。特别是，我们要求您运用机器学习工具来预测哪些乘客幸免于悲剧。</p>
<p>案例：<a href="https://www.kaggle.com/c/titanic/overview" target="_blank" rel="noopener">https://www.kaggle.com/c/titanic/overview</a></p>
<p>我们提取到的数据集中的特征包括票的类别，是否存活，乘坐班次，年龄，登陆home.dest，房间，船和性别等。</p>
<p>数据：<a href="http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt" target="_blank" rel="noopener">http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt</a></p>
<p>经过观察数据得到:</p>
<ul>
<li><strong>1 乘坐班是指乘客班（1，2，3），是社会经济阶层的代表。</strong></li>
<li><strong>2 其中age数据存在缺失。</strong></li>
</ul>
<h5 id="步骤分析"><a href="#步骤分析" class="headerlink" title="步骤分析"></a>步骤分析</h5><ul>
<li><p>1.获取数据</p>
</li>
<li><p>2.数据基本处理</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">2.1</span> 确定特征值,目标值</span><br><span class="line"><span class="number">2.2</span> 缺失值处理</span><br><span class="line"><span class="number">2.3</span> 数据集划分</span><br></pre></td></tr></table></figure>
</li>
<li><p>3.特征工程(字典特征抽取)</p>
</li>
<li><p>4.机器学习(决策树)</p>
</li>
<li><p>5.模型评估</p>
</li>
</ul>
<h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据</span></span><br><span class="line">taitan = pd.read_csv(<span class="string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span>)</span><br><span class="line">taitan.describe()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据基本处理</span></span><br><span class="line"><span class="comment"># 2.1 确定特征值,目标值</span></span><br><span class="line">x = taitan[[<span class="string">"pclass"</span>, <span class="string">"age"</span>, <span class="string">"sex"</span>]]</span><br><span class="line">y = taitan[<span class="string">"survived"</span>]</span><br><span class="line"><span class="comment"># 2.2 缺失值处理</span></span><br><span class="line"><span class="comment"># inplace:True:会修改原数据，False:不替换修改原数据，生成新的对象</span></span><br><span class="line">x[<span class="string">'age'</span>].fillna(x[<span class="string">'age'</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 2.3 数据集划分</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程(字典特征抽取)</span></span><br><span class="line"><span class="comment"># 特征中出现类别符号，需要进行one-hot编码处理(DictVectorizer)</span></span><br><span class="line"><span class="comment"># x.to_dict(orient="records") 需要将数组特征转换成字典数据</span></span><br><span class="line"><span class="comment"># 对于x转换成字典数据x.to_dict(orient="records")</span></span><br><span class="line">transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">x_train = transfer.fit_transform(x_train.to_dict(orient=<span class="string">"records"</span>))</span><br><span class="line">x_test = transfer.fit_transform(x_test.to_dict(orient=<span class="string">"records"</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.机器学习(决策树)</span></span><br><span class="line">estimator = DecisionTreeClassifier(criterion=<span class="string">"entropy"</span>, max_depth=<span class="number">5</span>)</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 精确率</span></span><br><span class="line">estimator.score(x_test, y_test)</span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line">estimator.predict(x_test)</span><br></pre></td></tr></table></figure>
<h4 id="决策树可视化"><a href="#决策树可视化" class="headerlink" title="决策树可视化"></a>决策树可视化</h4><h5 id="保存树的结构到dot文件"><a href="#保存树的结构到dot文件" class="headerlink" title="保存树的结构到dot文件"></a>保存树的结构到dot文件</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sklearn.tree.export_graphviz() 该函数能够导出DOT格式</span></span><br><span class="line"><span class="comment"># tree.export_graphviz(estimator,out_file='tree.dot’,feature_names=[‘’,’’])</span></span><br><span class="line"></span><br><span class="line">export_graphviz(estimator, out_file=<span class="string">"./data/tree.dot"</span>, feature_names=[<span class="string">'age'</span>, <span class="string">'pclass=1st'</span>, <span class="string">'pclass=2nd'</span>, <span class="string">'pclass=3rd'</span>, <span class="string">'女性'</span>, <span class="string">'男性'</span>])</span><br></pre></td></tr></table></figure>
<h5 id="网站显示结构"><a href="#网站显示结构" class="headerlink" title="网站显示结构"></a>网站显示结构</h5><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">http:</span><span class="comment">//webgraphviz.com/</span></span><br></pre></td></tr></table></figure>
<h5 id="结果显示"><a href="#结果显示" class="headerlink" title="结果显示"></a>结果显示</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093538.png"/></p>
<h5 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h5><ul>
<li>优点：简单的理解和解释，树木可视化。</li>
<li>缺点：<strong>决策树学习者可以创建不能很好地推广数据的过于复杂的树，容易发生过拟合。</strong></li>
<li>改进：<ul>
<li>剪枝cart算法</li>
<li><strong>随机森林</strong>（集成学习的一种）</li>
</ul>
</li>
</ul>
<p><strong>注：企业重要决策，由于决策树很好的分析能力，在决策过程应用较多， 可以选择特征</strong></p>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>决策树可视化</tag>
        <tag>监督学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树算法</title>
    <url>/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><p>决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-else结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法。</p>
<p><strong>决策树：是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树</strong>。</p>
<a id="more"></a>
<h4 id="熵的概念"><a href="#熵的概念" class="headerlink" title="熵的概念"></a>熵的概念</h4><p> 物理学上，<strong>熵 Entropy</strong> 是“混乱”程度的量度。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093747.png"/> </p>
<p> <strong>系统越有序，熵值越低；系统越混乱或者分散，熵值越高</strong>。 </p>
<ul>
<li><h5 id="信息理论"><a href="#信息理论" class="headerlink" title="信息理论"></a>信息理论</h5><ol>
<li><p><strong>从信息的完整性上进行的描述：</strong></p>
<p> 当<strong>系统的有序状态一致时</strong>，数据越集中的地方熵值越小，数据越分散的地方熵值越大。 </p>
</li>
<li><p><strong>从信息的有序性上进行的描述：</strong></p>
<p>  当<strong>数据量一致时</strong>，<strong>系统越有序，熵值越低；系统越混乱或者分散，熵值越高</strong>。 </p>
</li>
</ol>
</li>
</ul>
<p>“<strong>信息熵</strong>“ (information entropy)是度量样本集合纯度最常用的一种指标。</p>
<p>假定当前样本集合 D 中第 k 类样本所占的比例为$p_k(k = 1, 2,. . . , |y|)$ ，</p>
<p>$p_k=\frac{C^k}{D}$, D为样本的所有数量，$C^k$为第$k$类样本的数量。</p>
<p>则 D的信息熵定义为(（log是以2为底）:</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093959.png"/></p>
<p> 其中：Ent(D) 的值越小，则 D 的纯度越高. </p>
<ul>
<li><h5 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h5></li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">假设我们没有看世界杯的比赛，但是想知道哪支球队会是冠军，</span><br><span class="line">我们只能猜测某支球队是或不是冠军，然后观众用对或不对来回答，</span><br><span class="line">我们想要猜测次数尽可能少，你会用什么方法？</span><br><span class="line"></span><br><span class="line">答案：</span><br><span class="line">二分法：</span><br><span class="line">假如有 <span class="number">16</span> 支球队，分别编号，先问是否在 <span class="number">1</span><span class="number">-8</span> 之间，如果是就继续问是否在 <span class="number">1</span><span class="number">-4</span> 之间，</span><br><span class="line">以此类推，直到最后判断出冠军球队是哪支。</span><br><span class="line">如果球队数量是 <span class="number">16</span>，我们需要问 <span class="number">4</span> 次来得到最后的答案。那么世界冠军这条消息的信息熵就是 <span class="number">4</span>。</span><br><span class="line"></span><br><span class="line">那么信息熵等于<span class="number">4</span>，是如何进行计算的呢？</span><br><span class="line">Ent(D) = -（p1 * logp1 + p2 * logp2 + ... + p16 * logp16），</span><br><span class="line">其中 p1, ..., p16 分别是这 <span class="number">16</span> 支球队夺冠的概率。</span><br><span class="line">当每支球队夺冠概率相等都是 <span class="number">1</span>/<span class="number">16</span> 的时：Ent(D) = -（<span class="number">16</span> * <span class="number">1</span>/<span class="number">16</span> * log1/<span class="number">16</span>） = <span class="number">4</span></span><br><span class="line">每个事件概率相同时，熵最大，这件事越不确定。</span><br><span class="line"></span><br><span class="line">篮球比赛里，有<span class="number">4</span>个球队 &#123;A,B,C,D&#125; ，获胜概率分别为&#123;<span class="number">1</span>/<span class="number">2</span>, <span class="number">1</span>/<span class="number">4</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>&#125;，求Ent(D)</span><br><span class="line">Ent(D)=<span class="number">7</span>/<span class="number">4</span></span><br></pre></td></tr></table></figure>
<h4 id="决策树的划分依据"><a href="#决策树的划分依据" class="headerlink" title="决策树的划分依据"></a>决策树的划分依据</h4><h5 id="1-信息增益"><a href="#1-信息增益" class="headerlink" title="1.信息增益"></a>1.信息增益</h5><p> <strong>信息增益：</strong>以某特征划分数据集前后的熵的差值。熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以<strong>使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏</strong>。 </p>
<p> <strong>信息增益 = entroy(前) - entroy(后)</strong> </p>
<figure class="highlight tp"><table><tr><td class="code"><pre><span class="line">注意：信息增益表示得知特征<span class="keyword">X</span>的信息而使得类<span class="keyword">Y</span>的信息熵减少的程度</span><br></pre></td></tr></table></figure>
<ul>
<li><p>定义与公式</p>
<p>假定离散属性a有 V 个可能的取值：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093755.png"/></p>
<p>若使用a来对样本集 $D$ 进行划分，则会产生 V 个分支结点，其中第$v$个分支结点包含了 $D$ 中所有在属性$a$上取值为$a^v$的样本，记为$D^v$. 我们可根据前面给出的信息熵公式计算出$D^v$的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重$\frac{|D^v|}{|D|}$</p>
<p>即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集 D 进行划分所获得的”信息增益” (information gain)</p>
<p>其中：</p>
<p>特征$a$对训练数据集D的信息增益$Gain(D,a)$，定义为<strong>集合D的信息熵$Ent(D)$</strong>与<strong>给定特征$a$条件下$D$的信息条件熵$Ent(D|a)$</strong>之差，即公式为：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093951.png"/></p>
<p>  信息熵的计算： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093943.png"/></p>
<p> 条件熵的计算： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093935.png"/></p>
<p>其中：</p>
<p>$D^v$ 表示$a$属性中第$v$个分支节点包含的样本数</p>
<p>$C^{kv}$ 表示$a$属性中第$v$个分支节点包含的样本数中，第$k$个类别下包含的样本数</p>
<p>一般而言，信息增益越大，则意味着<strong>使用属性 $a$ 来进行划分所获得的”纯度提升”越大</strong>。因此，我们可用信息增益来进行决策树的划分属性选择，著名的 <strong>ID3 决策树学习算法</strong> [Quinlan， 1986] 就是以<strong>信息增益为准则</strong>来选择划分属性。 </p>
</li>
<li><p>举例说明</p>
<p>如下图，第一列为论坛号码，第二列为性别，第三列为活跃度，最后一列用户是否流失。</p>
<p>我们要解决一个问题：<strong>性别和活跃度两个特征，哪个对用户流失影响更大</strong>？</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094202.png"/> </p>
<p>通过计算信息增益可以解决这个问题，统计上右表信息</p>
<p>其中Positive为正样本（已流失），Negative为负样本（未流失），下面的数值为不同划分下对应的人数。</p>
<p>可得到三个熵：</p>
<p><strong>a.计算类别信息熵</strong></p>
<p>整体熵：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093928.png"/></p>
<p> <strong>b.计算性别属性的信息熵(a=”性别”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093638.png"/></p>
<p> <strong>c.计算性别的信息增益(a=”性别”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093732.png"/> </p>
<p> <strong>b.计算活跃度属性的信息熵(a=”活跃度”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093802.png"/></p>
<p> <strong>c.计算活跃度的信息增益(a=”活跃度”)</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093724.png"/> </p>
<p> <strong>活跃度的信息增益比性别的信息增益大，也就是说，活跃度对用户流失的影响比性别大。</strong>在做特征选择或者数据分析的时候，我们应该重点考察活跃度这个指标。 </p>
</li>
</ul>
<h5 id="2-信息增益率"><a href="#2-信息增益率" class="headerlink" title="2.信息增益率"></a>2.信息增益率</h5><p> 在上面的介绍中，我们有意忽略了”编号”这一列.若把”编号”也作为一个候选划分属性，则根据信息增益公式可计算出它的信息增益为 0.9182，远大于其他候选划分属性。 </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">计算每个属性的信息熵过程中,我们发现,该属性的值为<span class="number">0</span>, 也就是其信息增益为<span class="number">0.9182</span>. 但是很明显这么分类,最后出现的结果不具有泛化效果.无法对新样本进行有效预测.</span><br></pre></td></tr></table></figure>
<p> 实际上，<strong>信息增益准则对可取值数目较多的属性有所偏好</strong>，为减少这种偏好可能带来的不利影响，著名的 <strong>C4.5 决策树算法 [Quinlan， 1993J 不直接使用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性</strong>。</p>
<p> <strong>增益率：</strong>增益率是用前面的信息增益$Gain(D, a)$和属性$a$对应的”固有值”(intrinsic value) [Quinlan , 1993J的比值来共同定义的。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093921.png"/></p>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">属性 a 的可能取值数目越多<span class="comment">(即 V 越大)</span>，则 IV<span class="comment">(a)</span> 的值通常会越大.</span><br></pre></td></tr></table></figure>
<p> <strong>上个案例中</strong></p>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">a.计算类别信息熵</span><br><span class="line">b.计算性别属性的信息熵<span class="comment">(性别、活跃度)</span></span><br><span class="line">c.计算活跃度的信息增益<span class="comment">(性别、活跃度)</span></span><br></pre></td></tr></table></figure>
<p> <strong>d.计算属性分裂信息度量</strong> </p>
<p> 用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息（instrisic information）。信息增益率用信息增益/内在信息，会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093717.png"/> </p>
<p> <strong>e.计算信息增益率</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093709.png"/> </p>
<p>活跃度的信息增益率更高一些，所以在构建决策树的时候，优先选择</p>
<p>通过这种方式，在选取节点的过程中，我们可以降低取值较多的属性的选取偏好。</p>
<p><strong>案例二</strong></p>
<p>如下图，第一列为天气，第二列为温度，第三列为湿度，第四列为风速，最后一列该活动是否进行。</p>
<p>我们要解决：<strong>根据下面表格数据，判断在对应天气下，活动是否会进行</strong>？</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094054.png"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094008.png"/> </p>
<p> 该数据集有四个属性，属性集合A={ 天气，温度，湿度，风速}， 类别标签有两个，类别集合L={进行，取消}。 </p>
<p> <strong>a.计算类别信息熵</strong> </p>
<p> 类别信息熵表示的是所有样本中各种类别出现的不确定性之和。根据熵的概念，熵越大，不确定性就越大，把事情搞清楚所需要的信息量就越多。 </p>
<script type="math/tex; mode=display">Ent(D)=-\frac{9}{14}log_2\frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940</script><p><strong>b.计算每个属性的信息熵</strong></p>
<p>每个属性的信息熵相当于一种条件熵。他表示的是在某种属性的条件下，各种类别出现的不确定性之和。属性的信息熵越大，表示这个属性中拥有的样本类别越不“纯”。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093911.png"/>  </p>
<p><strong>c.计算信息增益</strong></p>
<p>信息增益的 = 熵 - 条件熵，在这里就是 类别信息熵 - 属性信息熵，它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，当然，选择该属性就可以更快更好地完成我们的分类目标。</p>
<p> <strong>信息增益就是ID3算法的特征选择指标。</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093632.png"/></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">假设我们把上面表格<span class="number">1</span>的数据前面添加一列为<span class="string">"编号"</span>,取值(<span class="number">1</span>-<span class="number">-14</span>). 若把<span class="string">"编号"</span>也作为一个候选划分属性,则根据前面步骤: 计算每个属性的信息熵过程中,我们发现,该属性的值为<span class="number">0</span>, 也就是其信息增益为<span class="number">0.940</span>. 但是很明显这么分类,最后出现的结果不具有泛化效果.此时根据信息增益就无法选择出有效分类特征。所以，C4<span class="number">.5</span>选择使用信息增益率对ID3进行改进。</span><br></pre></td></tr></table></figure>
<p> <strong>d.计算属性分裂信息度量</strong></p>
<p>  用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息（instrisic information）。信息增益率用信息增益/内在信息，会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093701.png"/> </p>
<p> <strong>e.计算信息增益率</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093654.png"/></p>
<p> 天气的信息增益率最高，选择天气为分裂属性。发现分裂了之后，天气是“阴”的条件下，类别是”纯“的，所以把它定义为叶子节点，选择不“纯”的结点继续分裂。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094038.png"/> </p>
<p>在子结点当中重复过程1~5，直到所有的叶子结点足够”纯”。</p>
<p>现在我们来总结一下C4.5的算法流程</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(当前节点<span class="string">"不纯"</span>)：</span><br><span class="line">    <span class="number">1.</span>计算当前节点的类别熵(以类别取值计算)</span><br><span class="line">    <span class="number">2.</span>计算当前阶段的属性熵(按照属性取值吓得类别取值计算)</span><br><span class="line">    <span class="number">3.</span>计算信息增益</span><br><span class="line">    <span class="number">4.</span>计算各个属性的分裂信息度量</span><br><span class="line">    <span class="number">5.</span>计算各个属性的信息增益率</span><br><span class="line">end <span class="keyword">while</span></span><br><span class="line">当前阶段设置为叶子节点</span><br></pre></td></tr></table></figure>
<h5 id="3-基尼值和基尼指数"><a href="#3-基尼值和基尼指数" class="headerlink" title="3.基尼值和基尼指数"></a>3.基尼值和基尼指数</h5><p> CART 决策树 [Breiman et al., 1984] 使用”基尼指数” (Gini index)来选择划分属性。</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">CART</span> 是Classification <span class="keyword">and </span>Regression Tree的简称，这是一种著名的决策树学习算法,分类和回归任务都可用。</span><br></pre></td></tr></table></figure>
<p> <strong>基尼值Gini（D）：</strong>从数据集D中随机抽取两个样本，其类别标记不一致的概率。<strong>故，Gini（D）值越小，数据集D的纯度越高。</strong> </p>
<p> 数据集 D 的纯度可用基尼值来度量: </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093905.png"/></p>
<p> $*p_k=\frac{C^k}{D}$, D为样本的所有数量，$C^k$为第k类样本的数量。 </p>
<p> <strong>基尼指数Gini_index（D）：</strong>一般，选择使划分后基尼系数最小的属性作为最优化分属性。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093857.png"/></p>
<p><strong>案例</strong></p>
<p> 请根据下图列表，按照基尼指数的划分依据，做出决策树。 </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>序号</th>
<th>是否有房</th>
<th>婚姻状况</th>
<th>年收入</th>
<th>是否拖欠贷款</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>yes</td>
<td>single</td>
<td>125k</td>
<td>no</td>
</tr>
<tr>
<td>2</td>
<td>no</td>
<td>married</td>
<td>100k</td>
<td>no</td>
</tr>
<tr>
<td>3</td>
<td>no</td>
<td>single</td>
<td>70k</td>
<td>no</td>
</tr>
<tr>
<td>4</td>
<td>yes</td>
<td>married</td>
<td>120k</td>
<td>no</td>
</tr>
<tr>
<td>5</td>
<td>no</td>
<td>divorced</td>
<td>95k</td>
<td>yes</td>
</tr>
<tr>
<td>6</td>
<td>no</td>
<td>married</td>
<td>60k</td>
<td>no</td>
</tr>
<tr>
<td>7</td>
<td>yes</td>
<td>divorced</td>
<td>220k</td>
<td>no</td>
</tr>
<tr>
<td>8</td>
<td>no</td>
<td>single</td>
<td>85k</td>
<td>yes</td>
</tr>
<tr>
<td>9</td>
<td>no</td>
<td>married</td>
<td>75k</td>
<td>no</td>
</tr>
<tr>
<td>10</td>
<td>No</td>
<td>Single</td>
<td>90k</td>
<td>Yes</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><p>对数据集非序列标号属性{是否有房，婚姻状况，年收入}分别计算它们的Gini指数，<strong>取Gini指数最小的属性作为决策树的根节点属性。</strong> </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一次大循环</span><br></pre></td></tr></table></figure>
</li>
<li><p>根节点的Gini值为： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093849.png"/></p>
</li>
<li><p>当根据是否有房来进行划分时，Gini指数计算过程为： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093646.png"/></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094152.png"/>  </p>
</li>
<li><p>若按婚姻状况属性来划分，属性婚姻状况有三个可能的取值{married，single，divorced}，分别计算划分后的Gini系数增益。 </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093842.png"/></p>
<p>对比计算结果，根据婚姻状况属性来划分根节点时取Gini指数最小的分组作为划分结果，即:</p>
<p>{married} | {single,divorced} </p>
</li>
<li><p>同理可得年收入Gini： </p>
<p>对于年收入属性为数值型属性，首先需要对数据按升序排序，然后从小到大依次用相邻值的中间值作为分隔将样本划分为两组。例如当面对年收入为60和70这两个值时，我们算得其中间值为65。以中间值65作为分割点求出Gini指数。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094032.png"/> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227100629.png"/> </p>
<p>根据计算知道，三个属性划分根节点的指数最小的有两个：年收入属性和婚姻状况，他们的指数都为0.3。此时，选取首先出现的属性【married】作为第一次划分。 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第二次大循环</span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来，采用同样的方法，分别计算剩下属性，其中根节点的Gini系数为（此时是否拖欠贷款的各有3个records） </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093826.png"/> </p>
</li>
<li><p>对于是否有房属性，可得： </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093818.png"/></p>
</li>
<li><p>对于年收入属性则有： </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094025.png"/></p>
<p>经过如上流程，构建的决策树，如下图： </p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094102.png"/></p>
<p>总结一下CART的算法流程 </p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(当前节点<span class="string">"不纯"</span>)：</span><br><span class="line">    <span class="number">1</span>.遍历每个变量的每一种分割方式，找到最好的分割点</span><br><span class="line">    <span class="number">2</span>.分割成两个节点N1和N2</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">while</span></span><br><span class="line">每个节点足够“纯”为止</span><br></pre></td></tr></table></figure>
<h4 id="常见决策树的启发函数比较"><a href="#常见决策树的启发函数比较" class="headerlink" title="常见决策树的启发函数比较"></a>常见决策树的启发函数比较</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093810.png"/></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>提出时间</th>
<th>分支方式</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>ID3</td>
<td>1975</td>
<td>信息增益</td>
<td>ID3只能对离散属性的数据集构成决策树</td>
</tr>
<tr>
<td>C4.5</td>
<td>1993</td>
<td>信息增益率</td>
<td>优化后解决了ID3分支过程中总喜欢偏向选择值较多的 属性</td>
</tr>
<tr>
<td>CART</td>
<td>1984</td>
<td>Gini系数</td>
<td>可以进行分类和回归，可以处理离散属性，也可以处理连续属性</td>
</tr>
</tbody>
</table>
</div>
<h5 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h5><p><strong>存在的缺点</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"> (<span class="number">1</span>) ID3算法在选择根节点和各内部节点中的分支属性时，采用信息增益作为评价标准。信息增益的缺点是倾向于选择取值较多的属性，在有些情况下这类属性可能不会提供太多有价值的信息.</span><br><span class="line">(<span class="number">2</span>) ID3算法只能对描述属性为离散型属性的数据集构造决策树。</span><br></pre></td></tr></table></figure>
<h5 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h5><p><strong>1.用信息增益率来选择属性</strong></p>
<p>克服了用信息增益来选择属性时偏向选择值多的属性的不足。</p>
<p><strong>2.采用了一种后剪枝方法</strong></p>
<p>避免树的高度无节制的增长，避免过度拟合数据</p>
<p><strong>3.对于缺失值的处理</strong></p>
<p>在某些情况下，可供使用的数据可能缺少某些属性的值。假如〈x，c(x)〉是样本集S中的一个训练实例，但是其属性A的值A(x)未知。处理缺少属性值的一种策略是赋给它结点n所对应的训练实例中该属性的最常见值；</p>
<p>另外一种更复杂的策略是为A的每个可能值赋予一个概率。</p>
<p>例如，给定一个布尔属性A，如果结点n包含6个已知A=1和4个A=0的实例，那么A(x)=1的概率是0.6，而A(x)=0的概率是0.4。于是，实例x的$60\%$被分配到A=1的分支，$40\%$被分配到另一个分支。</p>
<p><strong>C4.5就是使用这种方法处理缺少的属性值</strong>。</p>
<p><strong>C4.5算法的优缺点</strong></p>
<p> 优点：产生的分类规则易于理解，准确率较高。</p>
<p> 缺点： 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。此外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</p>
<h5 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h5><p> CART算法相比C4.5算法的分类方法，采用了简化的二叉树模型，同时特征选择采用了近似的基尼系数来简化计算。 </p>
<p> <strong>C4.5不一定是二叉树，但CART一定是二叉树</strong> </p>
<h5 id="多变量决策树-multi-variate-decision-tree"><a href="#多变量决策树-multi-variate-decision-tree" class="headerlink" title="多变量决策树(multi-variate decision tree)"></a>多变量决策树(multi-variate decision tree)</h5><p> 同时，无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，<strong>分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。</strong>这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1 （了解一下）。</p>
<p> 如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。 </p>
<h4 id="决策树变量的两种类型"><a href="#决策树变量的两种类型" class="headerlink" title="决策树变量的两种类型"></a>决策树变量的两种类型</h4><ol>
<li>数字型（Numeric）：变量类型是整数或浮点数，如前面例子中的“年收入”。用“&gt;=”，“&gt;”,“&lt;”或“&lt;=”作为分割条件（排序后，利用已有的分割情况，可以优化分割算法的时间复杂度）。</li>
<li>名称型（Nominal）：类似编程语言中的枚举类型，变量只能从有限的选项中选取，比如前面例子中的“婚姻情况”，只能是“单身”，“已婚”或“离婚”，使用“=”来分割。</li>
</ol>
<h4 id="如何评估分割点的好坏"><a href="#如何评估分割点的好坏" class="headerlink" title="如何评估分割点的好坏"></a>如何评估分割点的好坏</h4><p>如果一个分割点可以将当前的所有节点分为两类，使得每一类都很“纯”，也就是同一类的记录较多，那么就是一个好分割点。</p>
<p>比如上面的例子，“拥有房产”，可以将记录分成了两类，“是”的节点全部都可以偿还债务，非常“纯”；“否”的节点，可以偿还贷款和无法偿还贷款的人都有，不是很“纯”，但是两个节点加起来的纯度之和与原始节点的纯度之差最大，所以按照这种方法分割。</p>
<p>构建决策树采用贪心算法，只考虑当前纯度差最大的情况作为分割点。</p>
<h4 id="cart剪枝"><a href="#cart剪枝" class="headerlink" title="cart剪枝"></a>cart剪枝</h4><h5 id="为什么要剪枝"><a href="#为什么要剪枝" class="headerlink" title="为什么要剪枝"></a>为什么要剪枝</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094206.png"/> </p>
<ul>
<li><strong>图形描述</strong><ul>
<li>横轴表示在决策树创建过程中树的结点总数，纵轴表示决策树的预测精度。</li>
<li>实线显示的是决策树在训练集上的精度，虚线显示的则是在一个独立的测试集上测量出来的精度。</li>
<li>随着树的增长，在训练样集上的精度是单调上升的， 然而在独立的测试样例上测出的精度先上升后下降。</li>
</ul>
</li>
<li><strong>出现这种情况的原因：</strong><ul>
<li>原因1：噪声、样本冲突，即错误的样本数据。</li>
<li>原因2：特征即属性不能完全作为分类标准。</li>
<li>原因3：巧合的规律性，数据量不够大。</li>
</ul>
</li>
</ul>
<h5 id="常用的减枝方法"><a href="#常用的减枝方法" class="headerlink" title="常用的减枝方法"></a>常用的减枝方法</h5><ol>
<li><p><strong>预剪枝</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>）每一个结点所包含的最小样本数目，例如<span class="number">10</span>，则该结点总样本数小于<span class="number">10</span>时，则不再分；</span><br><span class="line"><span class="number">2</span>）指定树的高度或者深度，例如树的最大深度为<span class="number">4</span>；</span><br><span class="line"><span class="number">3</span>）指定结点的熵小于某个值，不再划分。随着树的增长， 在训练样集上的精度是单调上升的， 然而在独立的测试样例上测出的精度先上升后下降。</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>后剪枝</strong></p>
<p>把一棵树，构建完成之后，再进行从下往上的剪枝 </p>
</li>
</ol>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>监督学习算法</tag>
        <tag>决策树分类原理</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP协议</title>
    <url>/2020/01/09/TCP%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<h4 id="网络应用程序之间的通信流程"><a href="#网络应用程序之间的通信流程" class="headerlink" title="网络应用程序之间的通信流程"></a>网络应用程序之间的通信流程</h4><p> 通过 IP 地址能够找到对应的设备，然后再通过端口号找到对应的端口，再通过端口把数据传输给应用程序，<strong>这里要注意，数据不能随便发送，在发送之前还需要选择一个对应的传输协议，保证程序之间按照指定的传输规则进行数据的通信，</strong> 而这个传输协议就是TCP协议。</p>
 <a id="more"></a>
<h4 id="TCP-的概念"><a href="#TCP-的概念" class="headerlink" title="TCP 的概念"></a>TCP 的概念</h4><p>TCP 的英文全拼(Transmission Control Protocol)简称<strong>传输控制协议</strong>，它是一种<strong>面向连接的、可靠的、基于字节流的传输层通信协议</strong>。</p>
<p><strong>面向连接的效果图:</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150331.png"/> </p>
<p><strong>TCP 通信步骤:</strong></p>
<ol>
<li>创建连接</li>
<li>传输数据</li>
<li>关闭连接</li>
</ol>
<h4 id="TCP-的特点"><a href="#TCP-的特点" class="headerlink" title="TCP 的特点"></a>TCP 的特点</h4><ol>
<li>面向连接<ul>
<li>通信双方必须先建立好连接才能进行数据的传输，数据传输完成后，双方必须断开此连接，以释放系统资源。双方间的数据传输都可以通过这一个连接进行，完成数据交换后，双方必须断开此连接，以释放系统资源。<strong>这种连接是一对一的，因此TCP不适用于广播的应用程序，基于广播的应用程序请使用UDP协议</strong></li>
</ul>
</li>
<li>可靠传输<ul>
<li>TCP 采用发送应答机制：通过TCP这种方式发送的每一个报文段都必须得到接收方的应答才认为这个TCP报文传送成功。</li>
<li>超时重传：指定时间内没有应答会重新发送。</li>
<li>错误校验：传输数据必须与接收数据一致，否则传输失败。</li>
<li>流量控制和阻塞管理：流量控制用来避免发送端发送过快而使得接收方来不及接收。</li>
</ul>
</li>
<li>TCP 是一个<strong>稳定、可靠的传输协议，常用于对数据进行准确无误的传输，比如: 文件下载，浏览器上网</strong>。 </li>
</ol>
<h4 id="TCP在建立连接时的三次握手"><a href="#TCP在建立连接时的三次握手" class="headerlink" title="TCP在建立连接时的三次握手"></a>TCP在建立连接时的三次握手</h4><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">TCP在建立连接时需要通过三次握手过程来完成。</span><br><span class="line">  	原因：TCP 协议为了实现可靠传输， 通信双方需要判断自己已经发送的数据包是否都被接收方收到， 如果没收到， 就需要重发。 为了实现这个需求， 很自然地就会引出序号（sequence number） 和确认号（acknowledgement number） 的使用。发送方在发送数据包（假设大小为 <span class="number">10</span> byte）时， 同时送上一个序号( 假设为 <span class="number">500</span>)，那么接收方收到这个数据包以后， 就可以回复一个确认号（<span class="number">510</span> = <span class="number">500</span> + <span class="number">10</span>） 告诉发送方 “我已经收到了你的数据包， 你可以发送下一个数据包， 序号从 <span class="number">510</span> 开始” 。这样发送方就可以知道哪些数据被接收到，哪些数据没被接收到， 需要重发。</span><br></pre></td></tr></table></figure>
<ul>
<li>第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。</li>
<li>第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack (number )=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。</li>
<li>第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。</li>
</ul>
<h4 id="TCP在断开连接时的四次挥手"><a href="#TCP在断开连接时的四次挥手" class="headerlink" title="TCP在断开连接时的四次挥手"></a>TCP在断开连接时的四次挥手</h4><p>TCP在断开连接时，需要通过四次挥手的过程来完成。</p>
<ul>
<li>第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送。</li>
<li>第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1。</li>
<li>第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送。</li>
<li>第四次挥手：Client收到FIN后，接着发送一个ACK给Server，确认序号为收到序号+1。</li>
</ul>
<h4 id="TCP-网络应用程序开发流程"><a href="#TCP-网络应用程序开发流程" class="headerlink" title="TCP 网络应用程序开发流程"></a>TCP 网络应用程序开发流程</h4><p>TCP 网络应用程序开发分为:</p>
<ul>
<li>TCP 客户端程序开发</li>
<li>TCP 服务端程序开发</li>
</ul>
<p><strong>说明:</strong></p>
<p>客户端程序是指运行在<strong>用户设备上的程序</strong> 服务端程序是指运行在<strong>服务器设备上的程序</strong>，专门为客户端提供数据服务。</p>
<h5 id="TCP-客户端程序开发流程的介绍"><a href="#TCP-客户端程序开发流程的介绍" class="headerlink" title="TCP 客户端程序开发流程的介绍"></a>TCP 客户端程序开发流程的介绍</h5><p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150415.png"/></p>
<p><strong>步骤说明:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 创建客户端套接字对象</span><br><span class="line"><span class="number">2.</span> 和服务端套接字建立连接</span><br><span class="line"><span class="number">3.</span> 发送数据</span><br><span class="line"><span class="number">4.</span> 接收数据</span><br><span class="line"><span class="number">5.</span> 关闭客户端套接字</span><br></pre></td></tr></table></figure>
<h5 id="TCP-服务端程序开发流程的介绍"><a href="#TCP-服务端程序开发流程的介绍" class="headerlink" title="TCP 服务端程序开发流程的介绍"></a>TCP 服务端程序开发流程的介绍</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150440.png"/> </p>
<p><strong>步骤说明:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 创建服务端端套接字对象</span><br><span class="line"><span class="number">2.</span> 绑定端口号</span><br><span class="line"><span class="number">3.</span> 设置监听</span><br><span class="line"><span class="number">4.</span> 等待接受客户端的连接请求</span><br><span class="line"><span class="number">5.</span> 接收数据</span><br><span class="line"><span class="number">6.</span> 发送数据</span><br><span class="line"><span class="number">7.</span> 关闭套接字</span><br></pre></td></tr></table></figure>
<p><strong>主动发起建立连接请求的</strong>是客户端程序</p>
<p><strong>等待接受连接请求的</strong>是服务端程序</p>
<h4 id="socket-介绍"><a href="#socket-介绍" class="headerlink" title="socket 介绍"></a>socket 介绍</h4><p> socket (简称 套接字) 是<strong>进程之间通信一个工具</strong>，好比现实生活中的<strong>插座</strong>，所有的家用电器要想工作都是基于插座进行，<strong>进程之间想要进行网络通信需要基于这个 socket</strong>。 </p>
<p>socket 的作用：负责<strong>进程之间的网络数据传输</strong>，好比数据的搬运工。 </p>
<h4 id="TCP-客户端程序开发API"><a href="#TCP-客户端程序开发API" class="headerlink" title="TCP 客户端程序开发API"></a>TCP 客户端程序开发API</h4><p><strong>socket 类的介绍</strong>：</p>
<p>1.导入 socket 模块</p>
<figure class="highlight elm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br></pre></td></tr></table></figure>
<p>2.创建客户端 socket 对象</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">socket.socket(AddressFamily, Type)</span><br><span class="line">参数说明:</span><br><span class="line">- AddressFamily 表示IP地址类型, 分为IPv4和IPv6</span><br><span class="line">-<span class="built_in"> Type </span>表示传输协议类型</span><br><span class="line">方法说明:</span><br><span class="line">- connect((host, port)) 表示和服务端套接字建立连接, host是服务器ip地址，port是应用程序的端口号</span><br><span class="line">- send(data) 表示发送数据，data是二进制数据</span><br><span class="line">- recv(buffersize) 表示接收数据, buffersize是每次接收数据的长度</span><br></pre></td></tr></table></figure>
<p>3.创建服务端 socket 对象</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">socket.socket(AddressFamily, Type)</span><br><span class="line">参数说明:</span><br><span class="line">- AddressFamily 表示IP地址类型, 分为IPv4和IPv6</span><br><span class="line">-<span class="built_in"> Type </span>表示传输协议类型</span><br><span class="line">方法说明:</span><br><span class="line">- bind((host, port)) 表示绑定端口号, host 是<span class="built_in"> ip </span>地址，port 是端口号，ip 地址一般不指定，表示本机的任何一个ip地址都可以。</span><br><span class="line">- listen (backlog) 表示设置监听，backlog参数表示最大等待建立连接的个数。</span><br><span class="line">- accept() 表示等待接受客户端的连接请求</span><br><span class="line">- send(data) 表示发送数据，data 是二进制数据</span><br><span class="line">- recv(buffersize) 表示接收数据, buffersize 是每次接收数据的长度</span><br></pre></td></tr></table></figure>
<h4 id="TCP-客户端程序开发示例代码"><a href="#TCP-客户端程序开发示例代码" class="headerlink" title="TCP 客户端程序开发示例代码"></a>TCP 客户端程序开发示例代码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 创建tcp客户端套接字</span></span><br><span class="line">    <span class="comment"># 1. AF_INET：表示ipv4</span></span><br><span class="line">    <span class="comment"># 2. SOCK_STREAM: tcp传输协议</span></span><br><span class="line">    tcp_client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">    <span class="comment"># 和服务端应用程序建立连接</span></span><br><span class="line">    tcp_client_socket.connect((<span class="string">"192.168.131.62"</span>, <span class="number">8080</span>))</span><br><span class="line">    <span class="comment"># 代码执行到此，说明连接建立成功</span></span><br><span class="line">    <span class="comment"># 准备发送的数据</span></span><br><span class="line">    send_data = <span class="string">"你好服务端，我是客户端小黑!"</span>.encode(<span class="string">"gbk"</span>)</span><br><span class="line">    <span class="comment"># 发送数据</span></span><br><span class="line">    tcp_client_socket.send(send_data)</span><br><span class="line">    <span class="comment"># 接收数据, 这次接收的数据最大字节数是1024</span></span><br><span class="line">    recv_data = tcp_client_socket.recv(<span class="number">1024</span>)</span><br><span class="line">    <span class="comment"># 返回的直接是服务端程序发送的二进制数据</span></span><br><span class="line">    print(recv_data)</span><br><span class="line">    <span class="comment"># 对数据进行解码</span></span><br><span class="line">    recv_content = recv_data.decode(<span class="string">"gbk"</span>)</span><br><span class="line">    print(<span class="string">"接收服务端的数据为:"</span>, recv_content)</span><br><span class="line">    <span class="comment"># 关闭套接字</span></span><br><span class="line">    tcp_client_socket.close()</span><br></pre></td></tr></table></figure>
<h4 id="案例-多任务版TCP服务端程序开发"><a href="#案例-多任务版TCP服务端程序开发" class="headerlink" title="案例-多任务版TCP服务端程序开发"></a>案例-多任务版TCP服务端程序开发</h4><h5 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h5><p>目前我们开发的TCP服务端程序只能服务于一个客户端，如何开发一个多任务版的TCP服务端程序能够服务于多个客户端呢?</p>
<p>完成多任务，可以使用<strong>线程</strong>，比进程更加节省内存资源。</p>
<h5 id="具体实现步骤"><a href="#具体实现步骤" class="headerlink" title="具体实现步骤"></a>具体实现步骤</h5><ol>
<li>编写一个TCP服务端程序，循环等待接受客户端的连接请求</li>
<li>当客户端和服务端建立连接成功，创建子线程，使用子线程专门处理客户端的请求，防止主线程阻塞</li>
<li>把创建的子线程设置成为守护主线程，防止主线程无法退出。</li>
</ol>
<h5 id="多任务版TCP服务端程序的示例代码"><a href="#多任务版TCP服务端程序的示例代码" class="headerlink" title="多任务版TCP服务端程序的示例代码"></a>多任务版TCP服务端程序的示例代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理客户端的请求操作</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_client_request</span><span class="params">(service_client_socket, ip_port)</span>:</span></span><br><span class="line">    <span class="comment"># 循环接收客户端发送的数据</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 接收客户端发送的数据</span></span><br><span class="line">        recv_data = service_client_socket.recv(<span class="number">1024</span>)</span><br><span class="line">        <span class="comment"># 容器类型判断是否有数据可以直接使用if语句进行判断，如果容器类型里面有数据表示条件成立，否则条件失败</span></span><br><span class="line">        <span class="comment"># 容器类型: 列表、字典、元组、字符串、set、range、二进制数据</span></span><br><span class="line">        <span class="keyword">if</span> recv_data:</span><br><span class="line">            print(recv_data.decode(<span class="string">"gbk"</span>), ip_port)</span><br><span class="line">            <span class="comment"># 回复</span></span><br><span class="line">            service_client_socket.send(<span class="string">"ok，问题正在处理中..."</span>.encode(<span class="string">"gbk"</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"客户端下线了:"</span>, ip_port)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 终止和客户端进行通信</span></span><br><span class="line">    service_client_socket.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 创建tcp服务端套接字</span></span><br><span class="line">    tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">    <span class="comment"># 设置端口号复用，让程序退出端口号立即释放</span></span><br><span class="line">    tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 绑定端口号</span></span><br><span class="line">    tcp_server_socket.bind((<span class="string">""</span>, <span class="number">9090</span>))</span><br><span class="line">    <span class="comment"># 设置监听, listen后的套接字是被动套接字，只负责接收客户端的连接请求</span></span><br><span class="line">    tcp_server_socket.listen(<span class="number">128</span>)</span><br><span class="line">    <span class="comment"># 循环等待接收客户端的连接请求</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 等待接收客户端的连接请求</span></span><br><span class="line">        service_client_socket, ip_port = tcp_server_socket.accept()</span><br><span class="line">        print(<span class="string">"客户端连接成功:"</span>, ip_port)</span><br><span class="line">        <span class="comment"># 当客户端和服务端建立连接成功以后，需要创建一个子线程，不同子线程负责接收不同客户端的消息</span></span><br><span class="line">        sub_thread = threading.Thread(target=handle_client_request, args=(service_client_socket, ip_port))</span><br><span class="line">        <span class="comment"># 设置守护主线程</span></span><br><span class="line">        sub_thread.setDaemon(<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 启动子线程</span></span><br><span class="line">        sub_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tcp服务端套接字可以不需要关闭，因为服务端程序需要一直运行</span></span><br><span class="line">    <span class="comment"># tcp_server_socket.close()</span></span><br></pre></td></tr></table></figure>
<p><strong>说明:</strong></p>
<p>当客户端和服务端建立连接后，<strong>服务端程序退出后端口号不会立即释放，需要等待大概1-2分钟。</strong></p>
<p>解决办法有两种:</p>
<ol>
<li>更换服务端端口号</li>
<li>设置端口号复用(推荐大家使用)，也就是说让服务端程序退出后端口号立即释放。</li>
</ol>
<p>设置端口号复用的代码如下:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 参数1: 表示当前套接字</span></span><br><span class="line"><span class="comment"># 参数2: 设置端口号复用选项</span></span><br><span class="line"><span class="comment"># 参数3: 设置端口号复用选项对应的值</span></span><br><span class="line">tcp_server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="socket之send和recv原理剖析"><a href="#socket之send和recv原理剖析" class="headerlink" title="socket之send和recv原理剖析"></a>socket之send和recv原理剖析</h4><h5 id="认识TCP-socket的发送和接收缓冲区"><a href="#认识TCP-socket的发送和接收缓冲区" class="headerlink" title="认识TCP socket的发送和接收缓冲区"></a>认识TCP socket的发送和接收缓冲区</h5><p>当创建一个TCP socket对象的时候会有一个<strong>发送缓冲区</strong>和一个<strong>接收缓冲区</strong>，<strong>这个发送和接收缓冲区指的就是内存中的一片空间。</strong></p>
<h5 id="send原理剖析"><a href="#send原理剖析" class="headerlink" title="send原理剖析"></a>send原理剖析</h5><p>send是不是直接把数据发给服务端?</p>
<p>不是，要想发数据，必须得<strong>通过网卡发送数据</strong>，应用程序是无法直接通过网卡发送数据的，它需要调用操作系统接口，也就是说，应用程序把发送的数据先写入到<strong>发送缓冲区</strong>(内存中的一片空间)，再<strong>由操作系统控制网卡把发送缓冲区的数据发送给服务端网卡</strong> 。</p>
<h5 id="recv原理剖析"><a href="#recv原理剖析" class="headerlink" title="recv原理剖析"></a>recv原理剖析</h5><p>recv是不是直接从客户端接收数据?</p>
<p>不是，<strong>应用软件是无法直接通过网卡接收数据的</strong>，它需要调用操作系统接口，<strong>由操作系统通过网卡接收数据</strong>，把接收的数据<strong>写入到接收缓冲区</strong>(内存中的一片空间），应用程序<strong>再从接收缓存区获取客户端发送的数据</strong>。</p>
<h5 id="send和recv原理剖析图"><a href="#send和recv原理剖析图" class="headerlink" title="send和recv原理剖析图"></a>send和recv原理剖析图</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150519.png"/> </p>
<ul>
<li>发送数据是发送到发送缓冲区</li>
<li>接收数据是从接收缓冲区 获取</li>
</ul>
]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>传输层通信协议</tag>
        <tag>TCP协议</tag>
        <tag>TCP应用程序开发</tag>
      </tags>
  </entry>
  <entry>
    <title>逻辑回归</title>
    <url>/2020/01/09/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h4 id="什么是逻辑回归"><a href="#什么是逻辑回归" class="headerlink" title="什么是逻辑回归"></a>什么是逻辑回归</h4><p> 逻辑回归（Logistic Regression）是机器学习中的<strong>一种分类模型</strong>，逻辑回归是一种分类算法，虽然名字中带有回归。由于算法的简单和高效，在实际中应用非常广泛。 </p>
<a id="more"></a>
<h4 id="逻辑回归的应用场景"><a href="#逻辑回归的应用场景" class="headerlink" title="逻辑回归的应用场景"></a>逻辑回归的应用场景</h4><ul>
<li>广告点击率</li>
<li>是否为垃圾邮件</li>
<li>是否患病</li>
<li>金融诈骗</li>
<li><p>虚假账号</p>
<p>看到上面的例子，我们可以发现其中的特点，那就是都属于两个类别之间的判断。逻辑回归就是解决二分类问题的利器 。</p>
</li>
</ul>
<h4 id="逻辑回归的原理"><a href="#逻辑回归的原理" class="headerlink" title="逻辑回归的原理"></a>逻辑回归的原理</h4><ol>
<li><h5 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092750.png"/></p>
<p>  <strong>逻辑回归的输入就是一个线性回归的结果</strong>。 </p>
</li>
<li><h5 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h5><ul>
<li><p><strong>sigmoid函数</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092937.png"/></p>
</li>
<li><p>判断标准</p>
<ol>
<li>回归的结果输入到sigmoid函数当中</li>
</ol>
</li>
</ul>
<ol>
<li><p>输出结果：[0, 1]区间中的一个概率值，默认为0.5为阈值。</p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092819.png"/></p>
</li>
</ol>
</li>
</ol>
<pre><code>逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例),另外的一个类别会标记为0(反例)。（方便损失计算） 
</code></pre><h4 id="逻辑损失以及优化"><a href="#逻辑损失以及优化" class="headerlink" title="逻辑损失以及优化"></a>逻辑损失以及优化</h4><p> 逻辑回归的损失，称之为<strong>对数似然损失</strong>，公式如下： </p>
<ul>
<li><p>分开类别：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092803.png"/></p>
<p>其中y为真实值，$h_\theta(x)$为预测值  </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092857.png"/></p>
<p>无论何时，我们都希望<strong>损失函数值，越小越好</strong></p>
<p>分情况讨论，对应的损失函数值：</p>
<ul>
<li><strong>当y=1时，我们希望$h_\theta(x)$值越大越好；</strong></li>
<li><strong>当y=0时，我们希望$h_\theta(x)$值越小越好</strong></li>
</ul>
</li>
<li><p>综合完整损失函数</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092741.png"/></p>
</li>
<li><p><strong>优化</strong></p>
<p>同样使用梯度下降优化算法，去减少损失函数的值。这样去更新逻辑回归前面对应算法的权重参数，<strong>提升原本属于1类别的概率，降低原本是0类别的概率。</strong>  </p>
</li>
</ul>
<h4 id="逻辑回归API"><a href="#逻辑回归API" class="headerlink" title="逻辑回归API"></a>逻辑回归API</h4><p><strong>sklearn.linear_model.LogisticRegression(solver=’liblinear’, penalty=‘l2’, C = 1.0)</strong></p>
<ul>
<li>solver可选参数:{‘liblinear’, ‘sag’, ‘saga’,’newton-cg’, ‘lbfgs’}，<ul>
<li>默认: ‘liblinear’；用于优化问题的算法。</li>
<li>对于小数据集来说，“liblinear”是个不错的选择，而“sag”和’saga’对于大型数据集会更快。</li>
<li>对于多类问题，只有’newton-cg’， ‘sag’， ‘saga’和’lbfgs’可以处理多项损失;“liblinear”仅限于“one-versus-rest”分类。</li>
</ul>
</li>
<li>penalty：正则化的种类</li>
<li><p>C：正则化力度</p>
<p><strong>LogisticRegression方法相当于 SGDClassifier(loss=”log”, penalty=” “),SGDClassifier实现了一个普通的随机梯度下降学习。而使用LogisticRegression(实现了SAG)。</strong> </p>
</li>
</ul>
<h4 id="案例-癌症分类预测"><a href="#案例-癌症分类预测" class="headerlink" title="案例-癌症分类预测"></a>案例-癌症分类预测</h4><ol>
<li><h5 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092811.png"/></p>
<p> 原始数据的下载地址：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="noopener">https://archive.ics.uci.edu/ml/machine-learning-databases/</a> </p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">数据描述</span><br><span class="line"></span><br><span class="line">（<span class="number">1</span>）<span class="number">699</span>条样本，共<span class="number">11</span>列数据，第一列用语检索的id，后<span class="number">9</span>列分别是与肿瘤相关的医学特征，最后一列表示肿瘤类型的数值。</span><br><span class="line">（<span class="number">2</span>）包含<span class="number">16</span>个缺失值，用”?”标出。</span><br></pre></td></tr></table></figure>
</li>
<li><h5 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h5><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span>获取数据</span><br><span class="line"><span class="number">2.</span>基本数据处理</span><br><span class="line"><span class="number">2.1</span> 缺失值处理</span><br><span class="line"><span class="number">2.2</span> 确定特征值,目标值</span><br><span class="line"><span class="number">2.3</span> 分割数据</span><br><span class="line"><span class="number">3.</span>特征工程(标准化)</span><br><span class="line"><span class="number">4.</span>机器学习(逻辑回归)</span><br><span class="line"><span class="number">5.</span>模型评估</span><br></pre></td></tr></table></figure>
</li>
<li><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br></pre></td></tr></table></figure>
<p><strong>1. 获取数据</strong></p>
<figure class="highlight kotlin"><table><tr><td class="code"><pre><span class="line">names = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>,</span><br><span class="line">                   <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>,</span><br><span class="line">                   <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">data</span> = pd.read_csv(<span class="string">"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>,</span><br><span class="line">                  names=names)</span><br><span class="line"><span class="keyword">data</span>.head()</span><br></pre></td></tr></table></figure>
<p><strong>2. 基本数据处理</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2.1 缺失值处理</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">"?"</span>, value=np.NaN)</span><br><span class="line">data = data.dropna()</span><br><span class="line"><span class="comment"># 2.2 确定特征值,目标值</span></span><br><span class="line">x = data.iloc[:, <span class="number">1</span>:<span class="number">10</span>]</span><br><span class="line">x.head()</span><br><span class="line">y = data[<span class="string">"Class"</span>]</span><br><span class="line">y.head()</span><br><span class="line"><span class="comment"># 2.3 分割数据</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br></pre></td></tr></table></figure>
<p><strong>3. 特征工程(标准化)</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br></pre></td></tr></table></figure>
<p><strong>4. 机器学习(逻辑回归)</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">estimator = LogisticRegression()</span><br><span class="line">estimator.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>
<p><strong>5. 模型评估</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line">y_predict</span><br><span class="line">estimator.score(x_test, y_test)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="分类评估方法"><a href="#分类评估方法" class="headerlink" title="分类评估方法"></a>分类评估方法</h4><p>在很多分类场景当中我们不一定只关注预测的准确率。</p>
<p>比如以这个癌症举例子，我们并不关注预测的准确率，而是关注在所有的样本当中，癌症患者有没有被全部预测（检测）出来。**</p>
<h5 id="精确率与召回率"><a href="#精确率与召回率" class="headerlink" title="精确率与召回率"></a>精确率与召回率</h5><ul>
<li><p><strong>准确率 （对不对） </strong></p>
</li>
<li><p>（TP+TN）/(TP+TN+FN+FP) </p>
</li>
<li><p><strong>混淆矩阵</strong></p>
<p> 在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类) </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092756.png"/></p>
</li>
<li><p><strong>精确率(Precision)与召回率(Recall)</strong></p>
<ul>
<li><p>精确率 —— 查的准不准 ：预测结果为正例样本中真实为正例的比例 </p>
</li>
<li><p>TP/(TP+FP) </p>
</li>
<li><p>P -预测为正，N-预测为负</p>
</li>
<li><p>T-预测对了， F-预测错了</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092928.png"/> </p>
</li>
<li><p>召回率  ——  查的全不全 ：真实为正例的样本中预测结果为正例的比例（查得全，对正样本的区分能力） </p>
</li>
<li><p>TP/(TP+FN) </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092913.png"/></p>
</li>
</ul>
</li>
<li><p><strong>F1-score</strong></p>
<ul>
<li><p>还有其他的评估标准，F1-score，反映了模型的稳健型 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092905.png"/></p>
</li>
</ul>
</li>
<li><p><strong>分类评估报告API</strong></p>
<ul>
<li>sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None )<ul>
<li>y_true：真实目标值</li>
<li>y_pred：估计器预测目标值</li>
<li>labels:指定类别对应的数字</li>
<li>target_names：目标类别名称</li>
<li>return：每个类别精确率与召回率</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ret = classification_report(y_test, y_predict, labels=(<span class="number">2</span>,<span class="number">4</span>), target_names=(<span class="string">"良性"</span>, <span class="string">"恶性"</span>))</span><br><span class="line">print(ret)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="ROC曲线与AUC指标"><a href="#ROC曲线与AUC指标" class="headerlink" title="ROC曲线与AUC指标"></a>ROC曲线与AUC指标</h5><p><strong>假设这样一个情况，如果99个样本癌症，1个样本非癌症，不管怎样我全都预测正例(默认癌症为正例),准确率就为99%但是这样效果并不好，这就是样本不均衡下的评估问题</strong></p>
<p>问题：<strong>如何衡量样本不均衡下的评估</strong>？</p>
<ul>
<li><p><strong>TPR与FPR</strong></p>
<ul>
<li>TPR = TP / (TP + FN)    —— 正类的召回率<ul>
<li>所有真实类别为1的样本中，预测类别为1的比例</li>
</ul>
</li>
<li>FPR = FP / (FP + TN)    —— 1-负类的召回率<ul>
<li>所有真实类别为0的样本中，预测类别为1的比例</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>ROC曲线</strong></p>
<p> ROC曲线的横轴就是FPRate，纵轴就是TPRate，当二者相等时，表示的意义则是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092851.png"/> </p>
</li>
<li><p><strong>AUC指标</strong></p>
<ul>
<li>AUC的概率意义是随机取一对正负样本，正样本得分大于负样本得分的概率</li>
<li>AUC的范围在[0, 1]之间，并且越接近1越好，越接近0.5属于乱猜</li>
<li><strong>AUC=1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。</strong></li>
<li>$0.5&lt;AUC&lt;1$ <strong>优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</strong> </li>
<li>这个指标主要用于评价不平衡的二分类问题 </li>
</ul>
</li>
<li><p><strong>AUC计算API</strong></p>
</li>
<li><p><strong>from sklearn.metrics import roc_auc_score</strong></p>
</li>
<li><p>sklearn.metrics.roc_auc_score(y_true, y_score)</p>
<ul>
<li>计算ROC曲线面积，即AUC值</li>
<li>y_true：每个样本的真实类别，必须为0(反例),1(正例)标记</li>
<li>y_score：预测得分，可以是正类的估计概率、置信值或者分类器方法的返回值</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 0.5~1之间，越接近于1约好</span></span><br><span class="line">y_test = np.where(y_test &gt; <span class="number">2.5</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"AUC指标："</span>, roc_auc_score(y_test, y_predict)</span><br></pre></td></tr></table></figure>
<ul>
<li>AUC只能用来评价二分类</li>
<li>AUC非常适合评价样本不平衡中的分类器性能</li>
</ul>
<h4 id="ROC曲线的绘制"><a href="#ROC曲线的绘制" class="headerlink" title="ROC曲线的绘制"></a>ROC曲线的绘制</h4><p>关于ROC曲线的绘制过程，通过以下举例进行说明：</p>
<h5 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h5><p>假设有6次展示记录，有两次被点击了，得到一个展示序列（1:1,2:0,3:1,4:0,5:0,6:0），前面的表示序号，后面的表示点击（1）或没有点击（0）。然后在这6次展示的时候都通过model算出了点击的概率序列。</p>
<p>下面看三种情况。</p>
<p>1.如果概率的序列是（1:0.9,2:0.7,3:0.8,4:0.6,5:0.5,6:0.4）：</p>
<p>与原来的序列一起，得到序列（从概率从高到低排）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>1</th>
<th>0</th>
<th>0</th>
<th>0</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9</td>
<td>0.8</td>
<td>0.7</td>
<td>0.6</td>
<td>0.5</td>
<td>0.4</td>
</tr>
</tbody>
</table>
</div>
<p>绘制的步骤是：</p>
<p>1）把概率序列从高到低排序，得到顺序（1:0.9,3:0.8,2:0.7,4:0.6,5:0.5,6:0.4）；</p>
<p>2）从概率最大开始取一个点作为正类，取到点1，计算得到TPR=0.5，FPR=0.0；</p>
<p>3）从概率最大开始，再取一个点作为正类，取到点3，计算得到TPR=1.0，FPR=0.0；</p>
<p>4）再从最大开始取一个点作为正类，取到点2，计算得到TPR=1.0，FPR=0.25;</p>
<p>5）以此类推，得到6对TPR和FPR。</p>
<p>然后把这6对数据组成6个点(0,0.5),(0,1.0),(0.25,1),(0.5,1),(0.75,1),(1.0,1.0)。</p>
<p>这6个点在二维坐标系中能绘出来就是 ROC曲线 。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092843.png"/> </p>
<p>2.如果概率的序列是（1:0.9,2:0.8,3:0.7,4:0.6,5:0.5,6:0.4）：</p>
<p>与原来的序列一起，得到序列（从概率从高到低排）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>0</th>
<th>1</th>
<th>0</th>
<th>0</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9</td>
<td>0.8</td>
<td>0.7</td>
<td>0.6</td>
<td>0.5</td>
<td>0.4</td>
</tr>
</tbody>
</table>
</div>
<p>绘制的步骤是：</p>
<p>6）把概率序列从高到低排序，得到顺序（1:0.9,2:0.8,3:0.7,4:0.6,5:0.5,6:0.4）；</p>
<p>7）从概率最大开始取一个点作为正类，取到点1，计算得到TPR=0.5，FPR=0.0；</p>
<p>8）从概率最大开始，再取一个点作为正类，取到点2，计算得到TPR=0.5，FPR=0.25；</p>
<p>9）再从最大开始取一个点作为正类，取到点3，计算得到TPR=1.0，FPR=0.25;</p>
<p>10）以此类推，得到6对TPR和FPR。</p>
<p>然后把这6对数据组成6个点(0,0.5),(0.25,0.5),(0.25,1),(0.5,1),(0.75,1),(1.0,1.0)。</p>
<p>这6个点在二维坐标系中能绘出来就是 ROC曲线 。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092833.png"/> </p>
<p>3.如果概率的序列是（1:0.4,2:0.6,3:0.5,4:0.7,5:0.8,6:0.9）：</p>
<p>与原来的序列一起，得到序列（从概率从高到低排）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>0</th>
<th>1</th>
<th>0</th>
<th>0</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.9</td>
<td>0.8</td>
<td>0.7</td>
<td>0.6</td>
<td>0.5</td>
<td>0.4</td>
</tr>
</tbody>
</table>
</div>
<p>绘制的步骤是：</p>
<p>6）把概率序列从高到低排序，得到顺序（1:0.9,2:0.8,3:0.7,4:0.6,5:0.5,6:0.4）；</p>
<p>7）从概率最大开始取一个点作为正类，取到点1，计算得到TPR=0.5，FPR=0.0；</p>
<p>8）从概率最大开始，再取一个点作为正类，取到点2，计算得到TPR=0.5，FPR=0.25；</p>
<p>9）再从最大开始取一个点作为正类，取到点3，计算得到TPR=1.0，FPR=0.25;</p>
<p>10）以此类推，得到6对TPR和FPR。</p>
<p>然后把这6对数据组成6个点(0,0.5),(0.25,0.5),(0.25,1),(0.5,1),(0.75,1),(1.0,1.0)。</p>
<p>这6个点在二维坐标系中能绘出来就是ROC曲线。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227092833.png"/> </p>
<h5 id="意义解释"><a href="#意义解释" class="headerlink" title="意义解释"></a>意义解释</h5><p>如上图的例子，总共6个点，2个正样本，4个负样本，取一个正样本和一个负样本的情况总共有8种。</p>
<p>上面的第一种情况，从上往下取，无论怎么取，正样本的概率总在负样本之上，所以分对的概率为1，AUC=1。再看那个ROC曲线，它的积分是什么？也是1，ROC曲线的积分与AUC相等。</p>
<p>上面第二种情况，如果取到了样本2和3，那就分错了，其他情况都分对了；所以分对的概率是0.875，AUC=0.875。再看那个ROC曲线，它的积分也是0.875，ROC曲线的积分与AUC相等。</p>
<p>上面的第三种情况，无论怎么取，都是分错的，所以分对的概率是0，AUC=0.0。再看ROC曲线，它的积分也是0.0，ROC曲线的积分与AUC相等。</p>
<p>很牛吧，其实AUC的意思是——Area Under roc Curve，就是ROC曲线的积分，也是ROC曲线下面的面积。</p>
<p>绘制ROC曲线的意义很明显，不断地把可能分错的情况扣除掉，从概率最高往下取的点，每有一个是负样本，就会导致分错排在它下面的所有正样本，所以要把它下面的正样本数扣除掉（1-TPR，剩下的正样本的比例）。总的ROC曲线绘制出来了，AUC就定了，分对的概率也能求出来了。</p>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>分类评估方法</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归</title>
    <url>/2020/01/08/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h4 id="什么是线性回归"><a href="#什么是线性回归" class="headerlink" title="什么是线性回归"></a>什么是线性回归</h4><p><strong>定义：</strong> 线性回归(Linear regression)是利用<strong>回归方程(函数)</strong>对<strong>一个或多个自变量(特征值)和因变量(目标值)之间</strong>关系进行建模的一种分析方式。 </p>
<p>特点： 只有一个自变量的情况称为单变量回归，多于一个自变量情况的叫做多元回归 </p>
<a id="more"></a>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223100938.png"/></p>
<p>在机器学习中<strong>特征值与目标值之间建立了一个关系，这个关系可以理解为线性模型</strong>。 </p>
<h4 id="线性回归的特征与目标的关系"><a href="#线性回归的特征与目标的关系" class="headerlink" title="线性回归的特征与目标的关系"></a>线性回归的特征与目标的关系</h4><p> 线性回归当中主要有两种模型，<strong>一种是线性关系，另一种是非线性关系。</strong>在这里我们只能画一个平面更好去理解，所以都用单个特征或两个特征举例子。 </p>
<ul>
<li><p>线性关系</p>
<ul>
<li><p>单变量关系：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101022.png"/></p>
</li>
</ul>
</li>
<li><p>多变量线性关系 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101102.png"/></p>
<p>注释： 单特征与目标值的关系呈直线关系，两个特征与目标值呈现平面的关系  </p>
</li>
<li><p>非线性关系 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101110.png"/></p>
</li>
</ul>
<h4 id="线性回归API"><a href="#线性回归API" class="headerlink" title="线性回归API"></a>线性回归API</h4><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">sklearn</span><span class="selector-class">.linear_model</span><span class="selector-class">.LinearRegression</span>()</span><br><span class="line">	# 基于正规方程</span><br><span class="line">	<span class="selector-tag">LinearRegression</span><span class="selector-class">.coef_</span>：回归系数</span><br></pre></td></tr></table></figure>
<p><strong>小案例：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment"># 构造数据集</span></span><br><span class="line"><span class="comment"># 已知学生平时成绩和期末成绩，预测最终成绩</span></span><br><span class="line">x = [[<span class="number">80</span>, <span class="number">86</span>],[<span class="number">82</span>, <span class="number">80</span>],[<span class="number">85</span>, <span class="number">78</span>],[<span class="number">90</span>, <span class="number">90</span>],</span><br><span class="line">     [<span class="number">86</span>, <span class="number">82</span>],[<span class="number">82</span>, <span class="number">90</span>],[<span class="number">78</span>, <span class="number">80</span>],[<span class="number">92</span>, <span class="number">94</span>]]</span><br><span class="line">y = [<span class="number">84.2</span>, <span class="number">80.6</span>, <span class="number">80.1</span>, <span class="number">90</span>, <span class="number">83.2</span>, <span class="number">87.6</span>, <span class="number">79.4</span>, <span class="number">93.4</span>]</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = LinearRegression()</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x,y)</span><br><span class="line">print(estimator.coef_)</span><br><span class="line">print(estimator.predict([[<span class="number">100</span>, <span class="number">80</span>]]))</span><br></pre></td></tr></table></figure>
<h4 id="线性回归的损失和优化"><a href="#线性回归的损失和优化" class="headerlink" title="线性回归的损失和优化"></a>线性回归的损失和优化</h4><ol>
<li><p><strong>损失函数</strong></p>
<p>总损失定义为：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101752.png"/></p>
<ul>
<li>$y_i$为第i个训练样本的真实值</li>
<li>$h(x_i)$为第i个训练样本特征值组合预测函数</li>
<li>又称<strong>最小二乘法</strong></li>
</ul>
<p>如何去减少这个损失，使我们预测的更加准确些？既然存在了这个损失，我们一直说机器学习有自动学习的功能，在线性回归这里更是能够体现。这里可以通过一些优化方法去优化（其实是数学当中的求导功能）回归的总损失！！！</p>
</li>
<li><p><strong>优化算法</strong></p>
<p><strong>如何去求模型当中的W，使得损失最小？（目的是找到最小损失对应的W值）</strong></p>
<ul>
<li>线性回归经常使用的两种优化算法<ul>
<li>正规方程</li>
<li>梯度下降法</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101812.png"/></p>
<p> 理解：X为特征值矩阵，y为目标值矩阵。<strong>直接求到最好的结果</strong></p>
<p><strong>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</strong></p>
<p><strong>正规方程的推导：</strong></p>
<p> 把该损失函数转换成矩阵写法： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101843.png"/></p>
<p>其中$y$是真实值矩阵，$X$是特征值矩阵，$w$是权重矩阵</p>
<p>对其求解关于$w$的最小值，起止$y$，$X$ 均已知二次函数直接求导，导数为零的位置，即为最小值。</p>
<p>对损失函数求导：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223101854.png"/></p>
<h4 id="梯度下降-Gradient-Descent"><a href="#梯度下降-Gradient-Descent" class="headerlink" title="梯度下降(Gradient Descent)"></a>梯度下降(Gradient Descent)</h4><p><strong>梯度</strong>：梯度是微积分中一个很重要的概念，<strong>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率；</strong> <strong>在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向；</strong></p>
<p> <strong>梯度下降（Gradient Descent）公式</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223103504.png"/></p>
<p>  <strong>α是什么含义</strong> </p>
<p> α在梯度下降算法中被称作为<strong>学习率</strong>或者<strong>步长</strong>，意味着我们可以通过α来控制每一步走的距离，以保证不要走太快，错过了最低点。同时也要保证不要走的太慢，导致太阳下山了，还没有走到山下。所以α的选择在梯度下降法中往往是很重要的！α不能太大也不能太小，太小的话，可能导致迟迟走不到最低点，太大的话，会导致错过最低点。</p>
<p> <strong>所以有了梯度下降这样一个优化算法，回归就有了”自动学习”的能力</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223103515.gif"/> </p>
<h4 id="梯度下降和正规方程的对比"><a href="#梯度下降和正规方程的对比" class="headerlink" title="梯度下降和正规方程的对比"></a>梯度下降和正规方程的对比</h4><div class="table-container">
<table>
<thead>
<tr>
<th>梯度下降</th>
<th>正规方程</th>
</tr>
</thead>
<tbody>
<tr>
<td>需要选择学习率</td>
<td>不需要</td>
</tr>
<tr>
<td>需要迭代求解</td>
<td>一次运算得出</td>
</tr>
<tr>
<td>特征数量较大可以使用</td>
<td>需要计算方程，时间复杂度高O(n3)</td>
</tr>
</tbody>
</table>
</div>
<h4 id="算法选择依据"><a href="#算法选择依据" class="headerlink" title="算法选择依据"></a>算法选择依据</h4><ul>
<li>小规模数据：<ul>
<li>正规方程：<strong>LinearRegression(不能解决拟合问题)</strong></li>
<li>岭回归</li>
</ul>
</li>
<li>大规模数据：<ul>
<li>梯度下降法：<strong>SGDRegressor</strong></li>
</ul>
</li>
</ul>
<h4 id="常见的梯度下降算法"><a href="#常见的梯度下降算法" class="headerlink" title="常见的梯度下降算法"></a>常见的梯度下降算法</h4><figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">全梯度下降算法(<span class="literal">Full</span> gradient descent）,</span><br><span class="line">随机梯度下降算法（Stochastic gradient descent）,</span><br><span class="line">小批量梯度下降算法（Mini<span class="params">-batch</span> gradient descent）,</span><br><span class="line">随机平均梯度下降算法（Stochastic <span class="keyword">average</span> gradient descent）</span><br></pre></td></tr></table></figure>
<h5 id="全梯度下降算法（FG）"><a href="#全梯度下降算法（FG）" class="headerlink" title="全梯度下降算法（FG）"></a>全梯度下降算法（FG）</h5><ol>
<li>计算训练集所有样本误差，对其求和再取平均值作为目标函数。</li>
<li>权重向量沿其梯度相反的方向移动，从而使当前目标函数减少得最多。</li>
<li>因为在执行每次更新时，我们需要在整个数据集上计算所有的梯度，所以批梯度下降法的速度会很慢，同时，批梯度下降法无法处理超出内存容量限制的数据集。</li>
<li>批梯度下降法同样也不能在线更新模型，即在运行的过程中，不能增加新的样本。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223215800.png"/></p>
<h5 id="随机梯度下降算法（SG）"><a href="#随机梯度下降算法（SG）" class="headerlink" title="随机梯度下降算法（SG）"></a>随机梯度下降算法（SG）</h5><p>由于FG每迭代更新一次权重都需要计算所有样本误差，而实际问题中经常有上亿的训练样本，故效率偏低，且容易陷入局部最优解，因此提出了随机梯度下降算法。</p>
<p>其每轮计算的目标函数不再是全体样本误差，而仅是单个样本误差，即<strong>每次只代入计算一个样本目标函数的梯度来更新权重，再取下一个样本重复此过程，直到损失函数值停止下降或损失函数值小于某个可以容忍的阈值。</strong></p>
<p>此过程简单，高效，通常可以较好地避免更新迭代收敛到局部最优解。 但是由于，SG每次只使用一个样本迭代，若遇上噪声则容易陷入局部最优解。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223215850.png"/> </p>
<h5 id="小批量梯度下降算法（mini-batch）"><a href="#小批量梯度下降算法（mini-batch）" class="headerlink" title="小批量梯度下降算法（mini-batch）"></a>小批量梯度下降算法（mini-batch）</h5><p>小批量梯度下降算法是FG和SG的折中方案,在一定程度上兼顾了以上两种方法的优点。</p>
<p><strong>每次从训练样本集上随机抽取一个小样本集，在抽出来的小样本集上采用FG迭代更新权重。</strong></p>
<p>被抽出的小样本集所含样本点的个数称为batch_size，通常设置为2的幂次方，更有利于GPU加速处理。</p>
<p>特别的，若batch_size=1，则变成了SG；若batch_size=n，则变成了FG.其迭代形式为</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223215953.png"/></p>
<h5 id="随机平均梯度下降算法（SAG）"><a href="#随机平均梯度下降算法（SAG）" class="headerlink" title="随机平均梯度下降算法（SAG）"></a>随机平均梯度下降算法（SAG）</h5><p>在SG方法中，虽然避开了运算成本大的问题，但对于大数据训练而言，SG效果常不尽如人意，因为每一轮梯度更新都完全与上一轮的数据和梯度无关。</p>
<p><strong>随机平均梯度算法克服了这个问题，在内存中为每一个样本都维护一个旧的梯度，随机选择第i个样本来更新此样本的梯度，其他样本的梯度保持不变，然后求得所有梯度的平均值，进而更新了参数。</strong></p>
<p>如此，每一轮更新仅需计算一个样本的梯度，计算成本等同于SG，但收敛速度快得多。</p>
<h4 id="梯度下降法算法比较"><a href="#梯度下降法算法比较" class="headerlink" title="梯度下降法算法比较"></a>梯度下降法算法比较</h4><ul>
<li>全梯度下降算法(Full gradient descent）,</li>
<li>随机梯度下降算法（Stochastic gradient descent）,</li>
<li>小批量梯度下降算法（Mini-batch gradient descent）,</li>
<li>随机平均梯度下降算法（Stochastic average gradient descent）</li>
</ul>
<ol>
<li><p>FG方法由于它每轮更新都要使用全体数据集，故花费的时间成本最多，内存存储最大。</p>
</li>
<li><p>SAG在训练初期表现不佳，优化速度较慢。这是因为我们常将初始梯度设为0，而SAG每轮梯度更新都结合了上一轮梯度值。</p>
</li>
<li>综合考虑迭代次数和运行时间，SG表现性能都很好，能在训练初期快速摆脱初始梯度值，快速将平均损失函数降到很低。但要注意，在使用SG方法时要慎重选择步长，否则容易错过最优解。 </li>
<li>mini-batch结合了SG的“胆大”和FG的“心细”，从6幅图像来看，它的表现也正好居于SG和FG二者之间。在目前的机器学习领域，mini-batch是使用最多的梯度下降算法，正是因为它避开了FG运算效率低成本大和SG收敛效果不稳定的缺点。 </li>
</ol>
<h4 id="基于梯度下降法API"><a href="#基于梯度下降法API" class="headerlink" title="基于梯度下降法API"></a>基于梯度下降法API</h4><p>正规方程</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.linear_model.<span class="constructor">LinearRegression(<span class="params">fit_intercept</span>=True)</span></span><br><span class="line">	通过正规方程优化</span><br><span class="line">	参数</span><br><span class="line">		fit_intercept：是否计算偏置</span><br><span class="line">	属性</span><br><span class="line">		<span class="module-access"><span class="module"><span class="identifier">LinearRegression</span>.</span></span>coef_：回归系数</span><br><span class="line">		<span class="module-access"><span class="module"><span class="identifier">LinearRegression</span>.</span></span>intercept_：偏置</span><br></pre></td></tr></table></figure>
<p><strong>随机梯度下降法</strong></p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sklearn.linear_model.SGDRegressor(<span class="attribute">loss</span>=<span class="string">"squared_loss"</span>, <span class="attribute">fit_intercept</span>=<span class="literal">True</span>, learning_rate =<span class="string">'invscaling'</span>, <span class="attribute">eta0</span>=0.01)</span><br><span class="line">	SGDRegressor类实现了随机梯度下降学习，它支持不同的loss函数和正则化惩罚项来拟合线性回归模型。</span><br><span class="line">	参数：</span><br><span class="line">	loss:损失类型</span><br><span class="line">		<span class="attribute">loss</span>=”squared_loss”: 普通最小二乘法</span><br><span class="line">	fit_intercept：是否计算偏置</span><br><span class="line">	learning_rate : string, optional</span><br><span class="line">		学习率填充</span><br><span class="line">		<span class="string">'constant'</span>: eta = eta0</span><br><span class="line">		<span class="string">'optimal'</span>: eta = 1.0 / (alpha * (t + t0) [default]</span><br><span class="line">		<span class="string">'invscaling'</span>: eta = eta0 / pow(t, power_t)</span><br><span class="line">			<span class="attribute">power_t</span>=0.25:存在父类当中</span><br><span class="line">	对于一个常数值的学习率来说，可以使用<span class="attribute">learning_rate</span>=’constant’ ，并使用eta0来指定学习率。</span><br><span class="line">	属性：</span><br><span class="line">		SGDRegressor.coef_：回归系数</span><br><span class="line">		SGDRegressor.intercept_：偏置</span><br></pre></td></tr></table></figure>
<h4 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h4><ol>
<li><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><ul>
<li>过拟合：一个假设<strong>在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据</strong>，此时认为这个假设出现了过拟合的现象。(模型过于复杂)</li>
<li>欠拟合：一个假设<strong>在训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据</strong>，此时认为这个假设出现了欠拟合的现象。(模型过于简单)</li>
</ul>
</li>
<li><h5 id="原因以及解决办法"><a href="#原因以及解决办法" class="headerlink" title="原因以及解决办法"></a>原因以及解决办法</h5><ul>
<li><p>欠拟合原因以及解决办法</p>
<p>原因：学习到数据的特征过少</p>
<p>解决办法：继续学习</p>
<p><strong>1）添加其他特征项，</strong>有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。</p>
<p><strong>2）添加多项式特征</strong>，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。</p>
</li>
<li><p>过拟合原因以及解决办法</p>
<p>原因：原始特征过多，存在一些嘈杂特征， 模型过于复杂是因为模型尝试去兼顾各个测试数据点</p>
<p>解决办法：</p>
<p>1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。</p>
<p>2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。</p>
<p><strong>3）正则化</strong></p>
<p>4）减少特征维度，防止<strong>维灾难</strong></p>
</li>
</ul>
</li>
<li><p>练一练 ：尝试不看后面的字回答出来是解决过拟合的措施，还是解决欠拟合的措施？</p>
<p><strong>过拟合和欠拟合的解决方案</strong></p>
<ul>
<li>获取更多样本 过 </li>
<li>减少特征个数 过 </li>
<li>增加特征个数 欠 </li>
<li>使用高次项的特征 欠 </li>
<li>增加正则化的惩罚系数 过 </li>
<li>减少正则化的惩罚系数 欠   </li>
</ul>
<p><strong>解决过拟合和欠拟合的措施</strong> </p>
<p>过拟合解决方案： </p>
<ul>
<li>获取更多样本</li>
<li>减少特征个数 </li>
<li>增加正则化的惩罚系数</li>
</ul>
<p>欠拟合解决方案:</p>
<ul>
<li>增加特征个数 </li>
<li>使用高次项的特征 </li>
<li>减少正则化的惩罚系数 </li>
</ul>
</li>
</ol>
<h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p> 在解决回归过拟合中，我们选择正则化。但是对于其他机器学习算法如分类算法来说也会出现这样的问题，除了一些算法本身作用之外（决策树、神经网络），我们更多的也是去自己做特征选择，包括之前说的删除、合并一些特征 。</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220026.png"/></p>
<p>  <strong>如何解决？</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220139.png"/></p>
<p><strong>在学习的时候，数据提供的特征有些影响模型复杂度或者这个特征的数据点异常较多，所以算法在学习的时候尽量减少这个特征的影响（甚至删除某个特征的影响），这就是正则化</strong></p>
<p>注：调整时候，算法并不知道某个特征影响，而是去调整参数得出优化的结果</p>
<h4 id="正则化类别"><a href="#正则化类别" class="headerlink" title="正则化类别"></a>正则化类别</h4><ul>
<li>L2正则化<ul>
<li>作用：可以使得其中一些W的都很小，都接近于0，削弱某个特征的影响</li>
<li>优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象</li>
<li>Ridge回归</li>
</ul>
</li>
<li>L1正则化<ul>
<li>作用：可以使得其中一些W的值直接为0，删除这个特征的影响</li>
<li>LASSO回归</li>
</ul>
</li>
</ul>
<h4 id="正则化线性模型"><a href="#正则化线性模型" class="headerlink" title="正则化线性模型"></a>正则化线性模型</h4><h5 id="岭回归（Ridge-Regression）"><a href="#岭回归（Ridge-Regression）" class="headerlink" title="岭回归（Ridge Regression）"></a>岭回归（Ridge Regression）</h5><p>岭回归是线性回归的正则化版本，即在原来的线性回归的 cost function 中添加正则项（regularization term）: </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220335.png"/> </p>
<p>以达到在拟合数据的同时，使模型权重尽可能小的目的,岭回归代价函数: </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220422.png"/> </p>
<p>α=0：岭回归退化为线性回归。 </p>
<h5 id="Lasso-Regression-Lasso-回归"><a href="#Lasso-Regression-Lasso-回归" class="headerlink" title="Lasso Regression(Lasso 回归)"></a>Lasso Regression(Lasso 回归)</h5><p>Lasso 回归是线性回归的另一种正则化版本，正则项为权值向量的ℓ1范数。</p>
<p>Lasso回归的代价函数 ：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220214.png"/></p>
<p>【注意 】</p>
<ul>
<li>Lasso Regression 的代价函数在 θi=0处是不可导的.</li>
<li>解决方法：在θi=0处用一个次梯度向量(subgradient vector)代替梯度，如下式</li>
<li><p>Lasso Regression 的次梯度向量</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220540.png"/></p>
</li>
</ul>
<p>Lasso Regression 有一个很重要的性质是：倾向于完全消除不重要的权重。</p>
<p>例如：当α 取值相对较大时，高阶多项式退化为二次甚至是线性：高阶多项式特征的权重被置为0。</p>
<p>也就是说，Lasso Regression 能够自动进行特征选择，并输出一个稀疏模型（只有少数特征的权重是非零的）。</p>
<h5 id="Elastic-Net-弹性网络"><a href="#Elastic-Net-弹性网络" class="headerlink" title="Elastic Net (弹性网络)"></a>Elastic Net (弹性网络)</h5><p>弹性网络在岭回归和Lasso回归中进行了折中，通过 <strong>混合比(mix ratio) r</strong> 进行控制， 是前两个内容的综合 ：</p>
<ul>
<li>r=0：弹性网络变为岭回归</li>
<li>r=1：弹性网络便为Lasso回归</li>
</ul>
<p>弹性网络的代价函数 ：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220637.png"/></p>
<ul>
<li><p><strong>Early Stopping</strong></p>
<p>Early Stopping 也是正则化迭代学习的方法之一。</p>
<p>其做法为：在验证错误率达到最小值的时候停止训练。</p>
</li>
<li><p><strong>选择正则化方法</strong></p>
<p> 一般来说，我们应避免使用<strong>朴素线性回归</strong>，而应对模型进行一定的正则化处理 。</p>
<ul>
<li>常用：岭回归</li>
<li>假设只有少部分特征是有用的：<ul>
<li>弹性网络</li>
<li>Lasso</li>
<li>一般来说，弹性网络的使用更为广泛。因为在特征维度高于训练样本数，或者特征是强相关的情况下，Lasso回归的表现不太稳定。</li>
</ul>
</li>
</ul>
</li>
<li><h5 id="岭回归API"><a href="#岭回归API" class="headerlink" title="岭回归API"></a>岭回归API</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, ElasticNet, Lasso</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>Ridge</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sklearn.linear_model.Ridge(alpha=<span class="number">1.0</span>, fit_intercept=<span class="literal">True</span>,solver=<span class="string">"auto"</span>, normalize=<span class="literal">False</span>)</span><br><span class="line">	具有l2正则化的线性回归</span><br><span class="line">	alpha:正则化力度，也叫 λ</span><br><span class="line">		λ取值：<span class="number">0</span>~<span class="number">1</span> <span class="number">1</span>~<span class="number">10</span></span><br><span class="line">	solver:会根据数据自动选择优化方法</span><br><span class="line">		sag:如果数据集、特征都比较大，选择该随机梯度下降优化</span><br><span class="line">	normalize:数据是否进行标准化</span><br><span class="line">		normalize=<span class="literal">False</span>:可以在fit之前调用preprocessing.StandardScaler标准化数据</span><br><span class="line">	Ridge.coef_:回归权重</span><br><span class="line">	Ridge.intercept_:回归偏置</span><br><span class="line">Ridge方法相当于SGDRegressor(penalty=<span class="string">'l2'</span>, loss=<span class="string">"squared_loss"</span>),</span><br><span class="line">只不过SGDRegressor实现了一个普通的随机梯度下降学习，推荐使用Ridge(实现了SAG)</span><br><span class="line">sklearn.linear_model.RidgeCV(_BaseRidgeCV, RegressorMixin)</span><br><span class="line">	具有l2正则化的线性回归，可以进行交叉验证</span><br><span class="line">	coef_:回归系数</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="案例-波士顿房价预测"><a href="#案例-波士顿房价预测" class="headerlink" title="案例-波士顿房价预测"></a>案例-波士顿房价预测</h4><p><strong>数据介绍：</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220738.png"/></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220745.png"/></p>
<p> <strong>案例分析：</strong></p>
<p>回归当中的数据大小不一致，是否会导致结果影响较大。所以需要做标准化处理。</p>
<ul>
<li>数据分割与标准化处理</li>
<li>回归预测</li>
<li>线性回归的算法效果评估</li>
</ul>
<p><strong>回归性能评估：</strong></p>
<p> 均方误差(Mean Squared Error)MSE)评价机制： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200223220755.png"/></p>
<p>$ y_i$为预测值，$\overline{y}$ 为真实值 </p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error(y_true, y_pred)</span><br><span class="line">	均方误差回归损失</span><br><span class="line"><span class="symbol">	y_true:</span>真实值</span><br><span class="line"><span class="symbol">	y_pred:</span>预测值</span><br><span class="line"><span class="symbol">	return:</span>浮点数结果</span><br></pre></td></tr></table></figure>
<p> <strong>代码实现：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression, SGDRegressor, Ridge, RidgeCV</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_model1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""线性回归：正规方程"""</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    boston = load_boston()</span><br><span class="line">    <span class="comment"># print(boston)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    <span class="comment"># 2.1分割数据</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target,test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归</span></span><br><span class="line">    estimator = LinearRegression()</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">"模型的偏置是：&#123;&#125;"</span>.format(estimator.intercept_))</span><br><span class="line">    print(<span class="string">"模型的系数是：&#123;&#125;"</span>.format(estimator.coef_))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1预测值</span></span><br><span class="line">    y_pre = estimator.predict(x_test)</span><br><span class="line">    <span class="comment"># print("预测值是：\n", y_pre)</span></span><br><span class="line">    <span class="comment"># 5.2均方误差</span></span><br><span class="line">    ret = mean_squared_error(y_test, y_pre)</span><br><span class="line">    print(<span class="string">"均方误差是："</span>, ret)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_model2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""线性回归：梯度下降法"""</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    boston = load_boston()</span><br><span class="line">    <span class="comment"># print(boston)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    <span class="comment"># 2.1分割数据</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归</span></span><br><span class="line">    estimator = SGDRegressor(max_iter=<span class="number">1000</span>)</span><br><span class="line">    <span class="comment"># estimator = SGDRegressor(max_iter=1000, learning_rate="constant", eta0=1)</span></span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">"模型的偏置是：&#123;&#125;"</span>.format(estimator.intercept_))</span><br><span class="line">    print(<span class="string">"模型的系数是：&#123;&#125;"</span>.format(estimator.coef_))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1预测值</span></span><br><span class="line">    y_pre = estimator.predict(x_test)</span><br><span class="line">    <span class="comment"># print("预测值是：\n", y_pre)</span></span><br><span class="line">    <span class="comment"># 5.2均方误差</span></span><br><span class="line">    ret = mean_squared_error(y_test, y_pre)</span><br><span class="line">    print(<span class="string">"均方误差是："</span>, ret)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_model3</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""线性回归：岭回归"""</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    boston = load_boston()</span><br><span class="line">    <span class="comment"># print(boston)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    <span class="comment"># 2.1分割数据</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归</span></span><br><span class="line">    <span class="comment"># estimator = Ridge(alpha=1.0)</span></span><br><span class="line">    estimator = RidgeCV()</span><br><span class="line">    estimator.fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">"模型的偏置是：&#123;&#125;"</span>.format(estimator.intercept_))</span><br><span class="line">    print(<span class="string">"模型的系数是：&#123;&#125;"</span>.format(estimator.coef_))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1预测值</span></span><br><span class="line">    y_pre = estimator.predict(x_test)</span><br><span class="line">    <span class="comment"># print("预测值是：\n", y_pre)</span></span><br><span class="line">    <span class="comment"># 5.2均方误差</span></span><br><span class="line">    ret = mean_squared_error(y_test, y_pre)</span><br><span class="line">    print(<span class="string">"均方误差是："</span>, ret)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    linear_model1()</span><br><span class="line">    linear_model2()</span><br><span class="line">    linear_model3()</span><br></pre></td></tr></table></figure>
<h4 id="模型的保存和加载"><a href="#模型的保存和加载" class="headerlink" title="模型的保存和加载"></a>模型的保存和加载</h4><ul>
<li><h5 id="sklearn模型的保存和加载API"><a href="#sklearn模型的保存和加载API" class="headerlink" title="sklearn模型的保存和加载API"></a>sklearn模型的保存和加载API</h5></li>
<li><h5 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge, RidgeCV</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dump_load</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""模型保存和加载"""</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    boston = load_boston()</span><br><span class="line">    <span class="comment"># print(boston)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.数据基本处理</span></span><br><span class="line">    <span class="comment"># 2.1分割数据</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=<span class="number">22</span>,test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.特征工程</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.机器学习-线性回归</span></span><br><span class="line">    <span class="comment"># 4.1 模型训练</span></span><br><span class="line">    <span class="comment"># estimator = Ridge(alpha=1.0)</span></span><br><span class="line">    <span class="comment"># estimator = RidgeCV()</span></span><br><span class="line">    <span class="comment"># estimator.fit(x_train, y_train)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># # 4.2 模型保存</span></span><br><span class="line">    <span class="comment"># joblib.dump(estimator, "./data/test.pkl")</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.3 模型加载</span></span><br><span class="line">    estimator = joblib.load(<span class="string">"./data/test.pkl"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"模型的偏置是：&#123;&#125;"</span>.format(estimator.intercept_))</span><br><span class="line">    print(<span class="string">"模型的系数是：&#123;&#125;"</span>.format(estimator.coef_))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.模型评估</span></span><br><span class="line">    <span class="comment"># 5.1预测值</span></span><br><span class="line">    y_pre = estimator.predict(x_test)</span><br><span class="line">    <span class="comment"># print("预测值是：\n", y_pre)</span></span><br><span class="line">    <span class="comment"># 5.2均方误差</span></span><br><span class="line">    ret = mean_squared_error(y_test, y_pre)</span><br><span class="line">    print(<span class="string">"均方误差是："</span>, ret)</span><br><span class="line"></span><br><span class="line">dump_load()</span><br></pre></td></tr></table></figure>
</li>
<li><h5 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h5><ul>
<li>1.保存文件，后缀名是**.pkl</li>
<li>2.加载模型是需要通过一个变量进行承接</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>监督学习算法</tag>
        <tag>梯度下降</tag>
        <tag>正规方程</tag>
        <tag>正则化</tag>
        <tag>岭回归</tag>
        <tag>模型保存和加载</tag>
      </tags>
  </entry>
  <entry>
    <title>knn算法</title>
    <url>/2020/01/07/knn%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h4 id="K-近邻算法定义"><a href="#K-近邻算法定义" class="headerlink" title="K-近邻算法定义"></a>K-近邻算法定义</h4><p> K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法， 总体来说KNN算法是相对比较容易理解的算法 ， 如果一个样本在特征空间中的<strong>k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别</strong>，则该样本也属于这个类别。 </p>
<a id="more"></a>
<h4 id="KNN算法流程"><a href="#KNN算法流程" class="headerlink" title="KNN算法流程"></a>KNN算法流程</h4><ol>
<li><p>计算已知类别数据集中的点与当前点之间的距离</p>
</li>
<li><p>按距离递增次序排序</p>
</li>
<li><p>选取与当前点距离最小的k个点</p>
</li>
<li><p>统计前k个点所在的类别出现的频率</p>
</li>
<li><p>返回前k个点出现频率最高的类别作为当前点的预测分类</p>
</li>
</ol>
<h4 id="k近邻算法api初步使用"><a href="#k近邻算法api初步使用" class="headerlink" title="k近邻算法api初步使用"></a>k近邻算法api初步使用</h4><p> <strong>机器学习流程 :</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span>获取数据集</span><br><span class="line"><span class="number">2.</span>数据基本处理</span><br><span class="line"><span class="number">3.</span>特征工程</span><br><span class="line"><span class="number">4.</span>机器学习</span><br><span class="line"><span class="number">5.</span>模型评估</span><br></pre></td></tr></table></figure>
<p><strong>Scikit-learn工具介绍：</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">Python语言的机器学习工具</span><br><span class="line">	Scikit-learn包括许多知名的机器学习算法的实现</span><br><span class="line">	Scikit-learn文档完善，容易上手，丰富的API</span><br><span class="line">包含内容：</span><br><span class="line">	分类、聚类、回归</span><br><span class="line">	特征工程</span><br><span class="line">	模型选择、调优</span><br><span class="line">优点：</span><br><span class="line">	文档多,且规范,包含的算法多,实现起来容易</span><br><span class="line">目前稳定版本<span class="number">0.19</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>
<p><a href="网址：https://scikit-learn.org/">Scikit-learn官网地址</a></p>
<p>K-近邻算法API**：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">	n_neighbors：<span class="built_in">int</span>,可选（默认= <span class="number">5</span>），k_neighbors查询默认使用的邻居数</span><br></pre></td></tr></table></figure>
<p><strong>小案例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据集</span></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"><span class="comment"># 2.数据基本处理（该案例中省略）</span></span><br><span class="line"><span class="comment"># 3.特征工程（该案例中省略）</span></span><br><span class="line"><span class="comment"># 4.机器学习</span></span><br><span class="line"><span class="comment"># 实例化API</span></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用fit方法进行训练</span></span><br><span class="line">estimator.fit(x, y)</span><br><span class="line"><span class="comment"># 输出预测值</span></span><br><span class="line">print(estimator.predict([[<span class="number">1</span>]]))</span><br><span class="line"><span class="comment"># 5.模型评估（该案例中省略）</span></span><br></pre></td></tr></table></figure>
<h4 id="K值选择"><a href="#K值选择" class="headerlink" title="K值选择"></a>K值选择</h4><p><strong>K值选择:</strong></p>
<p><strong>李航博士的一书「统计学习方法」上所说：</strong></p>
<ol>
<li><p>选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，<strong>K值的减小就意味着整体模型变得复杂，容易发生过拟合；</strong></p>
</li>
<li><p>选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，<strong>与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。</strong></p>
</li>
<li><p>K=N（N为训练样本个数），则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</p>
</li>
</ol>
<p>在<strong>实际应用中，K值一般取一个比较小的数值</strong>，例如采用交叉验证法（简单来说，就是把训练数据在分成两组:训练集和验证集）来选择最优的K值。</p>
<h4 id="KNN中K值选择"><a href="#KNN中K值选择" class="headerlink" title="KNN中K值选择"></a>KNN中K值选择</h4><ul>
<li>K值过小<ul>
<li>容易受到异常点的影响</li>
<li>容易过拟合</li>
</ul>
</li>
<li>k值过大：<ul>
<li>受到样本均衡的问题</li>
<li>容易欠拟合</li>
</ul>
</li>
</ul>
<h4 id="kd树"><a href="#kd树" class="headerlink" title="kd树"></a>kd树</h4><p><strong>定义:</strong></p>
<p>根据<strong>KNN</strong>每次需要预测一个点时，我们都需要计算训练数据集里每个点到这个点的距离，然后选出距离最近的k个点进行投票。<strong>当数据集很大时，这个计算成本非常高</strong>。</p>
<p><strong>kd树</strong>：为了避免每次都重新计算一遍距离，算法会把距离信息保存在一棵树里，这样在计算之前从树里查询距离信息，尽量避免重新计算。其基本原理是，<strong>如果A和B距离很远，B和C距离很近，那么A和C的距离也很远</strong>。有了这个信息，就可以在合适的时候跳过距离远的点。</p>
<p> <strong>最近邻域搜索:</strong></p>
<p>  kd树(K-dimension tree)是<strong>一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。</strong>kd树是一种二叉树，表示对k维空间的一个划分，<strong>构造kd树相当于不断地用垂直于坐标轴的超平面将K维空间切分，构成一系列的K维超矩形区域</strong>。kd树的每个结点对应于一个k维超矩形区域。<strong>利用kd树可以省去对大部分数据点的搜索，从而减少搜索的计算量。</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150641.png"/></p>
<p><strong>构造方法:</strong></p>
<ol>
<li><p><strong>构造根结点，使根结点对应于K维空间中包含所有实例点的超矩形区域；</strong></p>
</li>
<li><p><strong>通过递归的方法，不断地对k维空间进行切分，生成子结点。</strong>在超矩形区域上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域（子结点）；这时，实例被分到两个子区域。</p>
</li>
<li><p><strong>上述过程直到子区域内没有实例时终止（终止时的结点为叶结点）</strong>。在此过程中，将实例保存在相应的结点上。</p>
</li>
<li><p>通常，循环的选择坐标轴对空间切分，选择训练实例点在坐标轴上的中位数为切分点，这样得到的kd树是平衡的（平衡二叉树：它是一棵空树，或其左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是平衡二叉树）。</p>
</li>
</ol>
<p>KD树中每个节点是一个向量，和二叉树按照数的大小划分不同的是，KD树每层需要选定向量中的某一维，然后根据这一维按左小右大的方式划分数据。在构建KD树时，关键需要解决2个问题：</p>
<ol>
<li><p><strong>选择向量的哪一维进行划分；</strong></p>
<p>解决方法可以是随机选择某一维或按顺序选择，但是<strong>更好的方法应该是在数据比较分散的那一维进行划分（分散的程度可以根据方差来衡量）</strong></p>
</li>
<li><p><strong>如何划分数据；</strong></p>
<p>好的划分方法可以使构建的树比较平衡，可以每次选择中位数来进行划分。</p>
<p><strong>kd树的搜索过程:</strong></p>
</li>
</ol>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 二叉树搜索比较待查询节点和分裂节点的分裂维的值，（小于等于就进入左子树分支，大于就进入右子树分支直到叶子结点）</span><br><span class="line"><span class="number">2.</span> 顺着“搜索路径”找到最近邻的近似点</span><br><span class="line"><span class="number">3.</span> 回溯搜索路径，并判断搜索路径上的结点的其他子结点空间中是否可能有距离查询点更近的数据点，如果有可能，则需要跳到其他子结点空间中去搜索</span><br><span class="line"><span class="number">4.</span> 重复这个过程直到搜索路径为空</span><br></pre></td></tr></table></figure>
<h4 id="scikit-learn中数据集"><a href="#scikit-learn中数据集" class="headerlink" title="scikit-learn中数据集"></a>scikit-learn中数据集</h4><p>scikit-learn数据集API</p>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">sklearn.datasets</span><br><span class="line">	加载获取流行数据集</span><br><span class="line">	datasets.load_*()</span><br><span class="line">		获取小规模数据集，数据包含在datasets里</span><br><span class="line">	datasets.fetch_*(dat<span class="built_in">a_home</span>=None)</span><br><span class="line">		获取大规模数据集，需要从网络上下载，</span><br><span class="line">		函数的第一个参数是dat<span class="built_in">a_home</span>，表示数据集下载的目录,</span><br><span class="line">		默认是 ~/scikit_learn_data/</span><br></pre></td></tr></table></figure>
<p><strong>sklearn小数据集</strong></p>
<ul>
<li>sklearn.datasets.load_iris()：加载并返回鸢尾花数据集</li>
</ul>
<p><strong>sklearn大数据集</strong></p>
<ul>
<li>sklearn.datasets.fetch_20newsgroups(data_home=None,subset=‘train’)<ul>
<li>subset：’train’或者’test’，’all’，可选，选择要加载的数据集。</li>
<li>训练集的“训练”，测试集的“测试”，两者的“全部”</li>
</ul>
</li>
</ul>
<p><strong>sklearn数据集返回值</strong></p>
<ul>
<li>load和fetch返回的数据类型datasets.base.Bunch(字典格式)<ul>
<li>data：特征数据数组，是 [n_samples * n_features] 的二维 numpy.ndarray 数组</li>
<li>target：标签数组，是 n_samples 的一维 numpy.ndarray 数组</li>
<li>DESCR：数据描述</li>
<li>feature_names：特征名,新闻数据，手写数字、回归数据集没有</li>
<li>target_names：标签名</li>
</ul>
</li>
</ul>
<p><strong>查看数据分布</strong></p>
<p>通过创建一些图，以查看不同类别是如何通过特征来区分的。 在理想情况下，标签类将由一个或多个特征对完美分隔。 在现实世界中，这种理想情况很少会发生。</p>
<ul>
<li>seaborn介绍<ul>
<li>Seaborn 是基于 Matplotlib 核心库进行了更高级的 API 封装，可以让你轻松地画出更漂亮的图形。而 Seaborn 的漂亮主要体现在配色更加舒服、以及图形元素的样式更加细腻。</li>
<li>安装 pip3 install seaborn</li>
<li>seaborn.lmplot() 是一个非常有用的方法，它会在绘制二维散点图时，自动完成回归拟合<ul>
<li>sns.lmplot() 里的 x, y 分别代表横纵坐标的列名,</li>
<li>data= 是关联到数据集,</li>
<li>hue=*代表按照 species即花的类别分类显示,</li>
<li>fit_reg=是否进行线性拟合。</li>
</ul>
</li>
<li><a href="http://seaborn.pydata.org/" target="_blank" rel="noopener">参考链接: api链接</a></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline  </span><br><span class="line"><span class="comment"># 内嵌绘图</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把数据转换成dataframe的格式</span></span><br><span class="line">iris_d = pd.DataFrame(iris[<span class="string">'data'</span>], columns = [<span class="string">'Sepal_Length'</span>, <span class="string">'Sepal_Width'</span>, <span class="string">'Petal_Length'</span>, <span class="string">'Petal_Width'</span>])</span><br><span class="line">iris_d[<span class="string">'Species'</span>] = iris.target</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_iris</span><span class="params">(iris, col1, col2)</span>:</span></span><br><span class="line">    sns.lmplot(x = col1, y = col2, data = iris, hue = <span class="string">"Species"</span>, fit_reg = <span class="literal">False</span>)</span><br><span class="line">    plt.xlabel(col1)</span><br><span class="line">    plt.ylabel(col2)</span><br><span class="line">    plt.title(<span class="string">'鸢尾花种类分布图'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">plot_iris(iris_d, <span class="string">'Petal_Width'</span>, <span class="string">'Sepal_Length'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150704.png"/> </p>
<h4 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h4><p>机器学习一般的数据集会划分为两个部分：</p>
<ul>
<li>训练数据：用于训练，<strong>构建模型</strong></li>
<li>测试数据：在模型检验时使用，用于<strong>评估模型是否有效</strong></li>
</ul>
<p>划分比例：</p>
<ul>
<li>训练集：70% 80% 75%</li>
<li>测试集：30% 20% 25%</li>
</ul>
<p><strong>数据集划分api</strong></p>
<ul>
<li>sklearn.model_selection.train_test_split(arrays, *options)<ul>
<li>参数：<ul>
<li>x 数据集的特征值</li>
<li>y 数据集的标签值</li>
<li>test_size 测试集的大小，一般为float</li>
<li>random_state 随机数种子,不同的种子会造成不同的随机采样结果。相同的种子采样结果相同。</li>
</ul>
</li>
<li>return<ul>
<li>x_train, x_test, y_train, y_test</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 1、获取鸢尾花数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment"># 对鸢尾花数据集进行分割</span></span><br><span class="line"><span class="comment"># 训练集的特征值x_train 测试集的特征值x_test 训练集的目标值y_train 测试集的目标值y_test</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line">print(<span class="string">"x_train:\n"</span>, x_train.shape)</span><br><span class="line"><span class="comment"># 随机数种子</span></span><br><span class="line">x_train1, x_test1, y_train1, y_test1 = train_test_split(iris.data, iris.target, random_state=<span class="number">6</span>)</span><br><span class="line">x_train2, x_test2, y_train2, y_test2 = train_test_split(iris.data, iris.target, random_state=<span class="number">6</span>)</span><br><span class="line">print(<span class="string">"如果随机数种子不一致：\n"</span>, x_train == x_train1)</span><br><span class="line">print(<span class="string">"如果随机数种子一致：\n"</span>, x_train1 == x_train2)</span><br></pre></td></tr></table></figure>
<h4 id="特征工程-特征预处理"><a href="#特征工程-特征预处理" class="headerlink" title="特征工程-特征预处理"></a>特征工程-特征预处理</h4><p><strong>定义：</strong></p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">scikit-learn的解释</span><br><span class="line">provides several common utility functions <span class="keyword">and</span> transformer classes <span class="keyword">to</span> change<span class="built_in"> raw </span>feature vectors into a representation that is more suitable <span class="keyword">for</span> the downstream estimators.</span><br><span class="line">翻译过来：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150714.png"/></p>
<p> <strong>特征预处理API</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">sklearn</span><span class="selector-class">.preprocessing</span></span><br></pre></td></tr></table></figure>
<p><strong>包含内容</strong></p>
<ul>
<li><p>归一化</p>
<ul>
<li>鲁棒性比较差(容易受到异常点的影响)</li>
<li>只适合传统精确小数据场景(以后基本不会用)</li>
</ul>
</li>
<li><p>标准化</p>
<ul>
<li>异常值对我影响小</li>
<li>适合现代嘈杂大数据场景</li>
</ul>
</li>
</ul>
<p><strong>归一化/标准化原因</strong></p>
<p>  特征的<strong>单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级</strong>，<strong>容易影响（支配）目标结果</strong>，使得一些算法无法学习到其它的特征 。所以 我们需要用到一些方法进行<strong>无量纲化</strong>，<strong>使不同规格的数据转换到同一规格</strong>。</p>
<p><strong>归一化：</strong> 通过对原始数据进行变换把数据映射到(默认为[0,1])之间。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222151230.png"/></p>
<p> <strong>API:</strong></p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler (feature_range=(<span class="number">0</span>,<span class="number">1</span>)… )</span><br><span class="line">	<span class="module-access"><span class="module"><span class="identifier">MinMaxScalar</span>.</span></span>fit<span class="constructor">_transform(X)</span></span><br><span class="line">		X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">	返回值：转换后的形状相同的<span class="built_in">array</span></span><br></pre></td></tr></table></figure>
<p><strong>标准化：</strong> 通过对原始数据进行变换把数据变换到均值为0,标准差为1范围内 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222151305.png"/></p>
<ul>
<li>对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变</li>
<li><p>对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小</p>
<p><strong>API:</strong></p>
</li>
</ul>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.preprocessing.<span class="constructor">StandardScaler( )</span></span><br><span class="line">	处理之后每列来说所有数据都聚集在均值<span class="number">0</span>附近标准差差为<span class="number">1</span></span><br><span class="line">	<span class="module-access"><span class="module"><span class="identifier">StandardScaler</span>.</span></span>fit<span class="constructor">_transform(X)</span></span><br><span class="line">		X:numpy <span class="built_in">array</span>格式的数据<span class="literal">[<span class="identifier">n_samples</span>,<span class="identifier">n_features</span>]</span></span><br><span class="line">	返回值：转换后的形状相同的<span class="built_in">array</span></span><br></pre></td></tr></table></figure>
<h4 id="交叉验证，网格搜索"><a href="#交叉验证，网格搜索" class="headerlink" title="交叉验证，网格搜索"></a>交叉验证，网格搜索</h4><p><strong>交叉验证：</strong> 将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成4份，其中一份作为验证集。然后经过4次(组)的测试，每次都更换不同的验证集。即得到4组模型的结果，取平均值作为最终结果。又称4折交叉验证。 </p>
<p>数据分为训练集和测试集，但是<strong>为了让从训练得到模型结果更加准确。</strong>做以下处理</p>
<ul>
<li>训练集：训练集+验证集</li>
<li>测试集：测试集</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222151310.png"/></p>
<p><strong>网格搜索：</strong> 通常情况下，<strong>有很多参数是需要手动指定的（如k-近邻算法中的K值），这种叫超参数</strong>。但是手动过程繁杂，所以需要对模型预设几种超参数组合。<strong>每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</strong> </p>
<p><strong>API</strong></p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">sklearn.model_selection.<span class="constructor">GridSearchCV(<span class="params">estimator</span>, <span class="params">param_grid</span>=None,<span class="params">cv</span>=None)</span></span><br><span class="line">	对估计器的指定参数值进行详尽搜索</span><br><span class="line">	estimator：估计器对象</span><br><span class="line">	param_grid：估计器参数(dict)&#123;“n_neighbors”:<span class="literal">[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>]</span>&#125;</span><br><span class="line">	cv：指定几折交叉验证</span><br><span class="line">	fit：输入训练数据</span><br><span class="line">	score：准确率</span><br><span class="line">结果分析：</span><br><span class="line">	bestscore__:在交叉验证中验证的最好结果</span><br><span class="line">	bestestimator：最好的参数模型</span><br><span class="line">	cvresults:每次交叉验证后的验证集准确率结果和训练集准确率结果</span><br></pre></td></tr></table></figure>
<h4 id="案例1-鸢尾花种类预测"><a href="#案例1-鸢尾花种类预测" class="headerlink" title="案例1-鸢尾花种类预测"></a>案例1-鸢尾花种类预测</h4><p> Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。关于数据集的具体介绍： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222151318.png"/></p>
<p> <strong>代码实现：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、获取数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、数据基本处理 -- 划分数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、特征工程：标准化</span></span><br><span class="line"><span class="comment"># 实例化一个转换器类</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 调用fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、KNN预估器流程</span></span><br><span class="line"><span class="comment">#  4.1 实例化预估器类</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 4.2 模型选择与调优——网格搜索和交叉验证</span></span><br><span class="line"><span class="comment"># 准备要调的超参数</span></span><br><span class="line">param_dict = &#123;<span class="string">"n_neighbors"</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 4.3 fit数据进行训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、评估模型效果</span></span><br><span class="line"><span class="comment"># 方法a：比对预测结果和真实值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line">print(<span class="string">"比对预测结果和真实值：\n"</span>, y_predict == y_test)</span><br><span class="line"><span class="comment"># 方法b：直接计算准确率</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line">print(<span class="string">"直接计算准确率：\n"</span>, score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后进行评估查看最终选择的结果和交叉验证的结果</span></span><br><span class="line">print(<span class="string">"在交叉验证中验证的最好结果：\n"</span>, estimator.best_score_)</span><br><span class="line">print(<span class="string">"最好的参数模型：\n"</span>, estimator.best_estimator_)</span><br><span class="line">print(<span class="string">"每次交叉验证后的准确率结果：\n"</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure>
<h4 id="案例2-预测facebook签到位置"><a href="#案例2-预测facebook签到位置" class="headerlink" title="案例2-预测facebook签到位置"></a>案例2-预测facebook签到位置</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222151341.png"/></p>
<p> 本次比赛的目的是<strong>预测一个人将要签到的地方。</strong> 为了本次比赛，Facebook创建了一个虚拟世界，其中包括<strong>10公里*10公里共100平方公里的约10万个地方。</strong> 对于给定的坐标集，您的任务将<strong>根据用户的位置，准确性和时间戳等预测用户下一次的签到位置。</strong> 数据被制作成类似于来自移动设备的位置数据。 请注意：您只能使用提供的数据进行预测。 </p>
<p><strong>数据集介绍：</strong></p>
<p> <img src="knn%E7%AE%97%E6%B3%95/facebook%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D.png" alt="image-20190515120143596"> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">文件说明 train.csv, test.csv</span><br><span class="line">  row id：签入事件的id</span><br><span class="line">  x y：坐标</span><br><span class="line">  accuracy: 准确度，定位精度</span><br><span class="line">  time: 时间戳</span><br><span class="line">  place_id: 签到的位置，这也是你需要预测的内容</span><br></pre></td></tr></table></figure>
<p><strong>数据来源：</strong> 官网：<a href="https://www.kaggle.com/navoshta/grid-knn/data" target="_blank" rel="noopener">https://www.kaggle.com/navoshta/grid-knn/data</a> </p>
<p><strong>步骤分析：</strong></p>
<ul>
<li>对于数据做一些基本处理（这里所做的一些处理不一定达到很好的效果，我们只是简单尝试，有些特征我们可以根据一些特征选择的方式去做处理）<ul>
<li>1 缩小数据集范围 DataFrame.query()</li>
<li>2 选取有用的时间特征</li>
<li>3 将签到位置少于n个用户的删除</li>
</ul>
</li>
<li>分割数据集</li>
<li>标准化处理</li>
<li>k-近邻预测</li>
</ul>
<p><strong>代码实现：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取数据集</span></span><br><span class="line">facebook = pd.read_csv(<span class="string">"./data/FBlocation/train.csv"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.基本数据处理</span></span><br><span class="line"><span class="comment"># 2.1 缩小数据范围</span></span><br><span class="line">facebook_data = facebook.query(<span class="string">"x&gt;2.0 &amp; x&lt;2.2 &amp; y&gt;2.0 &amp; y&lt;2.2"</span>)</span><br><span class="line"><span class="comment"># 2.2 选择时间特征(脱敏)</span></span><br><span class="line">time = pd.to_datetime(facebook_data[<span class="string">"time"</span>], unit=<span class="string">"s"</span>)</span><br><span class="line"><span class="comment"># 转换</span></span><br><span class="line">time = pd.DatetimeIndex(time)</span><br><span class="line">facebook_data[<span class="string">"day"</span>] = time.day</span><br><span class="line">facebook_data[<span class="string">"hour"</span>] = time.hour</span><br><span class="line">facebook_data[<span class="string">"weekday"</span>] = time.weekday</span><br><span class="line"><span class="comment"># 2.3 去掉签到较少的地方</span></span><br><span class="line">place_count = facebook_data.groupby(<span class="string">"place_id"</span>).count()</span><br><span class="line">place_count = place_count[place_count[<span class="string">"row_id"</span>]&gt;<span class="number">3</span>]</span><br><span class="line">facebook_data = facebook_data[facebook_data[<span class="string">"place_id"</span>]].isin(place_count.index)</span><br><span class="line"><span class="comment"># 2.4 确定特征值和目标值</span></span><br><span class="line">x = facebook_data[[<span class="string">"x"</span>, <span class="string">"y"</span>, <span class="string">"accuracy"</span>, <span class="string">"day"</span>, <span class="string">"hour"</span>, <span class="string">"weekday"</span>]]</span><br><span class="line">y = facebook_data[<span class="string">"place_id"</span>]</span><br><span class="line"><span class="comment"># 2.5 分割数据集</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.特征工程 -- 特征预处理(标准化)</span></span><br><span class="line"><span class="comment"># 3.1 实例化一个转换器</span></span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"><span class="comment"># 3.2 调用fit_transform</span></span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.机器学习 -- knn+cv</span></span><br><span class="line"><span class="comment"># 4.1 实例化一个训练器</span></span><br><span class="line">estimator = KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 4.2 交叉验证，网格搜索实现，调用gridsearchCV</span></span><br><span class="line">param_grid = &#123;<span class="string">"n_neighbors"</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]&#125;</span><br><span class="line"><span class="comment"># n_jobs：指定几个CPU跑程序</span></span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_grid, cv=<span class="number">5</span>, n_jobs=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 4.3 模型训练</span></span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.模型评估</span></span><br><span class="line"><span class="comment"># 5.1 基本评估方式</span></span><br><span class="line">score = estimator.score(x_test, y_test)</span><br><span class="line">print(<span class="string">"最后预测的准确率为:\n"</span>, score)</span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line">print(<span class="string">"最后的预测值为:\n"</span>, y_predict)</span><br><span class="line">print(<span class="string">"预测值和真实值的对比情况:\n"</span>, y_predict == y_test)</span><br><span class="line"><span class="comment"># 5.2 使用交叉验证后的评估方式</span></span><br><span class="line">print(<span class="string">"在交叉验证中验证的最好结果:\n"</span>, estimator.best_score_)</span><br><span class="line">print(<span class="string">"最好的参数模型:\n"</span>, estimator.best_estimator_)</span><br><span class="line">print(<span class="string">"每次交叉验证后的验证集准确率结果和训练集准确率结果:\n"</span>,estimator.cv_results_)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习算法</category>
      </categories>
      <tags>
        <tag>机器学习算法</tag>
        <tag>机器学习</tag>
        <tag>监督学习算法</tag>
        <tag>特征工程</tag>
        <tag>特征工程预处理</tag>
        <tag>交叉验证网格搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>距离度量</title>
    <url>/2020/01/06/%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F/</url>
    <content><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p> 机器学习中常见的距离计算公式 </p>
<a id="more"></a>
<h4 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h4><p>欧氏距离(<strong>Euclidean Distance</strong>)是最容易直观理解的距离度量方法，我们小学、初中和高中接触到的两个点在空间中的距离一般都是指欧氏距离。 </p>
<p><strong>公式</strong>：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222012326.png"/> </p>
<h4 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h4><p>在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离(<strong>Manhattan Distance</strong>)也称为“城市街区距离”(City Block distance)。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222012631.png"/></p>
<p>  <strong>公式</strong>：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222012805.png"/> </p>
<h4 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h4><p>国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻8个方格中的任意一个。国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步？这个距离就叫切比雪夫距离（<strong>Chebyshev Distance</strong>）。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222012850.png"/></p>
<p><strong>公式</strong>：</p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222012935.png"/> </p>
<h4 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h4><p>闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述。</p>
<p>两个n维变量a(x11,x12,…,x1n)与b(x21,x22,…,x2n)间的闵可夫斯基距离（<strong>Minkowski Distance</strong>）定义为：</p>
<p><strong>公式</strong>：</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222013016.png"/></p>
<p>其中p是一个变参数：</p>
<p>当p=1时，就是曼哈顿距离；</p>
<p>当p=2时，就是欧氏距离；</p>
<p>当p→∞时，就是切比雪夫距离。</p>
<p>根据p的不同，闵氏距离可以表示某一类/种的距离。</p>
<p><strong>闵氏距离的缺点：</strong></p>
<ol>
<li><p>将各个分量的量纲(scale)，也就是“单位”相同的看待了;</p>
</li>
<li><p>未考虑各个分量的分布（期望，方差等）可能是不同的。</p>
</li>
</ol>
<h4 id="标准化欧氏距离"><a href="#标准化欧氏距离" class="headerlink" title="标准化欧氏距离"></a>标准化欧氏距离</h4><p>标准化欧氏距离(<strong>Standardized EuclideanDistance</strong>)是针对欧氏距离的缺点而作的一种改进。</p>
<p>思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差相等。</p>
<p> $S_k$表示各个维度的标准差</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222013054.png"/> </p>
<h4 id="余弦距离"><a href="#余弦距离" class="headerlink" title="余弦距离"></a>余弦距离</h4><p>几何中，夹角余弦可用来衡量两个向量方向的差异；机器学习中，借用这一概念来衡量样本向量之间的差异。 </p>
<ul>
<li><p>二维空间中向量$A(x_1,y_1)$与向量$B(x_2,y_2)$的夹角余弦公式： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222013230.png"/></p>
</li>
<li><p>两个n维样本点$a(x11,x12,…,x1n)$和$b(x21,x22,…,x2n)$的夹角余弦为： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014044.png"/></p>
</li>
</ul>
<h4 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h4><p>两个等长字符串s1与s2的汉明距离（<strong>Hamming Distance</strong>）为：将其中一个变为另外一个所需要作的最小字符替换次数。 </p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014217.png"/></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">求下列字符串的汉明距离：</span><br><span class="line"><span class="number">1011101</span>与 <span class="number">1001001</span> <span class="number">1111111</span> <span class="number">1101011</span> <span class="number">7</span><span class="number">-5</span>=<span class="number">2</span></span><br><span class="line"><span class="number">2143896</span>与 <span class="number">2233796</span> <span class="number">1111111</span> <span class="number">1001011</span> <span class="number">7</span><span class="number">-4</span>=<span class="number">3</span> </span><br><span class="line">irie与 rise <span class="number">1111</span> <span class="number">0001</span> <span class="number">4</span><span class="number">-1</span>=<span class="number">3</span></span><br></pre></td></tr></table></figure>
<h4 id="杰卡德距离"><a href="#杰卡德距离" class="headerlink" title="杰卡德距离"></a>杰卡德距离</h4><p>杰卡德相似系数(<strong>Jaccard similarity coefficient</strong>)：两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014303.png"/></p>
<p> 杰卡德距离(<strong>Jaccard Distance</strong>)：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014335.png"/></p>
<h4 id="马氏距离"><a href="#马氏距离" class="headerlink" title="马氏距离"></a>马氏距离</h4><p>下图有两个正态分布图，它们的均值分别为a和b，但方差不一样，则图中的A点离哪个总体更近？或者说A有更大的概率属于谁？显然，A离左边的更近，A属于左边总体的概率更大，尽管A与a的欧式距离远一些。这就是马氏距离的直观解释。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014412.png"/></p>
<p>马氏距离是基于样本分布的一种距离。</p>
<p>马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个位置样本集的相似度的方法。</p>
<p>与欧式距离不同的是，它考虑到各种特性之间的联系，即独立于测量尺度。</p>
<p><strong>马氏距离定义：</strong>设总体G为m维总体（考察m个指标），均值向量为$μ=(μ1，μ2，… …，μm,)$，协方差阵为$∑=(σij)$,</p>
<p>则样本$X=(X1，X2，… …，Xm，)$与总体G的马氏距离定义为：</p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014453.png"/></p>
<p>马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为∑的随机变量的差异程度：如果协方差矩阵为单位矩阵，马氏距离就简化为欧式距离；如果协方差矩阵为对角矩阵，则其也可称为正规化的欧式距离。 </p>
<p><strong>马氏距离特性：</strong></p>
<ol>
<li><p><strong>量纲无关</strong>，排除变量之间的相关性的干扰；</p>
</li>
<li><p><strong>马氏距离的计算是建立在总体样本的基础上的</strong>，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；</p>
</li>
<li><p>计算马氏距离过程中，<strong>要求总体样本数大于样本的维数</strong>，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。</p>
</li>
<li><p>还有一种情况，满足了条件总体样本数大于样本的维数，但是协方差矩阵的逆矩阵仍然不存在，比如三个样本点$（3，4），（5，6），（7，8）$，这种情况是因为这三个样本在其所处的二维空间平面内共线。这种情况下，也采用欧式距离计算。</p>
<p><strong>欧式距离&amp;马氏距离：</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014529.png"/></p>
</li>
</ol>
<p>举例：</p>
<p>已知有两个类G1和G2，比如G1是设备A生产的产品，G2是设备B生产的同类产品。设备A的产品质量高（如考察指标为耐磨度X），其平均耐磨度μ1=80，反映设备精度的方差σ2(1)=0.25;设备B的产品质量稍差，其平均耐磨损度μ2=75，反映设备精度的方差σ2(2)=4.</p>
<p>今有一产品G0，测的耐磨损度X0=78，试判断该产品是哪一台设备生产的？</p>
<p>直观地看，X0与μ1（设备A）的绝对距离近些，按距离最近的原则，是否应把该产品判断设备A生产的？</p>
<p>考虑一种相对于分散性的距离，记X0与G1，G2的相对距离为d1，d2,则：</p>
<p>  <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014622.png"/></p>
<p>因为d2=1.5 &lt; d1=4，按这种距离准则，应判断X0为设备B生产的。</p>
<p>设备B生产的产品质量较分散，出现X0为78的可能性较大；而设备A生产的产品质量较集中，出现X0为78的可能性较小。</p>
<p>这种相对于分散性的距离判断就是马氏距离。</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014741.png"/></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>距离计算公式</tag>
      </tags>
  </entry>
  <entry>
    <title>查找算法</title>
    <url>/2020/01/06/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h4 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h4><p>搜索是在一个项目集合中找到一个特定项目的算法过程。搜索通常的答案是真的或假的，因为该项目是否存在。 搜索的八大查找算法：顺序查找，二分查找，插值查找，分块查找， 斐波那契查找，树表查找，哈希查找。</p>
<a id="more"></a>
<h4 id="顺序查找"><a href="#顺序查找" class="headerlink" title="顺序查找"></a>顺序查找</h4><p><strong>1. 定义</strong></p>
<p> 顺序查找是按照序列原有顺序对数组进行遍历比较查询的基本查找算法。  对于任意一个序列以及一个给定的元素，将给定元素与序列中元素依次比较，直到找出与给定关键字相同的元素，或者将序列中的元素与其都比较完为止。 </p>
<p><strong>2. 图示</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150023.png"/></p>
<p><strong>3. 代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">order_search</span><span class="params">(arr, value)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="keyword">if</span> value == i:</span><br><span class="line">            print(<span class="string">"在列表中找到该值&#123;&#125;"</span>.format(value))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"没找到该值"</span>)</span><br><span class="line"></span><br><span class="line">arr = [<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"e"</span>, <span class="string">"f"</span>, <span class="string">"g"</span>]</span><br><span class="line">order_search(arr, <span class="string">"f"</span>)</span><br><span class="line">order_search(arr, <span class="string">"d"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>4. 适用</strong></p>
<p> 无序表查找，也就是数据不排序的线性查找，遍历数据元素 </p>
<h4 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h4><p><strong>定义</strong></p>
<p>二分查找又称折半查找，优点是比较次数少，查找速度快，平均性能好；其缺点是要求待查表为有序表，且插入删除困难。因此，折半查找方法适用于不经常变动而查找频繁的有序列表。首先，假设表中元素是按升序排列，将表中间位置记录的关键字与查找关键字比较，如果两者相等，则查找成功；否则利用中间位置记录将表分成前、后两个子表，如果中间位置记录的关键字大于查找关键字，则进一步查找前一子表，否则进一步查找后一子表。重复以上过程，直到找到满足条件的记录，使查找成功，或直到子表不存在为止，此时查找不成功。 </p>
<p><strong>图示</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150051.png"/></p>
<p><strong>代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 非递归实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search1</span><span class="params">(alist, item)</span>:</span></span><br><span class="line">    first = <span class="number">0</span></span><br><span class="line">    last = len(alist) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> first &lt;= last:</span><br><span class="line">        midpoint = (first + last) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> alist[midpoint] == item:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> item &lt; alist[midpoint]:</span><br><span class="line">            last = midpoint - <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            first = midpoint + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">testlist = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">13</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">32</span>, <span class="number">42</span>, <span class="number">78</span>]</span><br><span class="line">print(binary_search1(testlist, <span class="number">3</span>))</span><br><span class="line">print(binary_search1(testlist, <span class="number">13</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search2</span><span class="params">(alist, item)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(alist) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        midpoint = len(alist)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> alist[midpoint]==item:</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">if</span> item&lt;alist[midpoint]:</span><br><span class="line">            <span class="keyword">return</span> binary_search2(alist[:midpoint],item)</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> binary_search2(alist[midpoint+<span class="number">1</span>:],item)</span><br><span class="line"></span><br><span class="line">testlist = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">13</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">32</span>, <span class="number">42</span>, <span class="number">78</span>]</span><br><span class="line">print(binary_search2(testlist, <span class="number">3</span>))</span><br><span class="line">print(binary_search2(testlist, <span class="number">13</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># leecode: 二分查找</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, nums, target)</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = len(nums)<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span>(left&lt;=right):</span><br><span class="line">            midpoint = left + int((right-left)/<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> nums[midpoint]==target:</span><br><span class="line">                <span class="keyword">return</span> midpoint</span><br><span class="line">            <span class="keyword">if</span> target&lt;nums[midpoint]:</span><br><span class="line">                right = midpoint <span class="number">-1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = midpoint+<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">alist = [<span class="number">-1</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">12</span>]</span><br><span class="line">Binary = Solution()</span><br><span class="line">result= Binary.search(nums=alist, target=<span class="number">9</span>)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p><strong>4. 适用</strong></p>
<p> 有序表查找，查找表中的数据必须按某个主键进行某种排序。  需要频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作，不建议适用二分查找。</p>
<h4 id="插值查找"><a href="#插值查找" class="headerlink" title="插值查找"></a>插值查找</h4><p><strong>1. 定义</strong></p>
<p> 二分查找每次都是从中间开始，没有考虑数据之间的关系，这是一种比较低效的实现方法，插值查找基于二分查找，改进的中间记录的选取  ，将查找点的选择改进为自适应选择，可以提高查找效率。  </p>
<p><strong>2. 图示</strong></p>
<p>和二分查找一样但是中间值选择方式不同为自适应选择</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150051.png"/></p>
<p><strong>3. 代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 递归实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inter_search</span><span class="params">(alist, item, low)</span>:</span></span><br><span class="line">    hight = len(alist)<span class="number">-1</span></span><br><span class="line">    <span class="keyword">if</span> alist[low]==item:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> alist[hight] == item:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> len(alist) &lt;= <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> alist[hight]-alist[low] != <span class="number">0</span>:</span><br><span class="line">            midpoint = int(low+(hight-low)*(item-alist[low])/(alist[hight]-alist[low]))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            midpoint = len(alist)//<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> alist[midpoint]==item:</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">if</span> item&lt;alist[midpoint]:</span><br><span class="line">            <span class="keyword">return</span> inter_search(alist[:midpoint],item, <span class="number">0</span>)</span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> inter_search(alist[midpoint+<span class="number">1</span>:],item, midpoint+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">testlist = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">13</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">32</span>, <span class="number">42</span>, <span class="number">78</span>]</span><br><span class="line">print(inter_search(testlist, <span class="number">3</span>, <span class="number">0</span>))</span><br><span class="line">print(inter_search(testlist, <span class="number">13</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># leecode 二分查找</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span><span class="params">(self, nums, target)</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = len(nums)<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span>(left&lt;=right):</span><br><span class="line">            <span class="keyword">if</span> nums[right]-nums[left] != <span class="number">0</span>:</span><br><span class="line">                midpoint = left + int((right - left)*(target-nums[left])/(nums[right]-nums[left]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                midpoint = left + int((right-left)/<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> nums[midpoint]==target:</span><br><span class="line">                <span class="keyword">return</span> midpoint</span><br><span class="line">            <span class="keyword">if</span> target&lt;nums[midpoint]:</span><br><span class="line">                right = midpoint <span class="number">-1</span></span><br><span class="line">            <span class="keyword">if</span> target&lt;nums[midpoint]:</span><br><span class="line">                right = midpoint <span class="number">-1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = midpoint+<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br></pre></td></tr></table></figure>
<p><strong>4. 适用</strong></p>
<p> 表比较大，而关键字分布比较均匀的查找，插值算法的平均性能比折半查找要好很多。反之，线性表中记录分布不均匀，用插值查找未必是很好的选择。 </p>
<h4 id="分块查找"><a href="#分块查找" class="headerlink" title="分块查找"></a>分块查找</h4><p><strong>1. 定义</strong></p>
<p>分块查找，又称为索引顺序查找，吸取了顺序查找和折半查找各自的优点，既有动态结构，又适合快速查找。将查找表分为若干个子块。块内元素可以无序，但块之间是有序的，即第一个块中的最小关键字小于第二个块中的所有记录的关键字，第二个块中的最大关键字小于第三个块中的所有记录的关键字，以此类推。在建立一个索引表，索引表中的每个元素含有各块的最大关键字和各块中第一个元素的地址，索引表按关键字有序排列。</p>
<p><strong>2. 图示</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222150227.png"/></p>
<p><strong>3. 代码实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>4. 适用</strong></p>
<p> 要求是顺序表，分块查找又称索引顺序查找，它是顺序查找的一种改进方法，分块查找算法的效率介于顺序查找和二分查找之间。 </p>
<h4 id="斐波那契查找"><a href="#斐波那契查找" class="headerlink" title="斐波那契查找"></a>斐波那契查找</h4><p><strong>1.定义</strong></p>
<p><strong>2.图示</strong></p>
<p><strong>3.代码实现</strong></p>
<p><strong>4. 适用</strong></p>
<h4 id="树表查找"><a href="#树表查找" class="headerlink" title="树表查找"></a>树表查找</h4><p><strong>1.定义</strong></p>
<p><strong>2.图示</strong></p>
<p><strong>3.代码实现</strong></p>
<p><strong>4. 适用</strong></p>
<h4 id="哈希查找"><a href="#哈希查找" class="headerlink" title="哈希查找"></a>哈希查找</h4><p><strong>1.定义</strong></p>
<p><strong>2.图示</strong></p>
<p><strong>3.代码实现</strong></p>
<p><strong>4. 适用</strong></p>
<h4 id="时间复杂度对比"><a href="#时间复杂度对比" class="headerlink" title="时间复杂度对比"></a>时间复杂度对比</h4>]]></content>
      <categories>
        <category>搜索查找算法</category>
      </categories>
      <tags>
        <tag>搜索查找算法</tag>
      </tags>
  </entry>
  <entry>
    <title>基数排序</title>
    <url>/2020/01/05/%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p> 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。 </p>
<a id="more"></a>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>取得数组中的最大数，并取得位数；</li>
<li>arr为原始数组，从最低位开始取每个位组成radix数组；</li>
<li>对radix进行计数排序（利用计数排序适用于小范围数的特点）；</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#基于桶排序的基数排序</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">radixSort</span><span class="params">(list)</span>:</span></span><br><span class="line">    d = len(str(max(list)))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(d):<span class="comment">#d轮排序</span></span><br><span class="line">        s=[[] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]<span class="comment">#因为每一位数字都是0~9，故建立10个桶</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> list:</span><br><span class="line">            s[int(i/(<span class="number">10</span>**k)%<span class="number">10</span>)].append(i)</span><br><span class="line">        list=[j <span class="keyword">for</span> i <span class="keyword">in</span> s <span class="keyword">for</span> j <span class="keyword">in</span> i]</span><br><span class="line">    <span class="keyword">return</span> list</span><br><span class="line"></span><br><span class="line">nums = [<span class="number">5</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">65</span>]</span><br><span class="line">print(radixSort(nums))</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><h4 id="时间复杂度-1"><a href="#时间复杂度-1" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n*k)</li>
<li>最坏时间复杂度：O(n*k)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222145847.gif"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>桶排序</title>
    <url>/2020/01/05/%E6%A1%B6%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p> 桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。 </p>
<a id="more"></a>
<ol>
<li><p><strong>什么时候最快</strong></p>
<p>当输入的数据可以均匀的分配到每一个桶中。</p>
</li>
<li><p><strong>什么时候最慢</strong></p>
<p>当输入的数据被分配到了同一个桶中。</p>
</li>
</ol>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>设置一个定量的数组当作空桶；</li>
<li>遍历输入数据，并且把数据一个一个放到对应的桶里去；</li>
<li>对每个不是空的桶进行排序；</li>
<li>从不是空的桶里把排好序的数据拼接起来。 </li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bucketSort</span><span class="params">(nums, n)</span>:</span></span><br><span class="line">    <span class="comment"># 选择一个最大的数</span></span><br><span class="line">    <span class="keyword">if</span> max(nums) &gt; len(nums):</span><br><span class="line">        n = max(nums)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        n = len(nums) + <span class="number">1</span></span><br><span class="line">    mid = max(nums) // n</span><br><span class="line">    <span class="keyword">if</span> mid == <span class="number">0</span>:</span><br><span class="line">        mid = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 创建一个元素全是0的列表, 当做桶</span></span><br><span class="line">    bucket = [[] <span class="keyword">for</span> i <span class="keyword">in</span> range(n + <span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># 把所有元素放入桶中</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">        bucket[int(i / mid)].append(i)</span><br><span class="line">    print(bucket)</span><br><span class="line">    sort_nums = []</span><br><span class="line">    <span class="comment"># 取出桶中的元素</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(bucket)):</span><br><span class="line">        <span class="keyword">if</span> len(bucket[j]) != <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 使用递归继续桶排序</span></span><br><span class="line">            <span class="keyword">if</span> len(bucket[j]) &gt;= <span class="number">2</span> <span class="keyword">and</span> len(set(nums)) != <span class="number">1</span>:</span><br><span class="line">                bucket[j] = bucketSort(bucket[j], n)</span><br><span class="line">            <span class="comment"># 取出排序好的元素</span></span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> bucket[j]:</span><br><span class="line">                sort_nums.append(y)</span><br><span class="line">    <span class="keyword">return</span> sort_nums</span><br><span class="line"></span><br><span class="line">nums = [<span class="number">5</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">65</span>]</span><br><span class="line">print(bucketSort(nums, <span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n)</li>
<li>最坏时间复杂度：O(n^2)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p> 元素分布在桶中： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222145747.png"/></p>
<p>然后，元素在每个桶中排序</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222145756.png"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>计数排序</title>
    <url>/2020/01/05/%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p> 计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 </p>
<a id="more"></a>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>找出待排序的数组中最大和最小的元素；</li>
<li>统计数组中每个值为i的元素出现的次数，存入数组C的第i项；</li>
<li>对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；</li>
<li>反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p><strong>数字排序</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="comment"># 输出序列</span></span><br><span class="line">    <span class="keyword">if</span> max(arr) &gt; len(arr):</span><br><span class="line">        n = max(arr) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        n = len(arr) + <span class="number">1</span></span><br><span class="line">    output = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</span><br><span class="line">    <span class="comment"># 计数序列</span></span><br><span class="line">    count = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        count[i] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)):</span><br><span class="line">        count[i + <span class="number">1</span>] += count[i]</span><br><span class="line">    print(count)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)):</span><br><span class="line">        <span class="comment"># 下标从0开始</span></span><br><span class="line">        output[count[arr[i]] - <span class="number">1</span>] = arr[i]</span><br><span class="line">        count[arr[i]] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> (output[:len(arr)])</span><br><span class="line"></span><br><span class="line">arr = [<span class="number">5</span>,<span class="number">6</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">8</span>,<span class="number">0</span>]</span><br><span class="line">ans = countSort(arr)</span><br><span class="line">print(ans)</span><br></pre></td></tr></table></figure>
<p><strong>字母排序</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    n = len(arr)</span><br><span class="line">    <span class="comment"># 输出序列</span></span><br><span class="line">    output = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">256</span>)]</span><br><span class="line">    <span class="comment"># 计数序列</span></span><br><span class="line">    count = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">256</span>)]</span><br><span class="line">    ans = [<span class="string">""</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        count[ord(i)] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">256</span>):</span><br><span class="line">        count[i] += count[i - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="comment"># 下标从0开始</span></span><br><span class="line">        output[count[ord(arr[i])] - <span class="number">1</span>] = arr[i]</span><br><span class="line">        count[ord(arr[i])] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)):</span><br><span class="line">        ans[i] = output[i]</span><br><span class="line">    <span class="keyword">return</span> ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">arr = <span class="string">"wwwrunoobcom"</span></span><br><span class="line">ans = countSort(arr)</span><br><span class="line">print(<span class="string">"字符数组排序 %s"</span> % (<span class="string">""</span>.join(ans)))</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n+k)</li>
<li>最坏时间复杂度：O(n+k)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222145653.gif"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>堆排序</title>
    <url>/2020/01/04/%E5%A0%86%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。 </p>
<p><strong>堆</strong>是一种完全二叉树， <strong>堆</strong>有两种类型: <strong>大根堆</strong>  <strong>小根堆</strong>，两种类型的概念如下：<br> 大根堆：每个结点的值都大于或等于左右孩子结点<br> 小根堆：每个结点的值都小于或等于左右孩子结点</p>
 <a id="more"></a>
<p>大根堆 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222144144.webp"/> </p>
<p> 小根堆</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222144211.webp"/></p>
<p> <strong>完全二叉树</strong>：是 一种除了最后一层之外的其他每一层都被完全填充，并且所有结点都保持向左对齐的树 </p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>首先将待排序的数组构造出一个大根堆</li>
<li>取出这个大根堆的堆顶节点(最大值)，与堆的最下最右的元素进行交换，然后把剩下的元素再构造出一个大根堆</li>
<li>重复第二步，直到这个大根堆的长度为1，此时完成排序。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span><span class="params">(arr, n, i)</span>:</span></span><br><span class="line">    largest = i</span><br><span class="line">    l = <span class="number">2</span> * i + <span class="number">1</span>  <span class="comment"># left = 2*i + 1</span></span><br><span class="line">    r = <span class="number">2</span> * i + <span class="number">2</span>  <span class="comment"># right = 2*i + 2</span></span><br><span class="line">    <span class="keyword">if</span> l &lt; n <span class="keyword">and</span> arr[i] &lt; arr[l]:</span><br><span class="line">        largest = l</span><br><span class="line">    <span class="keyword">if</span> r &lt; n <span class="keyword">and</span> arr[largest] &lt; arr[r]:</span><br><span class="line">        largest = r</span><br><span class="line">    <span class="keyword">if</span> largest != i:</span><br><span class="line">        arr[i], arr[largest] = arr[largest], arr[i]  <span class="comment"># 交换</span></span><br><span class="line">        heapify(arr, n, largest)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    n = len(arr)</span><br><span class="line">    <span class="comment"># Build a maxheap.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        print(i)</span><br><span class="line">        heapify(arr, n, i)</span><br><span class="line">    <span class="comment"># 一个个交换元素</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        arr[i], arr[<span class="number">0</span>] = arr[<span class="number">0</span>], arr[i]  <span class="comment"># 交换</span></span><br><span class="line">        heapify(arr, i, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">arr = [<span class="number">12</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">heapSort(arr)</span><br><span class="line">print(<span class="string">"排序后"</span>, arr)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(nlogn) （升序排列，序列已经处于升序状态）</li>
<li>最坏时间复杂度：O(nlogn)</li>
<li>稳定性：不稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222145519.gif"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>归并排序</title>
    <url>/2020/01/02/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。将数组分解最小之后，然后合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可<br><a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>把长度为n的输入序列分成两个长度为n/2的子序列；</li>
<li>对这两个子序列分别采用归并排序；</li>
<li>将两个排序好的子序列合并成一个最终的排序序列。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(alist)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(alist) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> alist</span><br><span class="line">    <span class="comment"># 二分分解</span></span><br><span class="line">    num = len(alist)/<span class="number">2</span></span><br><span class="line">    left = merge_sort(alist[:num])</span><br><span class="line">    right = merge_sort(alist[num:])</span><br><span class="line">    <span class="comment"># 合并</span></span><br><span class="line">    <span class="keyword">return</span> merge(left,right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">    <span class="string">'''合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组'''</span></span><br><span class="line">    <span class="comment">#left与right的下标指针</span></span><br><span class="line">    l, r = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">while</span> l&lt;len(left) <span class="keyword">and</span> r&lt;len(right):</span><br><span class="line">        <span class="keyword">if</span> left[l] &lt;= right[r]:</span><br><span class="line">            result.append(left[l])</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(right[r])</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">    result += left[l:]</span><br><span class="line">    result += right[r:]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]</span><br><span class="line">sorted_alist = mergeSort(alist)</span><br><span class="line">print(sorted_alist)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(nlogn)</li>
<li>最坏时间复杂度：O(nlogn)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222015225.gif"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排序</title>
    <url>/2020/01/02/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>快速排序</strong>（英语：Quicksort），又称划分交换排序（partition-exchange sort），通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。  使用分治法来把一个串（list）分为两个子串（sub-lists） 。<br><a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>从数列中挑出一个元素，称为”基准”（pivot），</li>
<li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。</li>
<li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(alist, start, end)</span>:</span></span><br><span class="line">    <span class="string">"""快速排序"""</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 递归的退出条件</span></span><br><span class="line">    <span class="keyword">if</span> start &gt;= end:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 设定起始元素为要寻找位置的基准元素</span></span><br><span class="line">    mid = alist[start]</span><br><span class="line">    <span class="comment"># low为序列左边的由左向右移动的游标</span></span><br><span class="line">    low = start</span><br><span class="line">    <span class="comment"># high为序列右边的由右向左移动的游标</span></span><br><span class="line">    high = end</span><br><span class="line">    <span class="keyword">while</span> low &lt; high:</span><br><span class="line">        <span class="comment"># 如果low与high未重合，high指向的元素不比基准元素小，则high向左移动</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high <span class="keyword">and</span> alist[high] &gt;= mid:</span><br><span class="line">            high -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># 将high指向的元素放到low的位置上</span></span><br><span class="line">        alist[low] = alist[high]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果low与high未重合，low指向的元素比基准元素小，则low向右移动</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high <span class="keyword">and</span> alist[low] &lt; mid:</span><br><span class="line">            low += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 将low指向的元素放到high的位置上</span></span><br><span class="line">        alist[high] = alist[low]</span><br><span class="line">    <span class="comment"># 退出循环后，low与high重合，此时所指位置为基准元素的正确位置</span></span><br><span class="line">    <span class="comment"># 将基准元素放到该位置</span></span><br><span class="line">    alist[low] = mid</span><br><span class="line">    <span class="comment"># 对基准元素左边的子序列进行快速排序</span></span><br><span class="line">    quick_sort(alist, start, low<span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># 对基准元素右边的子序列进行快速排序</span></span><br><span class="line">    quick_sort(alist, low+<span class="number">1</span>, end)</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]</span><br><span class="line">quick_sort(alist,<span class="number">0</span>,len(alist)<span class="number">-1</span>)</span><br><span class="line">print(alist)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(nlogn)</li>
<li>最坏时间复杂度：O(n2)</li>
<li>稳定性：不稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222015054.gif"/> </p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>希尔排序</title>
    <url>/2020/01/02/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>希尔排序(Shell Sort)是插入排序的一种。也称<strong>缩小增量排序</strong>，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。</p>
<p>希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。<br><a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；</li>
<li>按增量序列个数k，对序列进行k 趟排序；</li>
<li>每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span><span class="params">(alist)</span>:</span></span><br><span class="line">    n = len(alist)</span><br><span class="line">    <span class="comment"># 初始步长</span></span><br><span class="line">    gap = n//<span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 按步长进行插入排序</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap, n):</span><br><span class="line">            j = i</span><br><span class="line">            <span class="comment"># 插入排序</span></span><br><span class="line">            <span class="keyword">while</span> j&gt;=gap <span class="keyword">and</span> alist[j-gap] &gt; alist[j]:</span><br><span class="line">                alist[j-gap], alist[j] = alist[j], alist[j-gap]</span><br><span class="line">                j -= gap</span><br><span class="line">        <span class="comment"># 得到新的步长</span></span><br><span class="line">        gap = gap // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]</span><br><span class="line">shell_sort(alist)</span><br><span class="line">print(alist)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：根据步长序列的不同而不同</li>
<li>最坏时间复杂度：O(n2)</li>
<li>稳定性：不稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222015144.gif"/> </p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>插入排序</title>
    <url>/2020/01/02/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>插入排序</strong>（英语：Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。<br> <a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>从第一个元素开始，该元素可以认为已经被排序；</li>
<li>取出下一个元素，在已经排序的元素序列中从后向前扫描；</li>
<li>如果该元素（已排序）大于新元素，将该元素移到下一位置；</li>
<li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；</li>
<li>将新元素插入到该位置后；</li>
<li>重复步骤2~5。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(alist)</span>:</span></span><br><span class="line">    <span class="comment"># 从第二个位置，即下标为1的元素开始向前插入</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(alist)):</span><br><span class="line">        <span class="comment"># 从第i个元素开始向前比较，如果小于前一个元素，交换位置</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">if</span> alist[j] &lt; alist[j<span class="number">-1</span>]:</span><br><span class="line">                alist[j], alist[j<span class="number">-1</span>] = alist[j<span class="number">-1</span>], alist[j]</span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">26</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]</span><br><span class="line">insert_sort(alist)</span><br><span class="line">print(alist)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n) （升序排列，序列已经处于升序状态）</li>
<li>最坏时间复杂度：O(n2)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222015522.gif"/> </p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>选择排序</title>
    <url>/2020/01/02/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>选择排序（Selection sort）</strong>是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。</p>
<p>选择排序的主要优点与数据移动有关。如果某个元素位于正确的最终位置上，则它不会被移动。选择排序每次交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对n个元素的表进行排序总共进行至多n-1次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。<br><a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>初始状态：无序区为R[1..n]，有序区为空；</li>
<li>第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；</li>
<li>n-1趟结束，数组有序化了。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selection_sort</span><span class="params">(alist)</span>:</span></span><br><span class="line">    n = len(alist)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n<span class="number">-1</span>):</span><br><span class="line">        <span class="comment"># 记录最小位置</span></span><br><span class="line">        min_index = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> alist[j] &lt; alist[min_index]:</span><br><span class="line">                min_index = j</span><br><span class="line">        <span class="comment"># 如果选择出的数据不在正确位置，进行交换</span></span><br><span class="line">        <span class="keyword">if</span> min_index != i:</span><br><span class="line">            alist[i], alist[min_index] = alist[min_index], alist[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">alist = [<span class="number">54</span>,<span class="number">226</span>,<span class="number">93</span>,<span class="number">17</span>,<span class="number">77</span>,<span class="number">31</span>,<span class="number">44</span>,<span class="number">55</span>,<span class="number">20</span>]</span><br><span class="line">selection_sort(alist)</span><br><span class="line">print(alist)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n2)</li>
<li>最坏时间复杂度：O(n2)</li>
<li>稳定性：不稳定（考虑升序每次选择最大的情况）</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222014917.gif"/> </p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>冒泡排序</title>
    <url>/2020/01/02/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。<br> <a id="more"></a></p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><ul>
<li>比较相邻的元素。如果第一个比第二个大（升序），就交换它们两个；</li>
<li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；</li>
<li>针对所有的元素重复以上的步骤，除了最后一个；</li>
<li>重复步骤1~3，直到排序完成。</li>
</ul>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(alist)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(alist)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(j):</span><br><span class="line">            <span class="keyword">if</span> alist[i] &gt; alist[i+<span class="number">1</span>]:</span><br><span class="line">                alist[i], alist[i+<span class="number">1</span>] = alist[i+<span class="number">1</span>], alist[i]</span><br><span class="line"></span><br><span class="line">li = [<span class="number">54</span>, <span class="number">26</span>, <span class="number">93</span>, <span class="number">17</span>, <span class="number">77</span>, <span class="number">31</span>, <span class="number">44</span>, <span class="number">55</span>, <span class="number">20</span>]</span><br><span class="line">bubble_sort(li)</span><br><span class="line">print(li)</span><br></pre></td></tr></table></figure>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><ul>
<li>最优时间复杂度：O(n) （表示遍历一次发现没有任何可以交换的元素，排序结束。）</li>
<li>最坏时间复杂度：O(n2)</li>
<li>稳定性：稳定</li>
</ul>
<h4 id="动画演示"><a href="#动画演示" class="headerlink" title="动画演示"></a>动画演示</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200222015002.gif"/></p>
]]></content>
      <categories>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
      </tags>
  </entry>
</search>
