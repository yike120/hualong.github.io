<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/bitbug_favicon32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/bitbug_favicon16x16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://xiaoliaozi.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="决策树决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-else结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法。 决策树：是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树。">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树算法">
<meta property="og:url" content="https://xiaoliaozi.com/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/index.html">
<meta property="og:site_name" content="小廖子的博客">
<meta property="og:description" content="决策树决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-else结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法。 决策树：是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093747.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093959.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093755.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093951.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093943.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093935.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094202.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093928.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093638.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093732.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093802.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093724.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093921.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093717.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093709.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094054.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094008.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093911.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093632.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093701.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093654.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094038.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093905.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093857.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093849.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093646.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094152.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093842.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094032.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227100629.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093826.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093818.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094025.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094102.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093810.png">
<meta property="og:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094206.png">
<meta property="article:published_time" content="2020-01-10T01:34:04.000Z">
<meta property="article:modified_time" content="2020-02-27T02:11:48.935Z">
<meta property="article:author" content="小廖子">
<meta property="article:tag" content="机器学习算法">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="监督学习算法">
<meta property="article:tag" content="决策树分类原理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093747.png">

<link rel="canonical" href="https://xiaoliaozi.com/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>决策树算法 | 小廖子的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="小廖子的博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小廖子的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">好记性不如记笔记</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xiaoliaozi.com/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avter.jpg">
      <meta itemprop="name" content="小廖子">
      <meta itemprop="description" content="学无止境">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小廖子的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          决策树算法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-10 09:34:04" itemprop="dateCreated datePublished" datetime="2020-01-10T09:34:04+08:00">2020-01-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-27 10:11:48" itemprop="dateModified" datetime="2020-02-27T10:11:48+08:00">2020-02-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习算法</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h4><p>决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-else结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法。</p>
<p><strong>决策树：是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树</strong>。</p>
<a id="more"></a>
<h4 id="熵的概念"><a href="#熵的概念" class="headerlink" title="熵的概念"></a>熵的概念</h4><p> 物理学上，<strong>熵 Entropy</strong> 是“混乱”程度的量度。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093747.png"/> </p>
<p> <strong>系统越有序，熵值越低；系统越混乱或者分散，熵值越高</strong>。 </p>
<ul>
<li><h5 id="信息理论"><a href="#信息理论" class="headerlink" title="信息理论"></a>信息理论</h5><ol>
<li><p><strong>从信息的完整性上进行的描述：</strong></p>
<p> 当<strong>系统的有序状态一致时</strong>，数据越集中的地方熵值越小，数据越分散的地方熵值越大。 </p>
</li>
<li><p><strong>从信息的有序性上进行的描述：</strong></p>
<p>  当<strong>数据量一致时</strong>，<strong>系统越有序，熵值越低；系统越混乱或者分散，熵值越高</strong>。 </p>
</li>
</ol>
</li>
</ul>
<p>“<strong>信息熵</strong>“ (information entropy)是度量样本集合纯度最常用的一种指标。</p>
<p>假定当前样本集合 D 中第 k 类样本所占的比例为$p_k(k = 1, 2,. . . , |y|)$ ，</p>
<p>$p_k=\frac{C^k}{D}$, D为样本的所有数量，$C^k$为第$k$类样本的数量。</p>
<p>则 D的信息熵定义为(（log是以2为底）:</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093959.png"/></p>
<p> 其中：Ent(D) 的值越小，则 D 的纯度越高. </p>
<ul>
<li><h5 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h5></li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">假设我们没有看世界杯的比赛，但是想知道哪支球队会是冠军，</span><br><span class="line">我们只能猜测某支球队是或不是冠军，然后观众用对或不对来回答，</span><br><span class="line">我们想要猜测次数尽可能少，你会用什么方法？</span><br><span class="line"></span><br><span class="line">答案：</span><br><span class="line">二分法：</span><br><span class="line">假如有 <span class="number">16</span> 支球队，分别编号，先问是否在 <span class="number">1</span><span class="number">-8</span> 之间，如果是就继续问是否在 <span class="number">1</span><span class="number">-4</span> 之间，</span><br><span class="line">以此类推，直到最后判断出冠军球队是哪支。</span><br><span class="line">如果球队数量是 <span class="number">16</span>，我们需要问 <span class="number">4</span> 次来得到最后的答案。那么世界冠军这条消息的信息熵就是 <span class="number">4</span>。</span><br><span class="line"></span><br><span class="line">那么信息熵等于<span class="number">4</span>，是如何进行计算的呢？</span><br><span class="line">Ent(D) = -（p1 * logp1 + p2 * logp2 + ... + p16 * logp16），</span><br><span class="line">其中 p1, ..., p16 分别是这 <span class="number">16</span> 支球队夺冠的概率。</span><br><span class="line">当每支球队夺冠概率相等都是 <span class="number">1</span>/<span class="number">16</span> 的时：Ent(D) = -（<span class="number">16</span> * <span class="number">1</span>/<span class="number">16</span> * log1/<span class="number">16</span>） = <span class="number">4</span></span><br><span class="line">每个事件概率相同时，熵最大，这件事越不确定。</span><br><span class="line"></span><br><span class="line">篮球比赛里，有<span class="number">4</span>个球队 &#123;A,B,C,D&#125; ，获胜概率分别为&#123;<span class="number">1</span>/<span class="number">2</span>, <span class="number">1</span>/<span class="number">4</span>, <span class="number">1</span>/<span class="number">8</span>, <span class="number">1</span>/<span class="number">8</span>&#125;，求Ent(D)</span><br><span class="line">Ent(D)=<span class="number">7</span>/<span class="number">4</span></span><br></pre></td></tr></table></figure>
<h4 id="决策树的划分依据"><a href="#决策树的划分依据" class="headerlink" title="决策树的划分依据"></a>决策树的划分依据</h4><h5 id="1-信息增益"><a href="#1-信息增益" class="headerlink" title="1.信息增益"></a>1.信息增益</h5><p> <strong>信息增益：</strong>以某特征划分数据集前后的熵的差值。熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以<strong>使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏</strong>。 </p>
<p> <strong>信息增益 = entroy(前) - entroy(后)</strong> </p>
<figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：信息增益表示得知特征<span class="keyword">X</span>的信息而使得类<span class="keyword">Y</span>的信息熵减少的程度</span><br></pre></td></tr></table></figure>
<ul>
<li><p>定义与公式</p>
<p>假定离散属性a有 V 个可能的取值：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093755.png"/></p>
<p>若使用a来对样本集 $D$ 进行划分，则会产生 V 个分支结点，其中第$v$个分支结点包含了 $D$ 中所有在属性$a$上取值为$a^v$的样本，记为$D^v$. 我们可根据前面给出的信息熵公式计算出$D^v$的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重$\frac{|D^v|}{|D|}$</p>
<p>即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集 D 进行划分所获得的”信息增益” (information gain)</p>
<p>其中：</p>
<p>特征$a$对训练数据集D的信息增益$Gain(D,a)$，定义为<strong>集合D的信息熵$Ent(D)$</strong>与<strong>给定特征$a$条件下$D$的信息条件熵$Ent(D|a)$</strong>之差，即公式为：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093951.png"/></p>
<p>  信息熵的计算： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093943.png"/></p>
<p> 条件熵的计算： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093935.png"/></p>
<p>其中：</p>
<p>$D^v$ 表示$a$属性中第$v$个分支节点包含的样本数</p>
<p>$C^{kv}$ 表示$a$属性中第$v$个分支节点包含的样本数中，第$k$个类别下包含的样本数</p>
<p>一般而言，信息增益越大，则意味着<strong>使用属性 $a$ 来进行划分所获得的”纯度提升”越大</strong>。因此，我们可用信息增益来进行决策树的划分属性选择，著名的 <strong>ID3 决策树学习算法</strong> [Quinlan， 1986] 就是以<strong>信息增益为准则</strong>来选择划分属性。 </p>
</li>
<li><p>举例说明</p>
<p>如下图，第一列为论坛号码，第二列为性别，第三列为活跃度，最后一列用户是否流失。</p>
<p>我们要解决一个问题：<strong>性别和活跃度两个特征，哪个对用户流失影响更大</strong>？</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094202.png"/> </p>
<p>通过计算信息增益可以解决这个问题，统计上右表信息</p>
<p>其中Positive为正样本（已流失），Negative为负样本（未流失），下面的数值为不同划分下对应的人数。</p>
<p>可得到三个熵：</p>
<p><strong>a.计算类别信息熵</strong></p>
<p>整体熵：</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093928.png"/></p>
<p> <strong>b.计算性别属性的信息熵(a=”性别”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093638.png"/></p>
<p> <strong>c.计算性别的信息增益(a=”性别”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093732.png"/> </p>
<p> <strong>b.计算活跃度属性的信息熵(a=”活跃度”)</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093802.png"/></p>
<p> <strong>c.计算活跃度的信息增益(a=”活跃度”)</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093724.png"/> </p>
<p> <strong>活跃度的信息增益比性别的信息增益大，也就是说，活跃度对用户流失的影响比性别大。</strong>在做特征选择或者数据分析的时候，我们应该重点考察活跃度这个指标。 </p>
</li>
</ul>
<h5 id="2-信息增益率"><a href="#2-信息增益率" class="headerlink" title="2.信息增益率"></a>2.信息增益率</h5><p> 在上面的介绍中，我们有意忽略了”编号”这一列.若把”编号”也作为一个候选划分属性，则根据信息增益公式可计算出它的信息增益为 0.9182，远大于其他候选划分属性。 </p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">计算每个属性的信息熵过程中,我们发现,该属性的值为<span class="number">0</span>, 也就是其信息增益为<span class="number">0.9182</span>. 但是很明显这么分类,最后出现的结果不具有泛化效果.无法对新样本进行有效预测.</span><br></pre></td></tr></table></figure>
<p> 实际上，<strong>信息增益准则对可取值数目较多的属性有所偏好</strong>，为减少这种偏好可能带来的不利影响，著名的 <strong>C4.5 决策树算法 [Quinlan， 1993J 不直接使用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性</strong>。</p>
<p> <strong>增益率：</strong>增益率是用前面的信息增益$Gain(D, a)$和属性$a$对应的”固有值”(intrinsic value) [Quinlan , 1993J的比值来共同定义的。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093921.png"/></p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">属性 a 的可能取值数目越多<span class="comment">(即 V 越大)</span>，则 IV<span class="comment">(a)</span> 的值通常会越大.</span><br></pre></td></tr></table></figure>
<p> <strong>上个案例中</strong></p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a.计算类别信息熵</span><br><span class="line">b.计算性别属性的信息熵<span class="comment">(性别、活跃度)</span></span><br><span class="line">c.计算活跃度的信息增益<span class="comment">(性别、活跃度)</span></span><br></pre></td></tr></table></figure>
<p> <strong>d.计算属性分裂信息度量</strong> </p>
<p> 用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息（instrisic information）。信息增益率用信息增益/内在信息，会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093717.png"/> </p>
<p> <strong>e.计算信息增益率</strong> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093709.png"/> </p>
<p>活跃度的信息增益率更高一些，所以在构建决策树的时候，优先选择</p>
<p>通过这种方式，在选取节点的过程中，我们可以降低取值较多的属性的选取偏好。</p>
<p><strong>案例二</strong></p>
<p>如下图，第一列为天气，第二列为温度，第三列为湿度，第四列为风速，最后一列该活动是否进行。</p>
<p>我们要解决：<strong>根据下面表格数据，判断在对应天气下，活动是否会进行</strong>？</p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094054.png"/> </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094008.png"/> </p>
<p> 该数据集有四个属性，属性集合A={ 天气，温度，湿度，风速}， 类别标签有两个，类别集合L={进行，取消}。 </p>
<p> <strong>a.计算类别信息熵</strong> </p>
<p> 类别信息熵表示的是所有样本中各种类别出现的不确定性之和。根据熵的概念，熵越大，不确定性就越大，把事情搞清楚所需要的信息量就越多。 </p>
<script type="math/tex; mode=display">Ent(D)=-\frac{9}{14}log_2\frac{9}{14}-\frac{5}{14}log_2\frac{5}{14}=0.940</script><p><strong>b.计算每个属性的信息熵</strong></p>
<p>每个属性的信息熵相当于一种条件熵。他表示的是在某种属性的条件下，各种类别出现的不确定性之和。属性的信息熵越大，表示这个属性中拥有的样本类别越不“纯”。</p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093911.png"/>  </p>
<p><strong>c.计算信息增益</strong></p>
<p>信息增益的 = 熵 - 条件熵，在这里就是 类别信息熵 - 属性信息熵，它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，当然，选择该属性就可以更快更好地完成我们的分类目标。</p>
<p> <strong>信息增益就是ID3算法的特征选择指标。</strong></p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093632.png"/></p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">假设我们把上面表格<span class="number">1</span>的数据前面添加一列为<span class="string">"编号"</span>,取值(<span class="number">1</span>-<span class="number">-14</span>). 若把<span class="string">"编号"</span>也作为一个候选划分属性,则根据前面步骤: 计算每个属性的信息熵过程中,我们发现,该属性的值为<span class="number">0</span>, 也就是其信息增益为<span class="number">0.940</span>. 但是很明显这么分类,最后出现的结果不具有泛化效果.此时根据信息增益就无法选择出有效分类特征。所以，C4<span class="number">.5</span>选择使用信息增益率对ID3进行改进。</span><br></pre></td></tr></table></figure>
<p> <strong>d.计算属性分裂信息度量</strong></p>
<p>  用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息（instrisic information）。信息增益率用信息增益/内在信息，会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093701.png"/> </p>
<p> <strong>e.计算信息增益率</strong> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093654.png"/></p>
<p> 天气的信息增益率最高，选择天气为分裂属性。发现分裂了之后，天气是“阴”的条件下，类别是”纯“的，所以把它定义为叶子节点，选择不“纯”的结点继续分裂。 </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094038.png"/> </p>
<p>在子结点当中重复过程1~5，直到所有的叶子结点足够”纯”。</p>
<p>现在我们来总结一下C4.5的算法流程</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(当前节点<span class="string">"不纯"</span>)：</span><br><span class="line">    <span class="number">1.</span>计算当前节点的类别熵(以类别取值计算)</span><br><span class="line">    <span class="number">2.</span>计算当前阶段的属性熵(按照属性取值吓得类别取值计算)</span><br><span class="line">    <span class="number">3.</span>计算信息增益</span><br><span class="line">    <span class="number">4.</span>计算各个属性的分裂信息度量</span><br><span class="line">    <span class="number">5.</span>计算各个属性的信息增益率</span><br><span class="line">end <span class="keyword">while</span></span><br><span class="line">当前阶段设置为叶子节点</span><br></pre></td></tr></table></figure>
<h5 id="3-基尼值和基尼指数"><a href="#3-基尼值和基尼指数" class="headerlink" title="3.基尼值和基尼指数"></a>3.基尼值和基尼指数</h5><p> CART 决策树 [Breiman et al., 1984] 使用”基尼指数” (Gini index)来选择划分属性。</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">CART</span> 是Classification <span class="keyword">and </span>Regression Tree的简称，这是一种著名的决策树学习算法,分类和回归任务都可用。</span><br></pre></td></tr></table></figure>
<p> <strong>基尼值Gini（D）：</strong>从数据集D中随机抽取两个样本，其类别标记不一致的概率。<strong>故，Gini（D）值越小，数据集D的纯度越高。</strong> </p>
<p> 数据集 D 的纯度可用基尼值来度量: </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093905.png"/></p>
<p> $*p_k=\frac{C^k}{D}$, D为样本的所有数量，$C^k$为第k类样本的数量。 </p>
<p> <strong>基尼指数Gini_index（D）：</strong>一般，选择使划分后基尼系数最小的属性作为最优化分属性。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093857.png"/></p>
<p><strong>案例</strong></p>
<p> 请根据下图列表，按照基尼指数的划分依据，做出决策树。 </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>序号</th>
<th>是否有房</th>
<th>婚姻状况</th>
<th>年收入</th>
<th>是否拖欠贷款</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>yes</td>
<td>single</td>
<td>125k</td>
<td>no</td>
</tr>
<tr>
<td>2</td>
<td>no</td>
<td>married</td>
<td>100k</td>
<td>no</td>
</tr>
<tr>
<td>3</td>
<td>no</td>
<td>single</td>
<td>70k</td>
<td>no</td>
</tr>
<tr>
<td>4</td>
<td>yes</td>
<td>married</td>
<td>120k</td>
<td>no</td>
</tr>
<tr>
<td>5</td>
<td>no</td>
<td>divorced</td>
<td>95k</td>
<td>yes</td>
</tr>
<tr>
<td>6</td>
<td>no</td>
<td>married</td>
<td>60k</td>
<td>no</td>
</tr>
<tr>
<td>7</td>
<td>yes</td>
<td>divorced</td>
<td>220k</td>
<td>no</td>
</tr>
<tr>
<td>8</td>
<td>no</td>
<td>single</td>
<td>85k</td>
<td>yes</td>
</tr>
<tr>
<td>9</td>
<td>no</td>
<td>married</td>
<td>75k</td>
<td>no</td>
</tr>
<tr>
<td>10</td>
<td>No</td>
<td>Single</td>
<td>90k</td>
<td>Yes</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><p>对数据集非序列标号属性{是否有房，婚姻状况，年收入}分别计算它们的Gini指数，<strong>取Gini指数最小的属性作为决策树的根节点属性。</strong> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">第一次大循环</span><br></pre></td></tr></table></figure>
</li>
<li><p>根节点的Gini值为： </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093849.png"/></p>
</li>
<li><p>当根据是否有房来进行划分时，Gini指数计算过程为： </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093646.png"/></p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094152.png"/>  </p>
</li>
<li><p>若按婚姻状况属性来划分，属性婚姻状况有三个可能的取值{married，single，divorced}，分别计算划分后的Gini系数增益。 </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093842.png"/></p>
<p>对比计算结果，根据婚姻状况属性来划分根节点时取Gini指数最小的分组作为划分结果，即:</p>
<p>{married} | {single,divorced} </p>
</li>
<li><p>同理可得年收入Gini： </p>
<p>对于年收入属性为数值型属性，首先需要对数据按升序排序，然后从小到大依次用相邻值的中间值作为分隔将样本划分为两组。例如当面对年收入为60和70这两个值时，我们算得其中间值为65。以中间值65作为分割点求出Gini指数。 </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094032.png"/> </p>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227100629.png"/> </p>
<p>根据计算知道，三个属性划分根节点的指数最小的有两个：年收入属性和婚姻状况，他们的指数都为0.3。此时，选取首先出现的属性【married】作为第一次划分。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">第二次大循环</span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来，采用同样的方法，分别计算剩下属性，其中根节点的Gini系数为（此时是否拖欠贷款的各有3个records） </p>
<p> <img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093826.png"/> </p>
</li>
<li><p>对于是否有房属性，可得： </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093818.png"/></p>
</li>
<li><p>对于年收入属性则有： </p>
</li>
<li><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094025.png"/></p>
<p>经过如上流程，构建的决策树，如下图： </p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094102.png"/></p>
<p>总结一下CART的算法流程 </p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(当前节点<span class="string">"不纯"</span>)：</span><br><span class="line">    <span class="number">1</span>.遍历每个变量的每一种分割方式，找到最好的分割点</span><br><span class="line">    <span class="number">2</span>.分割成两个节点N1和N2</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">while</span></span><br><span class="line">每个节点足够“纯”为止</span><br></pre></td></tr></table></figure>
<h4 id="常见决策树的启发函数比较"><a href="#常见决策树的启发函数比较" class="headerlink" title="常见决策树的启发函数比较"></a>常见决策树的启发函数比较</h4><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227093810.png"/></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>提出时间</th>
<th>分支方式</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>ID3</td>
<td>1975</td>
<td>信息增益</td>
<td>ID3只能对离散属性的数据集构成决策树</td>
</tr>
<tr>
<td>C4.5</td>
<td>1993</td>
<td>信息增益率</td>
<td>优化后解决了ID3分支过程中总喜欢偏向选择值较多的 属性</td>
</tr>
<tr>
<td>CART</td>
<td>1984</td>
<td>Gini系数</td>
<td>可以进行分类和回归，可以处理离散属性，也可以处理连续属性</td>
</tr>
</tbody>
</table>
</div>
<h5 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h5><p><strong>存在的缺点</strong></p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> (<span class="number">1</span>) ID3算法在选择根节点和各内部节点中的分支属性时，采用信息增益作为评价标准。信息增益的缺点是倾向于选择取值较多的属性，在有些情况下这类属性可能不会提供太多有价值的信息.</span><br><span class="line">(<span class="number">2</span>) ID3算法只能对描述属性为离散型属性的数据集构造决策树。</span><br></pre></td></tr></table></figure>
<h5 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h5><p><strong>1.用信息增益率来选择属性</strong></p>
<p>克服了用信息增益来选择属性时偏向选择值多的属性的不足。</p>
<p><strong>2.采用了一种后剪枝方法</strong></p>
<p>避免树的高度无节制的增长，避免过度拟合数据</p>
<p><strong>3.对于缺失值的处理</strong></p>
<p>在某些情况下，可供使用的数据可能缺少某些属性的值。假如〈x，c(x)〉是样本集S中的一个训练实例，但是其属性A的值A(x)未知。处理缺少属性值的一种策略是赋给它结点n所对应的训练实例中该属性的最常见值；</p>
<p>另外一种更复杂的策略是为A的每个可能值赋予一个概率。</p>
<p>例如，给定一个布尔属性A，如果结点n包含6个已知A=1和4个A=0的实例，那么A(x)=1的概率是0.6，而A(x)=0的概率是0.4。于是，实例x的$60\%$被分配到A=1的分支，$40\%$被分配到另一个分支。</p>
<p><strong>C4.5就是使用这种方法处理缺少的属性值</strong>。</p>
<p><strong>C4.5算法的优缺点</strong></p>
<p> 优点：产生的分类规则易于理解，准确率较高。</p>
<p> 缺点： 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。此外，C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</p>
<h5 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h5><p> CART算法相比C4.5算法的分类方法，采用了简化的二叉树模型，同时特征选择采用了近似的基尼系数来简化计算。 </p>
<p> <strong>C4.5不一定是二叉树，但CART一定是二叉树</strong> </p>
<h5 id="多变量决策树-multi-variate-decision-tree"><a href="#多变量决策树-multi-variate-decision-tree" class="headerlink" title="多变量决策树(multi-variate decision tree)"></a>多变量决策树(multi-variate decision tree)</h5><p> 同时，无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，<strong>分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。</strong>这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1 （了解一下）。</p>
<p> 如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。 </p>
<h4 id="决策树变量的两种类型"><a href="#决策树变量的两种类型" class="headerlink" title="决策树变量的两种类型"></a>决策树变量的两种类型</h4><ol>
<li>数字型（Numeric）：变量类型是整数或浮点数，如前面例子中的“年收入”。用“&gt;=”，“&gt;”,“&lt;”或“&lt;=”作为分割条件（排序后，利用已有的分割情况，可以优化分割算法的时间复杂度）。</li>
<li>名称型（Nominal）：类似编程语言中的枚举类型，变量只能从有限的选项中选取，比如前面例子中的“婚姻情况”，只能是“单身”，“已婚”或“离婚”，使用“=”来分割。</li>
</ol>
<h4 id="如何评估分割点的好坏"><a href="#如何评估分割点的好坏" class="headerlink" title="如何评估分割点的好坏"></a>如何评估分割点的好坏</h4><p>如果一个分割点可以将当前的所有节点分为两类，使得每一类都很“纯”，也就是同一类的记录较多，那么就是一个好分割点。</p>
<p>比如上面的例子，“拥有房产”，可以将记录分成了两类，“是”的节点全部都可以偿还债务，非常“纯”；“否”的节点，可以偿还贷款和无法偿还贷款的人都有，不是很“纯”，但是两个节点加起来的纯度之和与原始节点的纯度之差最大，所以按照这种方法分割。</p>
<p>构建决策树采用贪心算法，只考虑当前纯度差最大的情况作为分割点。</p>
<h4 id="cart剪枝"><a href="#cart剪枝" class="headerlink" title="cart剪枝"></a>cart剪枝</h4><h5 id="为什么要剪枝"><a href="#为什么要剪枝" class="headerlink" title="为什么要剪枝"></a>为什么要剪枝</h5><p><img src="https://raw.githubusercontent.com/xlztongxue/picgo/master/img/20200227094206.png"/> </p>
<ul>
<li><strong>图形描述</strong><ul>
<li>横轴表示在决策树创建过程中树的结点总数，纵轴表示决策树的预测精度。</li>
<li>实线显示的是决策树在训练集上的精度，虚线显示的则是在一个独立的测试集上测量出来的精度。</li>
<li>随着树的增长，在训练样集上的精度是单调上升的， 然而在独立的测试样例上测出的精度先上升后下降。</li>
</ul>
</li>
<li><strong>出现这种情况的原因：</strong><ul>
<li>原因1：噪声、样本冲突，即错误的样本数据。</li>
<li>原因2：特征即属性不能完全作为分类标准。</li>
<li>原因3：巧合的规律性，数据量不够大。</li>
</ul>
</li>
</ul>
<h5 id="常用的减枝方法"><a href="#常用的减枝方法" class="headerlink" title="常用的减枝方法"></a>常用的减枝方法</h5><ol>
<li><p><strong>预剪枝</strong></p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>）每一个结点所包含的最小样本数目，例如<span class="number">10</span>，则该结点总样本数小于<span class="number">10</span>时，则不再分；</span><br><span class="line"><span class="number">2</span>）指定树的高度或者深度，例如树的最大深度为<span class="number">4</span>；</span><br><span class="line"><span class="number">3</span>）指定结点的熵小于某个值，不再划分。随着树的增长， 在训练样集上的精度是单调上升的， 然而在独立的测试样例上测出的精度先上升后下降。</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>后剪枝</strong></p>
<p>把一棵树，构建完成之后，再进行从下往上的剪枝 </p>
</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
            <!---<a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" rel="tag"># 机器学习算法</a>--->
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" rel="tag">机器学习算法</a>
            <!---<a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>--->
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a>
            <!---<a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" rel="tag"># 监督学习算法</a>--->
            <a href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" rel="tag">监督学习算法</a>
            <!---<a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E5%8E%9F%E7%90%86/" rel="tag"># 决策树分类原理</a>--->
            <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E5%8E%9F%E7%90%86/" rel="tag">决策树分类原理</a>
            <br>
          <div class="fa fa-tag">本文结束</div>
          <br/>
          </div>
        

        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/09/TCP%E5%8D%8F%E8%AE%AE/" rel="prev" title="TCP协议">
      <i class="fa fa-chevron-left"></i> TCP协议
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/01/10/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B/" rel="next" title="决策树算法案例">
      决策树算法案例 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树"><span class="nav-number">1.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#熵的概念"><span class="nav-number">2.</span> <span class="nav-text">熵的概念</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#信息理论"><span class="nav-number">2.1.</span> <span class="nav-text">信息理论</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#举例说明"><span class="nav-number">2.2.</span> <span class="nav-text">举例说明</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树的划分依据"><span class="nav-number">3.</span> <span class="nav-text">决策树的划分依据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-信息增益"><span class="nav-number">3.1.</span> <span class="nav-text">1.信息增益</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-信息增益率"><span class="nav-number">3.2.</span> <span class="nav-text">2.信息增益率</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-基尼值和基尼指数"><span class="nav-number">3.3.</span> <span class="nav-text">3.基尼值和基尼指数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#常见决策树的启发函数比较"><span class="nav-number">4.</span> <span class="nav-text">常见决策树的启发函数比较</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ID3-算法"><span class="nav-number">4.1.</span> <span class="nav-text">ID3 算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#C4-5算法"><span class="nav-number">4.2.</span> <span class="nav-text">C4.5算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CART算法"><span class="nav-number">4.3.</span> <span class="nav-text">CART算法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#多变量决策树-multi-variate-decision-tree"><span class="nav-number">4.4.</span> <span class="nav-text">多变量决策树(multi-variate decision tree)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#决策树变量的两种类型"><span class="nav-number">5.</span> <span class="nav-text">决策树变量的两种类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何评估分割点的好坏"><span class="nav-number">6.</span> <span class="nav-text">如何评估分割点的好坏</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cart剪枝"><span class="nav-number">7.</span> <span class="nav-text">cart剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#为什么要剪枝"><span class="nav-number">7.1.</span> <span class="nav-text">为什么要剪枝</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#常用的减枝方法"><span class="nav-number">7.2.</span> <span class="nav-text">常用的减枝方法</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <a href="/"><img class="site-author-image" itemprop="image" alt="小廖子"
      src="/images/avter.jpg">
    </a>
  <p class="site-author-name" itemprop="name">小廖子</p>
  <div class="site-description" itemprop="description">学无止境</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">73</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xlztongxue" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xlztongxue" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xlz_tongxue@163.com" title="E-Mail → mailto:xlz_tongxue@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/weixin_45439324" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_45439324" rel="noopener" target="_blank"><i class="fa fa-fw fa-copyright"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-fw fa-rss"></i>RSS</a>
      </span>
  </div>


    <p class="site-author-name" itemprop="name">关注我哟</p>
    <img class="site-author-image" itemprop="image" alt="微信公众号"
      src="/images/xlzblog.jpg">
    <div class="site-description" itemprop="description">关注公众号，更多精彩等着你</div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-小廖子"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小廖子</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">124k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">3:27</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el: '#valine-comments',
      verify: false,
      notify: false,
      appId: 'Ed2mvWHWKlphKGAa6hId76UP-gzGzoHsz',
      appKey: '7MYwWTLCtelB1RHhedbF58S4',
      placeholder: "Just go go",
      avatar: 'mm',
      meta: guest,
      pageSize: '10' || 10,
      visitor: false,
      lang: '' || 'zh-cn',
      path: location.pathname,
      recordIP: false,
      serverURLs: ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
